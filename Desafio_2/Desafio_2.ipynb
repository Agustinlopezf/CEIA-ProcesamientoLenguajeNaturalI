{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8589956a",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Custom embedddings con Gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04d1155",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto. Se utilizará canciones de bandas para generar los embeddings, es decir, que los vectores tendrán la forma en función de como esa banda haya utilizado las palabras en sus canciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "746cab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ae22e",
   "metadata": {},
   "source": [
    "### Desafío 2\n",
    "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
    "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
    "- Graficarlos.\n",
    "- Obtener conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037cdf93",
   "metadata": {},
   "source": [
    "### Datos\n",
    "Como fuente de datos de utilizarán las novelas de \"A Song of Ice and Fire\" de George Martin. Las mismas fueron obtenidas de Kaggle:\n",
    "https://www.kaggle.com/datasets/saurabhbadole/game-of-thrones-book-dataset/data\n",
    "\n",
    "El dataset cotiene cinco archivos de texto, cada uno con un libro de la saga. Se comienza concatenando todos los archivos en un solo corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1604869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "lista_libros = [\n",
    "    \"1 - A Game of Thrones.txt\",\n",
    "    \"2 - A Clash of Kings.txt\",\n",
    "    \"3 - A Storm of Swords.txt\",\n",
    "    \"4 - A Feast for Crows.txt\",\n",
    "    \"5 - A Dance with Dragons.txt\"\n",
    "]\n",
    "\n",
    "# Crear un corpus en memoria\n",
    "corpus = \"\"\n",
    "\n",
    "for nombre in lista_libros:\n",
    "    ruta_libro = os.path.join(\"./Dataset\", nombre)\n",
    "    with open(ruta_libro, \"r\", encoding=\"latin-1\") as f:\n",
    "        contenido = f.read()\n",
    "        corpus += contenido + \"\\n\"  # agrega un salto de línea entre libros\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209a9b6",
   "metadata": {},
   "source": [
    "Se muestran las primeras líneas del texto completo, la cantidad de líneas y caracteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad15dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 10 líneas:\n",
      "A Game Of Thrones \n",
      "Book One of A Song of Ice and Fire \n",
      "By George R. R. Martin \n",
      "PROLOGUE \n",
      "\"We should start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are \n",
      "dead.\" \n",
      "\"Do the dead frighten you?\" Ser Waymar Royce asked with just the hint of a smile. \n",
      "Gared did not rise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go. \n",
      "\"Dead is dead,\" he said. \"We have no business with the dead.\" \n",
      "\"Are they dead?\" Royce asked softly. \"What proof have we?\" \n",
      "\n",
      "Cantidad de líneas: 125666\n",
      "Cantidad total de caracteres: 9778338\n"
     ]
    }
   ],
   "source": [
    "# Dividir el corpus en líneas\n",
    "lineas = corpus.splitlines()  # crea una lista de líneas\n",
    "\n",
    "# Mostrar las primeras 10 líneas\n",
    "print(\"Primeras 10 líneas:\")\n",
    "print(\"\\n\".join(lineas[:10]))\n",
    "\n",
    "# Cantidad de líneas\n",
    "print(\"\\nCantidad de líneas:\", len(lineas))\n",
    "\n",
    "# Cantidad total de caracteres\n",
    "print(\"Cantidad total de caracteres:\", len(corpus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9edf13",
   "metadata": {},
   "source": [
    "# Preprocesamiento de texto para embeddings\n",
    "\n",
    "Antes de entrenar embeddings, se aplican varios pasos de limpieza y tokenización del texto:\n",
    "\n",
    "- **Convertir a minúsculas:**  \n",
    "  Se unifican todas las palabras para evitar duplicados debidos a mayúsculas/minúsculas.\n",
    "\n",
    "- **Eliminar encabezados y secciones no deseadas:**  \n",
    "  Se eliminan nombres de libros, capítulos, autor, prólogo, dedicatoria, tabla de contenidos, notas de cronología y numeración de páginas.\n",
    "\n",
    "- **Separar en oraciones:**  \n",
    "  Se divide el texto usando signos de puntuación (`.`, `?`, `!`) para preservar la estructura básica de las oraciones, incluyendo diálogos y frases cortas.\n",
    "\n",
    "- **Limpiar cada oración:**  \n",
    "  Se eliminan números y puntuación interna, y se normalizan espacios en blanco para obtener texto limpio.\n",
    "\n",
    "- **Tokenización y eliminación de *stopwords*:**  \n",
    "  Cada oración se convierte en una lista de palabras y se eliminan las palabras vacías (como \"the\", \"and\", \"of\") que no aportan significado semántico.\n",
    "\n",
    "\n",
    "**Nota:** Algunas oraciones resultan muy cortas después de este proceso, especialmente diálogos o frases muy breves. Como alternativa, se evalúa realizar la tokenización por párrafos completos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "339feaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de oraciones tokenizadas: 155054\n",
      "Ejemplo de primera oración tokenizada: ['start', 'back', 'gared', 'urged', 'woods', 'began', 'grow', 'dark', 'around']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocesar_texto_por_oracion(text):\n",
    "    \"\"\"\n",
    "    Recibe un texto completo y devuelve una lista de oraciones,\n",
    "    cada una representada como lista de tokens limpios.\n",
    "    Esta versión no depende de NLTK punkt.\n",
    "    \"\"\"\n",
    "    # 1. Pasar a minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Eliminar encabezados no deseados\n",
    "    patterns_to_remove = [\n",
    "        r\"a game of thrones\",\n",
    "        r\"a clash of kings\",\n",
    "        r\"a storm of swords\",\n",
    "        r\"a feast for crows\",\n",
    "        r\"a dance with dragons\",\n",
    "        r\"book [^\\n]+\",          # líneas tipo \"Book One of...\"\n",
    "        r\"by george r\\. r\\. martin\",\n",
    "        r\"prologue\",\n",
    "        r\"dedication\",\n",
    "        r\"contents\",\n",
    "        r\"a note on chronology\",\n",
    "        r\"a cavil on chronology\",\n",
    "        r\"version history.*\",\n",
    "        r\"page \\d+\",             # \"Page XX\"\n",
    "    ]\n",
    "    for pat in patterns_to_remove:\n",
    "        text = re.sub(pat, \" \", text)\n",
    "    \n",
    "    # 3. Separar en “oraciones” usando signos de puntuación\n",
    "    oraciones = re.split(r'[.!?]+', text)\n",
    "    oraciones = [s.strip() for s in oraciones if s.strip()]\n",
    "    \n",
    "    # 4. Tokenizar palabras y limpiar cada oración\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    corpus_tokens = []\n",
    "    for oracion in oraciones:\n",
    "        # Eliminar números y puntuación dentro de la oración\n",
    "        clean_oracion = re.sub(r'\\d+', ' ', oracion)\n",
    "        clean_oracion = clean_oracion.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        clean_oracion = re.sub(r'\\s+', ' ', clean_oracion).strip()\n",
    "        \n",
    "        # Tokenizar por espacios y eliminar stopwords\n",
    "        tokens = [w for w in clean_oracion.split() if w not in stop_words]\n",
    "        if tokens:\n",
    "            corpus_tokens.append(tokens)\n",
    "    \n",
    "    return corpus_tokens\n",
    "\n",
    "# Aplicar al corpus completo\n",
    "corpus_tokens = preprocesar_texto_por_oracion(corpus)\n",
    "\n",
    "print(\"Cantidad de oraciones tokenizadas:\", len(corpus_tokens))\n",
    "print(\"Ejemplo de primera oración tokenizada:\", corpus_tokens[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5937da",
   "metadata": {},
   "source": [
    "Visualizamos los tokens de las 20 primeras oraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eca8ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'back', 'gared', 'urged', 'woods', 'began', 'grow', 'dark', 'around']\n",
      "['wildlings', 'dead']\n",
      "['dead', 'frighten']\n",
      "['ser', 'waymar', 'royce', 'asked', 'hint', 'smile']\n",
      "['gared', 'rise', 'bait']\n",
      "['old', 'man', 'past', 'fifty', 'seen', 'lordlings', 'come', 'go']\n",
      "['dead', 'dead', 'said']\n",
      "['business', 'dead']\n",
      "['dead']\n",
      "['royce', 'asked', 'softly']\n",
      "['proof']\n",
      "['saw', 'gared', 'said']\n",
      "['says', 'dead', 'thats', 'proof', 'enough']\n",
      "['known', 'would', 'drag', 'quarrel', 'sooner', 'later']\n",
      "['wished', 'later', 'rather', 'sooner']\n",
      "['mother', 'told', 'dead', 'men', 'sing', 'songs', 'put']\n",
      "['wet', 'nurse', 'said', 'thing', 'royce', 'replied']\n",
      "['never', 'believe', 'anything', 'hear', 'womans', 'tit']\n",
      "['things', 'learned', 'even', 'dead']\n",
      "['voice', 'echoed', 'loud', 'twilit', 'forest']\n"
     ]
    }
   ],
   "source": [
    "for token in corpus_tokens[:20]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69959d5d",
   "metadata": {},
   "source": [
    "#### Alternativa: Tokenizar por párrafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55aca1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de párrafos tokenizados: 118164\n",
      "Ejemplo de primer párrafo tokenizado: ['start', 'back', 'gared', 'urged', 'woods', 'began', 'grow', 'dark', 'around', 'wildlings']\n",
      "['start', 'back', 'gared', 'urged', 'woods', 'began', 'grow', 'dark', 'around', 'wildlings']\n",
      "['dead']\n",
      "['dead', 'frighten', 'ser', 'waymar', 'royce', 'asked', 'hint', 'smile']\n",
      "['gared', 'rise', 'bait', 'old', 'man', 'past', 'fifty', 'seen', 'lordlings', 'come', 'go']\n",
      "['dead', 'dead', 'said', 'business', 'dead']\n",
      "['dead', 'royce', 'asked', 'softly', 'proof']\n",
      "['saw', 'gared', 'said', 'says', 'dead', 'thats', 'proof', 'enough']\n",
      "['known', 'would', 'drag', 'quarrel', 'sooner', 'later', 'wished', 'later', 'rather']\n",
      "['sooner', 'mother', 'told', 'dead', 'men', 'sing', 'songs', 'put']\n",
      "['wet', 'nurse', 'said', 'thing', 'royce', 'replied', 'never', 'believe', 'anything', 'hear', 'womans']\n",
      "['tit', 'things', 'learned', 'even', 'dead', 'voice', 'echoed', 'loud', 'twilit', 'forest']\n",
      "['long', 'ride', 'us', 'gared', 'pointed', 'eight', 'days', 'maybe', 'nine', 'night', 'falling']\n",
      "['ser', 'waymar', 'royce', 'glanced', 'sky', 'disinterest', 'every', 'day', 'time']\n",
      "['unmanned', 'dark', 'gared']\n",
      "['could', 'see', 'tightness', 'around', 'gareds', 'mouth', 'barely', 'sup']\n",
      "['pressed', 'anger', 'eyes', 'thick', 'black', 'hood', 'cloak', 'gared', 'spent', 'forty', 'years']\n",
      "['nights', 'watch', 'man', 'boy', 'accustomed', 'made', 'light', 'yet']\n",
      "['wounded', 'pride', 'could', 'sense', 'something', 'else', 'older', 'man', 'could', 'taste']\n",
      "['nervous', 'tension', 'came', 'perilous', 'close', 'fear']\n",
      "['shared', 'unease', 'four', 'years', 'wall', 'first', 'time', 'sent', 'beyond']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocesar_texto_por_parrafo(text):\n",
    "    \"\"\"\n",
    "    Recibe un texto completo y devuelve una lista de párrafos,\n",
    "    cada uno representado como lista de tokens limpios.\n",
    "    \"\"\"\n",
    "    # 1. Pasar a minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Reemplazar caracteres especiales comunes\n",
    "    text = text.replace(\"\\x97\", \" \")  # guion largo\n",
    "    text = text.replace(\"\\x96\", \" \")  # guion corto\n",
    "    text = text.replace(\"\\x91\", \"'\").replace(\"\\x92\", \"'\")  # comillas simples\n",
    "    text = text.replace(\"\\x93\", '\"').replace(\"\\x94\", '\"')  # comillas dobles\n",
    "    # eliminar cualquier otro caracter no ASCII\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    \n",
    "    # 3. Eliminar encabezados no deseados\n",
    "    patterns_to_remove = [\n",
    "        r\"a game of thrones\",\n",
    "        r\"a clash of kings\",\n",
    "        r\"a storm of swords\",\n",
    "        r\"a feast for crows\",\n",
    "        r\"a dance with dragons\",\n",
    "        r\"book [^\\n]+\",\n",
    "        r\"by george r\\. r\\. martin\",\n",
    "        r\"prologue\",\n",
    "        r\"dedication\",\n",
    "        r\"contents\",\n",
    "        r\"a note on chronology\",\n",
    "        r\"a cavil on chronology\",\n",
    "        r\"version history.*\",\n",
    "        r\"page \\d+\",\n",
    "    ]\n",
    "    for pat in patterns_to_remove:\n",
    "        text = re.sub(pat, \" \", text)\n",
    "    \n",
    "    # 4. Separar en párrafos usando saltos de línea\n",
    "    parrafos = text.split(\"\\n\")\n",
    "    parrafos = [p.strip() for p in parrafos if p.strip()]\n",
    "    \n",
    "    # 5. Limpiar cada párrafo y tokenizar\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    corpus_tokens = []\n",
    "    for parrafo in parrafos:\n",
    "        # Eliminar números y puntuación\n",
    "        clean_parrafo = re.sub(r'\\d+', ' ', parrafo)\n",
    "        clean_parrafo = clean_parrafo.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        clean_parrafo = re.sub(r'\\s+', ' ', clean_parrafo).strip()\n",
    "        \n",
    "        # Tokenizar por espacios y eliminar stopwords\n",
    "        tokens = [w for w in clean_parrafo.split() if w not in stop_words]\n",
    "        if tokens:\n",
    "            corpus_tokens.append(tokens)\n",
    "    \n",
    "    return corpus_tokens\n",
    "\n",
    "# Aplicar al corpus completo\n",
    "corpus_tokens_parrafo = preprocesar_texto_por_parrafo(corpus)\n",
    "\n",
    "print(\"Cantidad de párrafos tokenizados:\", len(corpus_tokens_parrafo))\n",
    "print(\"Ejemplo de primer párrafo tokenizado:\", corpus_tokens_parrafo[0])\n",
    "\n",
    "for token in corpus_tokens_parrafo[:20]:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af4889",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos de embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc459b",
   "metadata": {},
   "source": [
    "Agregamos la función de callback vista en clase para informar el loss de cada época:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ff737b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
    "# Sobrecargamos el callback para poder tener esta información\n",
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c80c4d0",
   "metadata": {},
   "source": [
    "Entrenamos dos variantes del modelo, tanto con **CBOW** como con **Skipgram**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b79a32",
   "metadata": {},
   "source": [
    "Si bien en el ejemplo en clase entrenamos embeddings con dimensión 300, dado que observamos que las oraciones son bastante cortas, disminuimos la dimensionalidad del embedding a 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a8714",
   "metadata": {},
   "source": [
    "#### Entrenamiento modelo Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e680951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crearmos el modelo generador de vectores\n",
    "# En este caso utilizaremos la estructura modelo Skipgram\n",
    "w2v_model_sg = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
    "                     window=2,       # cant de palabras antes y desp de la predicha\n",
    "                     vector_size=100,       # dimensionalidad de los vectores \n",
    "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
    "                     workers=5,      # si tienen más cores pueden cambiar este valor\n",
    "                     sg=1)           # modelo 0:CBOW  1:skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcf83470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de docs en el corpus: 155054\n",
      "Cantidad de words distintas en el corpus: 12698\n"
     ]
    }
   ],
   "source": [
    "w2v_model_sg.build_vocab(corpus_tokens)\n",
    "\n",
    "# Cantidad de filas/docs encontradas en el corpus\n",
    "print(\"Cantidad de docs en el corpus:\", w2v_model_sg.corpus_count)\n",
    "\n",
    "# Cantidad de palabras encontradas en el corpus\n",
    "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model_sg.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e536828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 1725810.625\n",
      "Loss after epoch 1: 1232323.875\n",
      "Loss after epoch 2: 1223176.5\n",
      "Loss after epoch 3: 1065123.0\n",
      "Loss after epoch 4: 1036676.0\n",
      "Loss after epoch 5: 1026184.0\n",
      "Loss after epoch 6: 1004914.5\n",
      "Loss after epoch 7: 945857.5\n",
      "Loss after epoch 8: 922068.0\n",
      "Loss after epoch 9: 918790.0\n",
      "Loss after epoch 10: 906584.0\n",
      "Loss after epoch 11: 954038.0\n",
      "Loss after epoch 12: 948284.0\n",
      "Loss after epoch 13: 894251.0\n",
      "Loss after epoch 14: 885068.0\n",
      "Loss after epoch 15: 930106.0\n",
      "Loss after epoch 16: 842389.0\n",
      "Loss after epoch 17: 852884.0\n",
      "Loss after epoch 18: 819894.0\n",
      "Loss after epoch 19: 860406.0\n",
      "Loss after epoch 20: 806098.0\n",
      "Loss after epoch 21: 810690.0\n",
      "Loss after epoch 22: 805436.0\n",
      "Loss after epoch 23: 801724.0\n",
      "Loss after epoch 24: 808186.0\n",
      "Loss after epoch 25: 846264.0\n",
      "Loss after epoch 26: 843656.0\n",
      "Loss after epoch 27: 788542.0\n",
      "Loss after epoch 28: 797570.0\n",
      "Loss after epoch 29: 821972.0\n",
      "Loss after epoch 30: 790580.0\n",
      "Loss after epoch 31: 830174.0\n",
      "Loss after epoch 32: 788958.0\n",
      "Loss after epoch 33: 777992.0\n",
      "Loss after epoch 34: 776360.0\n",
      "Loss after epoch 35: 784540.0\n",
      "Loss after epoch 36: 767534.0\n",
      "Loss after epoch 37: 720448.0\n",
      "Loss after epoch 38: 756528.0\n",
      "Loss after epoch 39: 756888.0\n",
      "Loss after epoch 40: 754136.0\n",
      "Loss after epoch 41: 738652.0\n",
      "Loss after epoch 42: 755828.0\n",
      "Loss after epoch 43: 751472.0\n",
      "Loss after epoch 44: 703172.0\n",
      "Loss after epoch 45: 750756.0\n",
      "Loss after epoch 46: 707484.0\n",
      "Loss after epoch 47: 750184.0\n",
      "Loss after epoch 48: 717240.0\n",
      "Loss after epoch 49: 714556.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(44091381, 47474250)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo generador de vectores\n",
    "# Utilizamos nuestro callback\n",
    "w2v_model_sg.train(corpus_tokens,\n",
    "                 total_examples=w2v_model_sg.corpus_count,\n",
    "                 epochs=50,\n",
    "                 compute_loss = True,\n",
    "                 callbacks=[callback()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e33b7b",
   "metadata": {},
   "source": [
    "#### Entrenamiento modelo CBOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33a41f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_cbow = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
    "                     window=2,       # cant de palabras antes y desp de la predicha\n",
    "                     vector_size=100,       # dimensionalidad de los vectores \n",
    "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
    "                     workers=5,      # si tienen más cores pueden cambiar este valor\n",
    "                     sg=0)           # modelo 0:CBOW  1:skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "205a4d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 830067.125\n",
      "Loss after epoch 1: 649568.75\n",
      "Loss after epoch 2: 561309.875\n",
      "Loss after epoch 3: 515371.75\n",
      "Loss after epoch 4: 500587.75\n",
      "Loss after epoch 5: 472484.0\n",
      "Loss after epoch 6: 468458.75\n",
      "Loss after epoch 7: 424459.0\n",
      "Loss after epoch 8: 395712.5\n",
      "Loss after epoch 9: 406217.5\n",
      "Loss after epoch 10: 401701.0\n",
      "Loss after epoch 11: 386298.5\n",
      "Loss after epoch 12: 384081.5\n",
      "Loss after epoch 13: 379510.5\n",
      "Loss after epoch 14: 398940.5\n",
      "Loss after epoch 15: 393477.0\n",
      "Loss after epoch 16: 371496.0\n",
      "Loss after epoch 17: 369863.0\n",
      "Loss after epoch 18: 381678.0\n",
      "Loss after epoch 19: 371086.0\n",
      "Loss after epoch 20: 351972.0\n",
      "Loss after epoch 21: 376496.0\n",
      "Loss after epoch 22: 382838.0\n",
      "Loss after epoch 23: 362989.0\n",
      "Loss after epoch 24: 370129.0\n",
      "Loss after epoch 25: 368586.0\n",
      "Loss after epoch 26: 359272.0\n",
      "Loss after epoch 27: 364394.0\n",
      "Loss after epoch 28: 353843.0\n",
      "Loss after epoch 29: 373257.0\n",
      "Loss after epoch 30: 364083.0\n",
      "Loss after epoch 31: 353851.0\n",
      "Loss after epoch 32: 360894.0\n",
      "Loss after epoch 33: 360626.0\n",
      "Loss after epoch 34: 360352.0\n",
      "Loss after epoch 35: 358757.0\n",
      "Loss after epoch 36: 351123.0\n",
      "Loss after epoch 37: 354135.0\n",
      "Loss after epoch 38: 362683.0\n",
      "Loss after epoch 39: 355854.0\n",
      "Loss after epoch 40: 344659.0\n",
      "Loss after epoch 41: 292324.0\n",
      "Loss after epoch 42: 253606.0\n",
      "Loss after epoch 43: 252370.0\n",
      "Loss after epoch 44: 245990.0\n",
      "Loss after epoch 45: 248488.0\n",
      "Loss after epoch 46: 249082.0\n",
      "Loss after epoch 47: 254046.0\n",
      "Loss after epoch 48: 246056.0\n",
      "Loss after epoch 49: 246458.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(44090839, 47474250)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_cbow.build_vocab(corpus_tokens)\n",
    "\n",
    "w2v_model_cbow.train(corpus_tokens,\n",
    "                 total_examples=w2v_model_cbow.corpus_count,\n",
    "                 epochs=50,\n",
    "                 compute_loss = True,\n",
    "                 callbacks=[callback()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d1f9c",
   "metadata": {},
   "source": [
    "### Análisis de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97554f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_similares(model, palabra, topn=10, tipo_modelo= \"\"):\n",
    "    \"\"\"\n",
    "    Muestra una tabla con los n más similares (positivos)\n",
    "    y los n menos similares (negativos) a la palabra dada.\n",
    "    \"\"\"\n",
    "    positivos = model.wv.most_similar(positive=[palabra], topn=topn)\n",
    "    negativos = model.wv.most_similar(negative=[palabra], topn=topn)\n",
    "\n",
    "    # Convertir en DataFrames\n",
    "    df_pos = pd.DataFrame(positivos, columns=[\"Positivo\", \"Similitud\"])\n",
    "    df_neg = pd.DataFrame(negativos, columns=[\"Negativo\", \"Similitud\"])\n",
    "\n",
    "    # Combinar lado a lado\n",
    "    tabla = pd.concat([df_pos, df_neg], axis=1)\n",
    "\n",
    "    print(f\"\\nPalabra consultada: {palabra}\\n\")\n",
    "    if tipo_modelo:\n",
    "        print(f\"\\Modelo utilozado: {tipo_modelo}\\n\")\n",
    "    print(tabla.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df8855e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra consultada: tyrion\n",
      "\n",
      "\\Modelo utilozado: Skipgram\n",
      "\n",
      " Positivo  Similitud  Negativo  Similitud\n",
      "   cersei   0.741190   fishing   0.125149\n",
      "    jaime   0.694874 attacking   0.081464\n",
      "    dwarf   0.641970     nests   0.076708\n",
      "crookedly   0.596002     squat   0.059596\n",
      "     dany   0.594187   trained   0.059358\n",
      "    kevan   0.587625   knotted   0.050335\n",
      "  brienne   0.580492   favored   0.043279\n",
      "    sansa   0.576284    mostly   0.037841\n",
      "    varys   0.575842       at   0.033913\n",
      "   alayne   0.572007    dotted   0.030109\n",
      "\n",
      "Palabra consultada: tyrion\n",
      "\n",
      "\\Modelo utilozado: CBOW\n",
      "\n",
      "Positivo  Similitud    Negativo  Similitud\n",
      "   jaime   0.783607      called   0.419913\n",
      "  cersei   0.750971       knows   0.383450\n",
      " brienne   0.730268        the   0.383371\n",
      "    dany   0.692191        plus   0.375646\n",
      "   dwarf   0.674594     sighted   0.373884\n",
      "   sansa   0.614691 accompanied   0.370443\n",
      " catelyn   0.604138     emerged   0.369464\n",
      "     ned   0.597978      driven   0.367199\n",
      "    arya   0.595080        wore   0.358510\n",
      "   griff   0.551301   supported   0.357502\n"
     ]
    }
   ],
   "source": [
    "mostrar_similares(w2v_model_sg, \"tyrion\", 10, \"Skipgram\")\n",
    "mostrar_similares(w2v_model_cbow, \"tyrion\", 10, \"CBOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1efdf998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra consultada: jon\n",
      "\n",
      "\\Modelo utilozado: Skipgram\n",
      "\n",
      "Positivo  Similitud  Negativo  Similitud\n",
      "  qhorin   0.634706     favor   0.072145\n",
      "    jon   0.627027   sceptre   0.070472\n",
      " catelyn   0.622429 stiffened   0.055806\n",
      "    bran   0.602437    repute   0.046927\n",
      "     ned   0.596018     plays   0.046914\n",
      " ygritte   0.590014     scrub   0.032574\n",
      "     sam   0.585840 courtiers   0.031462\n",
      "     ion   0.574884   pillars   0.029485\n",
      "     fon   0.562981     bends   0.026725\n",
      "   mance   0.558799    nailed   0.025407\n",
      "\n",
      "Palabra consultada: jon\n",
      "\n",
      "\\Modelo utilozado: CBOW\n",
      "\n",
      "Positivo  Similitud    Negativo  Similitud\n",
      "    bran   0.661791     quailed   0.433029\n",
      "     sam   0.635791    nobility   0.432746\n",
      " catelyn   0.615853  mistrusted   0.394515\n",
      "   davos   0.614937 accompanied   0.394212\n",
      "   theon   0.587482    infantry   0.385418\n",
      "     ned   0.571846     planted   0.380035\n",
      "     ion   0.567229      hefted   0.376840\n",
      "    arya   0.566378       stews   0.375331\n",
      "    dany   0.544259     gliding   0.373697\n",
      " brienne   0.536006      nailed   0.371898\n"
     ]
    }
   ],
   "source": [
    "mostrar_similares(w2v_model_sg, \"jon\", 10, \"Skipgram\")\n",
    "mostrar_similares(w2v_model_cbow, \"jon\", 10, \"CBOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cf1ff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra consultada: jaime\n",
      "\n",
      "\\Modelo utilozado: Skipgram\n",
      "\n",
      "Positivo  Similitud Negativo  Similitud\n",
      "  tyrion   0.694874  fishing   0.121288\n",
      "  cersei   0.679603   dotted   0.075399\n",
      "   kevan   0.611098    patch   0.037903\n",
      "   sansa   0.600463      at   0.033800\n",
      " brienne   0.593470     toys   0.033699\n",
      " catelyn   0.572049    beams   0.033441\n",
      "   loras   0.563172     pole   0.033418\n",
      "   daven   0.559101   maids   0.031080\n",
      "    dany   0.549354     oval   0.030966\n",
      "  lancel   0.548754 longhall   0.028478\n",
      "\n",
      "Palabra consultada: jaime\n",
      "\n",
      "\\Modelo utilozado: CBOW\n",
      "\n",
      "Positivo  Similitud  Negativo  Similitud\n",
      "  tyrion   0.783607    dotted   0.415130\n",
      "  cersei   0.734387 consigned   0.388718\n",
      "   kevan   0.712490 dispersed   0.383931\n",
      " brienne   0.622864    soared   0.380317\n",
      " catelyn   0.598228     woven   0.374453\n",
      "   sansa   0.570295     draws   0.366896\n",
      "     ned   0.551906  anchored   0.362752\n",
      "   tywin   0.551361    enters   0.361224\n",
      "   cleos   0.548854      the   0.361205\n",
      "  lancel   0.542193  wreckage   0.350539\n"
     ]
    }
   ],
   "source": [
    "mostrar_similares(w2v_model_sg, \"jaime\", 10, \"Skipgram\")\n",
    "mostrar_similares(w2v_model_cbow, \"jaime\", 10, \"CBOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96e37366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra consultada: daenerys\n",
      "\n",
      "\\Modelo utilozado: Skipgram\n",
      "\n",
      "   Positivo  Similitud    Negativo  Similitud\n",
      "  stormborn   0.680650      smiths   0.152044\n",
      "    unburnt   0.623447       ankle   0.076069\n",
      "  targaryen   0.586436      tugged   0.076065\n",
      "    viserys   0.528879    crackled   0.070229\n",
      "   khaleesi   0.526044       broom   0.065783\n",
      "     aegon   0.522682 cleanshaven   0.063186\n",
      "sunandstars   0.519439  everywhere   0.059365\n",
      "  consented   0.505674     blocked   0.059033\n",
      "      queen   0.503939        luke   0.056934\n",
      "     sweet   0.490403       store   0.056267\n",
      "\n",
      "Palabra consultada: daenerys\n",
      "\n",
      "\\Modelo utilozado: CBOW\n",
      "\n",
      " Positivo  Similitud   Negativo  Similitud\n",
      "    aerys   0.471588    blocked   0.412596\n",
      "  viserys   0.467510    archery   0.393226\n",
      "    queen   0.461241      pikes   0.356539\n",
      "     dany   0.457213      round   0.350911\n",
      "       ii   0.455923     showed   0.340260\n",
      "   aegon   0.454993       hose   0.339790\n",
      "   cersei   0.453849     smithy   0.338736\n",
      "stormborn   0.433189     hacked   0.338337\n",
      "   tyrion   0.432342   squinted   0.334832\n",
      "  dynasty   0.432059 splintered   0.330908\n"
     ]
    }
   ],
   "source": [
    "mostrar_similares(w2v_model_sg, \"daenerys\", 10, \"Skipgram\")\n",
    "mostrar_similares(w2v_model_cbow, \"daenerys\", 10, \"CBOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f97418bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra consultada: stark\n",
      "\n",
      "\\Modelo utilozado: Skipgram\n",
      "\n",
      "  Positivo  Similitud  Negativo  Similitud\n",
      "   starks   0.674530  unwashed   0.066877\n",
      "    starks   0.668352  overseer   0.062107\n",
      "    eddard   0.649646 sharpened   0.058771\n",
      "      robb   0.592073   hopping   0.058646\n",
      "  eddards   0.589543    onions   0.055465\n",
      "     tully   0.546825    coarse   0.051253\n",
      "winterfell   0.536577    popped   0.048029\n",
      "  leobalds   0.520321     manse   0.047801\n",
      "     daryn   0.514446   barrels   0.043414\n",
      "   cassana   0.505951   puppies   0.037317\n",
      "\n",
      "Palabra consultada: stark\n",
      "\n",
      "\\Modelo utilozado: CBOW\n",
      "\n",
      "   Positivo  Similitud      Negativo  Similitud\n",
      "     starks   0.689264       grasses   0.449166\n",
      "    starks   0.635930       firepit   0.440947\n",
      "      tully   0.501797     scrabbled   0.399156\n",
      "     father   0.467121          coil   0.392945\n",
      "   karstark   0.456764 diamondshaped   0.392163\n",
      " winterfell   0.453886      hawthorn   0.390141\n",
      "grandfather   0.450694     mushrooms   0.389273\n",
      "    greyjoy   0.442022        pewter   0.375700\n",
      "     robert   0.438168           dew   0.373871\n",
      "     lyanna   0.432060       incense   0.372436\n"
     ]
    }
   ],
   "source": [
    "mostrar_similares(w2v_model_sg, \"stark\", 10, \"Skipgram\")\n",
    "mostrar_similares(w2v_model_cbow, \"stark\", 10, \"CBOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13e1d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra consultada: dragon\n",
      "\n",
      "\\Modelo utilozado: Skipgram\n",
      "\n",
      "   Positivo  Similitud  Negativo  Similitud\n",
      "threeheaded   0.623594 greyfaced   0.096935\n",
      "    dragons   0.570713     mudge   0.091785\n",
      "     drogon   0.564024   service   0.086874\n",
      "   dragons   0.547834   chances   0.081100\n",
      "    dynasty   0.525226      slip   0.071666\n",
      "     aegon   0.508702 manatarms   0.069938\n",
      "    visenya   0.507552     brune   0.067433\n",
      "  stormborn   0.505543  mornings   0.065012\n",
      "    viserys   0.498209 wandering   0.064896\n",
      "      aegon   0.497900     rhyme   0.063901\n",
      "\n",
      "Palabra consultada: dragon\n",
      "\n",
      "\\Modelo utilozado: CBOW\n",
      "\n",
      " Positivo  Similitud   Negativo  Similitud\n",
      "  dragons   0.546968   terrance   0.403854\n",
      "conqueror   0.436736    scowled   0.396557\n",
      " dragons   0.420863      lord   0.379978\n",
      "    bitch   0.415827    stouts   0.372693\n",
      "   drogon   0.411245 softspoken   0.366340\n",
      "    lions   0.400173     chided   0.364933\n",
      "targaryen   0.395804 complaints   0.363622\n",
      "     fire   0.393629   subsided   0.355576\n",
      "  meraxes   0.391300     behead   0.346377\n",
      " balerion   0.381832   reddened   0.341473\n"
     ]
    }
   ],
   "source": [
    "mostrar_similares(w2v_model_sg, \"dragon\", 10, \"Skipgram\")\n",
    "mostrar_similares(w2v_model_cbow, \"dragon\", 10, \"CBOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b01479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra consultada: throne\n",
      "\n",
      "\\Modelo utilozado: Skipgram\n",
      "\n",
      "  Positivo  Similitud  Negativo  Similitud\n",
      "      iron   0.556011  messages   0.109514\n",
      "     chair   0.549967      pies   0.106188\n",
      "     crown   0.528103    popped   0.105961\n",
      "   derives   0.515011    emrick   0.100937\n",
      "rightfully   0.501939 feathered   0.083466\n",
      "  rightful   0.500867    pepper   0.082216\n",
      "     hinge   0.499716     dream   0.078566\n",
      "birthright   0.495223     gruff   0.069395\n",
      "        ii   0.488736      bill   0.065157\n",
      "  proclaim   0.486143    rolled   0.060728\n",
      "\n",
      "Palabra consultada: throne\n",
      "\n",
      "\\Modelo utilozado: CBOW\n",
      "\n",
      "  Positivo  Similitud      Negativo  Similitud\n",
      "     crown   0.507749        combed   0.368167\n",
      "     chair   0.483957     stammered   0.364914\n",
      "   victory   0.463250       should   0.362063\n",
      "   thrones   0.454978 understanding   0.353198\n",
      "      seat   0.442675       puffing   0.351534\n",
      "      holt   0.427063       teasing   0.343023\n",
      "birthright   0.414824         piney   0.342458\n",
      "   sconces   0.414757       weaving   0.339620\n",
      "     studs   0.414285       buttery   0.338957\n",
      "    spikes   0.406449        chided   0.333530\n"
     ]
    }
   ],
   "source": [
    "mostrar_similares(w2v_model_sg, \"throne\", 10, \"Skipgram\")\n",
    "mostrar_similares(w2v_model_cbow, \"throne\", 10, \"CBOW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f454e2b",
   "metadata": {},
   "source": [
    "### Visualizar agrupación de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f871149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    \n",
    "from sklearn.manifold import TSNE                   \n",
    "import numpy as np                                  \n",
    "\n",
    "def reduce_dimensions(model, num_dimensions = 2 ):\n",
    "     \n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  \n",
    "\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    return vectors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7074804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"82aeb81b-4074-4967-8de2-eb519c4cbfdb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"82aeb81b-4074-4967-8de2-eb519c4cbfdb\")) {                    Plotly.newPlot(                        \"82aeb81b-4074-4967-8de2-eb519c4cbfdb\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"\\u0094\",\"said\",\"lord\",\"would\",\"one\",\"ser\",\"could\",\"man\",\"back\",\"men\",\"well\",\"like\",\"jon\",\"old\",\"even\",\"hand\",\"never\",\"king\",\"know\",\"see\",\"made\",\"tyrion\",\"eyes\",\"told\",\"thought\",\"black\",\"time\",\"long\",\"lady\",\"might\",\"us\",\"come\",\"father\",\"still\",\"face\",\"head\",\"way\",\"must\",\"red\",\"boy\",\"little\",\"took\",\"came\",\"good\",\"two\",\"\\u0093i\",\"though\",\"say\",\"away\",\"brother\",\"dead\",\"take\",\"son\",\"blood\",\"make\",\"go\",\"saw\",\"queen\",\"arya\",\"three\",\"first\",\"day\",\"want\",\"night\",\"look\",\"much\",\"enough\",\"white\",\"looked\",\"sword\",\"jaime\",\"knew\",\"asked\",\"gave\",\"great\",\"called\",\"left\",\"tell\",\"every\",\"girl\",\"heard\",\"went\",\"turned\",\"need\",\"behind\",\"yet\",\"wall\",\"bran\",\"around\",\"half\",\"dany\",\"beneath\",\"across\",\"another\",\"sansa\",\"let\",\"maester\",\"found\",\"keep\",\"last\",\"hands\",\"gods\",\"knight\",\"think\",\"snow\",\"feet\",\"hair\",\"castle\",\"woman\",\"many\",\"grace\",\"gold\",\"seemed\",\"cersei\",\"ever\",\"stannis\",\"stark\",\"\\u0093the\",\"may\",\"kings\",\"find\",\"done\",\"catelyn\",\"hear\",\"name\",\"lannister\",\"put\",\"prince\",\"upon\",\"stone\",\"high\",\"wine\",\"water\",\"horse\",\"voice\",\"fire\",\"gone\",\"iron\",\"hard\",\"robb\",\"seen\",\"always\",\"years\",\"better\",\"give\",\"shall\",\"place\",\"mother\",\"dark\",\"small\",\"grey\",\"stood\",\"cold\",\"end\",\"hundred\",\"sam\",\"ned\",\"robert\",\"words\",\"right\",\"winterfell\",\"brothers\",\"walls\",\"nothing\",\"fingers\",\"cloak\",\"beside\",\"house\",\"\\u0093you\",\"sea\",\"young\",\"mouth\",\"door\",\"watch\",\"get\",\"sent\",\"big\",\"wanted\",\"almost\",\"sister\",\"others\",\"true\",\"leave\",\"lost\",\"felt\",\"perhaps\",\"light\",\"wind\",\"city\",\"dont\",\"daughter\",\"seven\",\"sweet\",\"children\",\"side\",\"ill\",\"brought\",\"lords\",\"green\",\"died\"],\"x\":{\"dtype\":\"f4\",\"bdata\":\"Jhk3wMJvisBBEotAxgECwXMss772IVtBML2twLnNM743n0hA5XVDwZBfo8DeQbQ\\u002fBhs6QRxxcb6Z4ITAKJVRQa2rusApXJ3ByuLWwBx10cCBDRrAF8aMwdWhgUGhmJzAPbzWwHD8FUH7wIrAxLiBwOT8u0BNaOrAVjI4wdznH8GW8iLB\\u002faN6wCHQiEHG\\u002fx9B1gmvwKluJMFCwbBBEJOqQCh0IcD2D1jBWuufPzcOE8B8vWTBhtTlwEFZdMDcEvbAq+hFQP5Uo0BUTcG\\u002fHXNVwdYsIkE4TkJBRTQgwPoGJMEggRo\\u002f3+JFQIqpm8GYUGnB9mmmwDstt8AXCCHB+niywOmChkCndpDAsXluwMGcs0FYUY1AKqrMQRVfjME9MsTAPbCUwG\\u002f+bcFIGo9AIZCnwF4stz+Q4vXA3NMzv\\u002foAtUA57Ku+3DKGQIZa0EAUxyfBQpMzv2Ptg8C\\u002fI4E9\\u002fKmmwWK4Kb\\u002fYsLq\\u002fvY\\u002fRwZn1JkHas4TAoqRuv8VllsFktDTBMthTQUT3p74S4hDBvxylwPQyUkH+qLzBc0IsQWDG8cDA7FvAFkS4QA3NqkGzDjHBVfF8vhnuccHLUvDAzGwEQsr3acDvaIzBlgW2wLTco8Hbe5nBN1R1v5ZHIsFaG7fBw69Iwa0J7sBJf5jBnr+5vhkOQcHZwI3BROepQPNJJkCB66K+8fsEv19lLUFh9M5BYxPCQGPnjcCZrzRA361OQR8tt78QLt1AR6AsQWyEm8EyGgI\\u002fDp5iwF1wrMAtTaXAho1ewTrAJMGE5q3AsrSLQOSAEUGtn03B9ZayQcuVBT9qY4FByWpIwccqdMGoQkdB+cSXwVj+nsF7BStAg34NQBCKn8F7IKpAgOQOvQvcqcB471lBzj\\u002fvQTsor77BYANBV6niwKVf8sAhWutAlP6BQZzk70C1OsHBJfMCwdrDa8HfZJ5AGZYdwa+VKj8C\\u002fJVA7I4uwejmtcB73ynBsW7qwKqkPkH1fdfA5L5LQZ9+HkFicqHBIBIMwBtuE0E4RWjBkzvtQJqJUMEo26++UeI2wHx5aMGlzixBDt3BQRc8h8E=\"},\"xaxis\":\"x\",\"y\":{\"dtype\":\"f4\",\"bdata\":\"XaCGQR7paEGWFkxBkTCKQBaAA8BfU+BBAmFxQLvqjr19stvA4jwVwY6bxz7zIi3AWOQeQda7EEBFkUw\\u002fcWBkwP91GkDJ+A5BNW\\u002fRQHs7nj+7O1tASTptQb+\\u002fvD7lDlhBsKc0QK14rsGhZqnA6r9Zvm0uokFnbYFAjVNwQO8MFMAX9KNAUB3sPggG3b9kxUTAqbMDwSos5kC6ozfBm3CAQb7\\u002fED\\u002fWAjFAD1sGwYGRkUBzTj7B1StZQcJ3wT+RP\\u002fBAk1jcwDLOZUFRTpnA+RlPQEgPv0E4f2S\\u002fA0FgQC9qDMDjp67A7IuSQQA6fkG\\u002fKkHB77BwwHx+tsAmnwNB4x+8wOPkLMD03xpAPD1nQJP5JcFTrTDAI6yQQFOBbEH4BWVAO7pxQQJso0A7WKHBAfK\\u002fQar+r8BVd9lAkn4dwJqHhEHH2z3Bvh3qwJUtlcB5YgVB+XZZwRPFrD+3OaXBWX6EQb5MYsEtGCnAxeh9QY4U0sH\\u002fP4zBPAcewPHFgEE\\u002fAwxBwFNeQVljvcBoiPK\\u002fyzN5wHu3YMCMzJtA9o0+QZkCukDu4RPB3x39wDM\\u002fssBasmfBGoAePjETM8EDi0JBeNsBwJQeFUD7NGxBYoQVQFYjIkGKYpJBg0o7QWlt5EAk1\\u002ftAni90QMxxgj+qUIJBAl09wbpMykEutGJBUdIhwEUCxUHOfoHAUh\\u002fWwXLmeUEoAIfBby+4wVOwYMEee\\u002fpAsVGcwcPFqsC7BGTBMT4iwUURj0FZ5qHArnscQCCokcDeaxxAhvaLQA796UALaiTAE5qcQQWursG7897BWcwkwW5u88C1\\u002fJXBrBrBwAISScEV0yJBn6GEQQECJkE4BPlAIPaYwANSl0EijV9BnnSnwQ8r8T\\u002f\\u002fZmLA\\u002fyChwMB0i8EXWKhBGv1XQbEPncGjmYNBvOrlv5AUf8FXLpS\\u002fvTagv0GEdkBb26LBsaL9QH1NeMAzqZtBzhUYwdZ6v0BEVUrAd6ArPwwersDNRvw\\u002f4JvUwaXumcHBq0vBO9\\u002fIQalTpkGt1JFBKvnwQNfIDcHSrIvB7kjKQTP3dkBo\\u002f0pBOEAmwXYeq0E=\"},\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('82aeb81b-4074-4967-8de2-eb519c4cbfdb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los embedddings en 2D\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "vecs, labels = reduce_dimensions(w2v_model_sg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00ed626a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"1e9246ee-ec27-47d0-9880-75f6cbb14aaf\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"1e9246ee-ec27-47d0-9880-75f6cbb14aaf\")) {                    Plotly.newPlot(                        \"1e9246ee-ec27-47d0-9880-75f6cbb14aaf\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"\\u0094\",\"said\",\"lord\",\"would\",\"one\",\"ser\",\"could\",\"man\",\"back\",\"men\",\"well\",\"like\",\"jon\",\"old\",\"even\",\"hand\",\"never\",\"king\",\"know\",\"see\",\"made\",\"tyrion\",\"eyes\",\"told\",\"thought\",\"black\",\"time\",\"long\",\"lady\",\"might\",\"us\",\"come\",\"father\",\"still\",\"face\",\"head\",\"way\",\"must\",\"red\",\"boy\",\"little\",\"took\",\"came\",\"good\",\"two\",\"\\u0093i\",\"though\",\"say\",\"away\",\"brother\",\"dead\",\"take\",\"son\",\"blood\",\"make\",\"go\",\"saw\",\"queen\",\"arya\",\"three\",\"first\",\"day\",\"want\",\"night\",\"look\",\"much\",\"enough\",\"white\",\"looked\",\"sword\",\"jaime\",\"knew\",\"asked\",\"gave\",\"great\",\"called\",\"left\",\"tell\",\"every\",\"girl\",\"heard\",\"went\",\"turned\",\"need\",\"behind\",\"yet\",\"wall\",\"bran\",\"around\",\"half\",\"dany\",\"beneath\",\"across\",\"another\",\"sansa\",\"let\",\"maester\",\"found\",\"keep\",\"last\",\"hands\",\"gods\",\"knight\",\"think\",\"snow\",\"feet\",\"hair\",\"castle\",\"woman\",\"many\",\"grace\",\"gold\",\"seemed\",\"cersei\",\"ever\",\"stannis\",\"stark\",\"\\u0093the\",\"may\",\"kings\",\"find\",\"done\",\"catelyn\",\"hear\",\"name\",\"lannister\",\"put\",\"prince\",\"upon\",\"stone\",\"high\",\"wine\",\"water\",\"horse\",\"voice\",\"fire\",\"gone\",\"iron\",\"hard\",\"robb\",\"seen\",\"always\",\"years\",\"better\",\"give\",\"shall\",\"place\",\"mother\",\"dark\",\"small\",\"grey\",\"stood\",\"cold\",\"end\",\"hundred\",\"sam\",\"ned\",\"robert\",\"words\",\"right\",\"winterfell\",\"brothers\",\"walls\",\"nothing\",\"fingers\",\"cloak\",\"beside\",\"house\",\"\\u0093you\",\"sea\",\"young\",\"mouth\",\"door\",\"watch\",\"get\",\"sent\",\"big\",\"wanted\",\"almost\",\"sister\",\"others\",\"true\",\"leave\",\"lost\",\"felt\",\"perhaps\",\"light\",\"wind\",\"city\",\"dont\",\"daughter\",\"seven\",\"sweet\",\"children\",\"side\",\"ill\",\"brought\",\"lords\",\"green\",\"died\"],\"x\":{\"dtype\":\"f4\",\"bdata\":\"Jhk3wMJvisBBEotAxgECwXMss772IVtBML2twLnNM743n0hA5XVDwZBfo8DeQbQ\\u002fBhs6QRxxcb6Z4ITAKJVRQa2rusApXJ3ByuLWwBx10cCBDRrAF8aMwdWhgUGhmJzAPbzWwHD8FUH7wIrAxLiBwOT8u0BNaOrAVjI4wdznH8GW8iLB\\u002faN6wCHQiEHG\\u002fx9B1gmvwKluJMFCwbBBEJOqQCh0IcD2D1jBWuufPzcOE8B8vWTBhtTlwEFZdMDcEvbAq+hFQP5Uo0BUTcG\\u002fHXNVwdYsIkE4TkJBRTQgwPoGJMEggRo\\u002f3+JFQIqpm8GYUGnB9mmmwDstt8AXCCHB+niywOmChkCndpDAsXluwMGcs0FYUY1AKqrMQRVfjME9MsTAPbCUwG\\u002f+bcFIGo9AIZCnwF4stz+Q4vXA3NMzv\\u002foAtUA57Ku+3DKGQIZa0EAUxyfBQpMzv2Ptg8C\\u002fI4E9\\u002fKmmwWK4Kb\\u002fYsLq\\u002fvY\\u002fRwZn1JkHas4TAoqRuv8VllsFktDTBMthTQUT3p74S4hDBvxylwPQyUkH+qLzBc0IsQWDG8cDA7FvAFkS4QA3NqkGzDjHBVfF8vhnuccHLUvDAzGwEQsr3acDvaIzBlgW2wLTco8Hbe5nBN1R1v5ZHIsFaG7fBw69Iwa0J7sBJf5jBnr+5vhkOQcHZwI3BROepQPNJJkCB66K+8fsEv19lLUFh9M5BYxPCQGPnjcCZrzRA361OQR8tt78QLt1AR6AsQWyEm8EyGgI\\u002fDp5iwF1wrMAtTaXAho1ewTrAJMGE5q3AsrSLQOSAEUGtn03B9ZayQcuVBT9qY4FByWpIwccqdMGoQkdB+cSXwVj+nsF7BStAg34NQBCKn8F7IKpAgOQOvQvcqcB471lBzj\\u002fvQTsor77BYANBV6niwKVf8sAhWutAlP6BQZzk70C1OsHBJfMCwdrDa8HfZJ5AGZYdwa+VKj8C\\u002fJVA7I4uwejmtcB73ynBsW7qwKqkPkH1fdfA5L5LQZ9+HkFicqHBIBIMwBtuE0E4RWjBkzvtQJqJUMEo26++UeI2wHx5aMGlzixBDt3BQRc8h8E=\"},\"xaxis\":\"x\",\"y\":{\"dtype\":\"f4\",\"bdata\":\"XaCGQR7paEGWFkxBkTCKQBaAA8BfU+BBAmFxQLvqjr19stvA4jwVwY6bxz7zIi3AWOQeQda7EEBFkUw\\u002fcWBkwP91GkDJ+A5BNW\\u002fRQHs7nj+7O1tASTptQb+\\u002fvD7lDlhBsKc0QK14rsGhZqnA6r9Zvm0uokFnbYFAjVNwQO8MFMAX9KNAUB3sPggG3b9kxUTAqbMDwSos5kC6ozfBm3CAQb7\\u002fED\\u002fWAjFAD1sGwYGRkUBzTj7B1StZQcJ3wT+RP\\u002fBAk1jcwDLOZUFRTpnA+RlPQEgPv0E4f2S\\u002fA0FgQC9qDMDjp67A7IuSQQA6fkG\\u002fKkHB77BwwHx+tsAmnwNB4x+8wOPkLMD03xpAPD1nQJP5JcFTrTDAI6yQQFOBbEH4BWVAO7pxQQJso0A7WKHBAfK\\u002fQar+r8BVd9lAkn4dwJqHhEHH2z3Bvh3qwJUtlcB5YgVB+XZZwRPFrD+3OaXBWX6EQb5MYsEtGCnAxeh9QY4U0sH\\u002fP4zBPAcewPHFgEE\\u002fAwxBwFNeQVljvcBoiPK\\u002fyzN5wHu3YMCMzJtA9o0+QZkCukDu4RPB3x39wDM\\u002fssBasmfBGoAePjETM8EDi0JBeNsBwJQeFUD7NGxBYoQVQFYjIkGKYpJBg0o7QWlt5EAk1\\u002ftAni90QMxxgj+qUIJBAl09wbpMykEutGJBUdIhwEUCxUHOfoHAUh\\u002fWwXLmeUEoAIfBby+4wVOwYMEee\\u002fpAsVGcwcPFqsC7BGTBMT4iwUURj0FZ5qHArnscQCCokcDeaxxAhvaLQA796UALaiTAE5qcQQWursG7897BWcwkwW5u88C1\\u002fJXBrBrBwAISScEV0yJBn6GEQQECJkE4BPlAIPaYwANSl0EijV9BnnSnwQ8r8T\\u002f\\u002fZmLA\\u002fyChwMB0i8EXWKhBGv1XQbEPncGjmYNBvOrlv5AUf8FXLpS\\u002fvTagv0GEdkBb26LBsaL9QH1NeMAzqZtBzhUYwdZ6v0BEVUrAd6ArPwwersDNRvw\\u002f4JvUwaXumcHBq0vBO9\\u002fIQalTpkGt1JFBKvnwQNfIDcHSrIvB7kjKQTP3dkBo\\u002f0pBOEAmwXYeq0E=\"},\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1e9246ee-ec27-47d0-9880-75f6cbb14aaf');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_WORDS=200\n",
    "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
    "fig.show(renderer=\"colab\") # esto para plotly en colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15a47f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_3d, labels_3d = reduce_dimensions(w2v_model_sg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c622bb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"0d4de1fa-c558-4687-9f96-68f10abe64f6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"0d4de1fa-c558-4687-9f96-68f10abe64f6\")) {                    Plotly.newPlot(                        \"0d4de1fa-c558-4687-9f96-68f10abe64f6\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"size\":2},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"\\u0094\",\"said\",\"lord\",\"would\",\"one\",\"ser\",\"could\",\"man\",\"back\",\"men\",\"well\",\"like\",\"jon\",\"old\",\"even\",\"hand\",\"never\",\"king\",\"know\",\"see\",\"made\",\"tyrion\",\"eyes\",\"told\",\"thought\",\"black\",\"time\",\"long\",\"lady\",\"might\",\"us\",\"come\",\"father\",\"still\",\"face\",\"head\",\"way\",\"must\",\"red\",\"boy\",\"little\",\"took\",\"came\",\"good\",\"two\",\"\\u0093i\",\"though\",\"say\",\"away\",\"brother\",\"dead\",\"take\",\"son\",\"blood\",\"make\",\"go\",\"saw\",\"queen\",\"arya\",\"three\",\"first\",\"day\",\"want\",\"night\",\"look\",\"much\",\"enough\",\"white\",\"looked\",\"sword\",\"jaime\",\"knew\",\"asked\",\"gave\",\"great\",\"called\",\"left\",\"tell\",\"every\",\"girl\",\"heard\",\"went\",\"turned\",\"need\",\"behind\",\"yet\",\"wall\",\"bran\",\"around\",\"half\",\"dany\",\"beneath\",\"across\",\"another\",\"sansa\",\"let\",\"maester\",\"found\",\"keep\",\"last\",\"hands\",\"gods\",\"knight\",\"think\",\"snow\",\"feet\",\"hair\",\"castle\",\"woman\",\"many\",\"grace\",\"gold\",\"seemed\",\"cersei\",\"ever\",\"stannis\",\"stark\",\"\\u0093the\",\"may\",\"kings\",\"find\",\"done\",\"catelyn\",\"hear\",\"name\",\"lannister\",\"put\",\"prince\",\"upon\",\"stone\",\"high\",\"wine\",\"water\",\"horse\",\"voice\",\"fire\",\"gone\",\"iron\",\"hard\",\"robb\",\"seen\",\"always\",\"years\",\"better\",\"give\",\"shall\",\"place\",\"mother\",\"dark\",\"small\",\"grey\",\"stood\",\"cold\",\"end\",\"hundred\",\"sam\",\"ned\",\"robert\",\"words\",\"right\",\"winterfell\",\"brothers\",\"walls\",\"nothing\",\"fingers\",\"cloak\",\"beside\",\"house\",\"\\u0093you\",\"sea\",\"young\",\"mouth\",\"door\",\"watch\",\"get\",\"sent\",\"big\",\"wanted\",\"almost\",\"sister\",\"others\",\"true\",\"leave\",\"lost\",\"felt\",\"perhaps\",\"light\",\"wind\",\"city\",\"dont\",\"daughter\",\"seven\",\"sweet\",\"children\",\"side\",\"ill\",\"brought\",\"lords\",\"green\",\"died\"],\"x\":{\"dtype\":\"f4\",\"bdata\":\"oadGwdx7AcI7lyBB6p26wbMRa8GH5ONB8J+tQRN5RcESJG\\u002fBf+XlwVQdAsQFmJ3B2O0BQYbeO8GciYrB7gGQwLTYjMFkFwlB+4jewYSFpcGLz2DBOaSpQW9GLkKRpbLBrl6XQPUSyUFeyG7BBr8XwumPD0KPKPnB9MF0wWR90sGgzQ5BYxHYwXINJkJ2dDjBs2dwwe+\\u002fCsJLfQlCvRLBwEYmbcJLSP\\u002fBpxxLwTWwycHNTCTCm85FwZBkisMD4pTBm\\u002flawYimREF2JUPCk1HgweqbiEGMZQ5C\\u002f8FPweyczsHLlqbBp9nVQG8YtkEZxCbCtBW5wRl9dcGlRgLCL1tHwaRkq0FWShjCRkSBwM8990GarLhBX3MTwS1BnUGpt8\\u002fBafoxQuVOgsHzaAzC2FpAwg8U1MHWOK3BbENVwkmH3MD00IFC1Of6wBl0nEG3ffnBE0uOwfGNL0OKaIjBhWBYQZ29ikFbDDTC6sarwY2FsEE+5qDBlhVBwonbsUHo0OjBOQAHQqTsg8F92trBSF2qwfOsqcDOuBfCL24owCyS0MHHSDZBL1oFwFeIF0KHrI3BQw0ywRHmN8LOgZnA0H9PQpLYe0EKA6NBJf6awbOmY0EWvwFCH4BvQmSqA8J+dCRAe9TEwS5728GmcsdB8yaCQkHkgsLYFnhB5DOswYvyo0GjdybCC466wEPBEEKyo2JC\\u002fjUSQWZb3z9eaCdCPt2DQVrhIcHxlZO\\u002feqcrQZQwAELpd5\\u002fBV3egwSzVrsFAOOXB1zipwfA3AsL8AADCQHSdQF4yrkEo9PrBviPhQf5IG8Hu1VZC99DWwcw2MMKmgzZB93rbQZNZaUGzYTBCeN6twbXtDUJMVllBCMRxwZ4fOsKPSqLAB3xDQm60asHbR2BBl6FHwdUd6r50S9jBNrwkQo2dv8DZh\\u002fI\\u002fmbLRwfyE3cEympbBvPgHwkmtksFyewNBhv3XwakNYsG9EQPCbLTywUYZckG17YzBxhVpQnxsH0Ls59vBbAENwvMdDkFb8zPCl25Lv2fDCcKXda3B1UkFwqVH4cE10TpBCKgvQovZHMI=\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"D\\u002fk7QuelZsGHISdClgKcQQpVlEBsTwZC+Sj8wRB9L0Gnu6HBB2hiwYtACcLBJnDBfhiOQJPGmsD7bRtBIPSswUc3ZkHjqiFC0cLDQfUc2cBxnR5Brt32Qcl7jj\\u002f\\u002fabdBNNs9QZgsbcEPEc\\u002fACbiOwTG3wUHyPQxChBAGQjQBlT\\u002fOJfxBxHpewcuVyL8E4lfBgZRpwTUIF0LyjabB1C1VQTBLcEDLPZpAtTeMwfsx0UHpuMXBHvNnQpdk2cNUlt9BNhqfwSbZ2kE\\u002f0gbB+Fu8QIsYE0IZbwrAKUQRQUiMJj\\u002fsli7Bd9A6QjHjzUGE1cPBWgy9v9yzv8Ce\\u002fRFCOcO9wPF0GECW0rZBxzMyQZaqkcH3BdQ\\u002fQngSwq9T9EHO8WZBA46MQRVN10FzifnB9VjwQXt5pMFHmrdBxNZuwb40YUGsp2HATH5+wW5K28BFexBCTczpwetkaUJHizTCrXlaQUnd+8GTFK7BNqj0QCXtIsKrZd3BMoJawVMW3kH4BR5CiHpbQWhnLMGAkTbBBlj\\u002fv9cCu8Fl0BRCeVJSQGn7oUGFI2A\\u002fggJvwbrQsMHTvK3Bu8JMQfqCnMFdXT5CDkv2wSziLUGJeANCb+NbQVr6KUKUCgdCkFMNQmm2FULFABFCWkZbQRkVmkDo2eNBVv8DwHXeXEEPrgBCFoprwd3TKkIGr\\u002fTAOoB5wj6KTkIG8sA\\u002femANwojNosH\\u002frTBC1fzXwRZ+UsE2MQLC\\u002fjlHwXkr7EE1BTjBIUxFQf7JEMG+OrVBj6lMQSnuHkLEVevAE6TTQeZDVME7gRDC236PwSEcnsGCcCbAldXiwAEHz8E21VdA9KvsQbiXHELMJzJCFXDLwSw6\\u002fEHukcRB4ck7wrmqrEE+D53Bb5A3wnguAMKvJcpBdNNeQntmA8LLdpRBH7TCv6b5C8KzgwHBcJTSv2cVakGSvlTCr5EXQqfg17+7J+1BgRpfwTIXO0KVeSW\\u002fyg6RQNlJsEDkvktBw8sAwoRtdcFDwZXBaT1BQq+gwkGGBTVBRVzJQRW8lz\\u002fjh9XB1nUxQtyFR0GM7x5CevAbwlQTUEE=\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"Abn4QdNMgcCdLx\\u002fBpz6GwWNylkBU9zdCX2YgQrUgg0G1A43BKgvIQIfq6EJ009zByaOuQbyJ5EGXG6DBL0g7wkU3hj\\u002foCOA\\u002fq4xJwNYym8G6viDCRTVLwN\\u002f+rsFoeRPBDujQwJqhFb\\u002fIln+\\u002fpLL5wX07gEE3Vr3AgBmvwVOTrcG5gpi\\u002fU8uzwRzXvsHVnlLClqsrQIYD18AwXJG\\u002fD72NQU5JlUGowAXCvBIPweezDMIv15NAoVk0QVAomkPR7AbBSOdtwQsNTUB+DzbAkgkEwt+Up0GLqyXCLnYbwobQw8GseX\\u002fBWE3CQJ8tS0AVms9AFH5ZPx9XDkHGbozB25QBQa4cdsCPvJPBqh8hwmfam8B4aLq\\u002fttctwrCsk8A6LZu\\u002fPLBoPlurLcKcXzjAf3enQYL\\u002fjcHiUtPACVSCwbbCpUHYDpo\\u002fydw5wUUAg8CIyqLBGtuUwAB4QcMUndLAK7oIQdu7ScKRTSLAcno1QnosOcK6OnDBI7yFweTnbkBf8dXBA79HQTBbIMED7O7BWDTCP7j8QMIO2GhBXXmpQV7aLMHkb1pBwIIbwYBiu8FuEqhBhX2JQVdZVEDpRvK\\u002f5UIDwnTg68EZlkTA47qSP3F7wb90u4g\\u002f1h0TQOhUn8AxbkbCvbHXwdmFGT7dNpVAmYs4PzILIsEbh+DAphMVwhMqAkF3T5DA5VFJwNoay75uoSTBi6+4QV3J6kHXb8DALMPzQDyuI8H5ydvBZFwawmdyQECbPo\\u002fB9AiNQHpJuEAUVt7Blb8Mwk9UwMCRNSbAEJGiQPhgZL4WlSPCu3sYwJs687\\u002fZHsrBSXnzwPk0VEEAZMVBT9kyQIi4Jr0sgefAl32+wYwEjUCzhz1AFWMJwS9duMFUrUPC6anYwBZ9FcAXn4tBA1VCQTnyZ0G4LA1CclzfwatsgsGa8hxCO5sFwm3qCcLpX9jBY1qVwZd7UsJvXW5AWhtRQLGv8sF6UcTB55Nnvz+N08GeHqnBSUgCQT2\\u002fu0D667tBlVsNwOh3uEGuE\\u002fRBONGJQcpLA0IioavBJxngwGHEFMIVI1PB9f5XQYavq0E=\"},\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0d4de1fa-c558-4687-9f96-68f10abe64f6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter_3d(x=vecs_3d[:MAX_WORDS,0], y=vecs_3d[:MAX_WORDS,1], z=vecs_3d[:MAX_WORDS,2],text=labels_3d[:MAX_WORDS])\n",
    "fig.update_traces(marker_size = 2)\n",
    "fig.show(renderer=\"colab\") # esto para plotly en colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
