{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo sequence to sequence - Traductor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "\n",
        "Replicar y extender el traductor:\n",
        "- Replicar el modelo en PyTorch.\n",
        "- Extender el entrenamiento a más datos y tamaños de secuencias mayores.\n",
        "- Explorar el impacto de la cantidad de neuronas en las capas recurrentes.\n",
        "- Mostrar 5 ejemplos de traducciones generadas.\n",
        "\n",
        "Extras que se pueden probar: \n",
        "- Embeddingspre-entrenados para los dos idiomas\n",
        "- Cambiar la estrategia de generación (por ejemplo muestreo aleatorio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torchsummar actualmente tiene un problema con las LSTM, por eso\n",
        "# se utiliza torchinfo, un fork del proyecto original con el bug solucionado\n",
        "from torchinfo import summary\n",
        "\n",
        "import os\n",
        "import platform\n",
        "\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "To: /home/agustin/Desktop/CEIA UBA/Procesamiento Lenguaje Natural I/CEIA-ProcesamientoLenguajeNaturalI/Desafio_4/Dataset/spa-eng.zip\n",
            "100%|██████████| 2.64M/2.64M [00:01<00:00, 2.05MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import gdown\n",
        "import zipfile\n",
        "if os.access('spa-eng', os.F_OK) is False:\n",
        "    if os.access('simpsons_dataset.zip', os.F_OK) is False:\n",
        "        url = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
        "        output = os.path.join(\"./Dataset\", \"spa-eng.zip\")\n",
        "        gdown.download(url, output, quiet=False)\n",
        "    with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"./Dataset\")\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")\n",
        "\n",
        "# dataset_file\n",
        "\n",
        "text_file = os.path.join(\"./Dataset\", \"spa-eng/spa.txt\")\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Funciones de guardado del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def save_checkpoint(folder, model, optimizer, history, config,\n",
        "                    input_tokenizer, output_tokenizer,\n",
        "                    word2idx_inputs, word2idx_outputs, embedding_matrix, embedding_matrix_decoder=None):\n",
        "    \"\"\"\n",
        "    Guarda todos los elementos necesarios para reconstruir el entrenamiento.\n",
        "    \"\"\"\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(folder, \"seq2seq_model.pth\"))\n",
        "    torch.save(optimizer.state_dict(), os.path.join(folder, \"optimizer_state.pth\"))\n",
        "    torch.save(config, os.path.join(folder, \"config.pth\"))\n",
        "\n",
        "    np.save(os.path.join(folder, \"embedding_matrix.npy\"), embedding_matrix)\n",
        "    if embedding_matrix_decoder is not None:\n",
        "        np.save(os.path.join(folder, \"embedding_matrix_decoder.npy\"), embedding_matrix_decoder)\n",
        "\n",
        "    with open(os.path.join(folder, \"input_tokenizer.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(input_tokenizer, f)\n",
        "    with open(os.path.join(folder, \"output_tokenizer.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(output_tokenizer, f)\n",
        "    with open(os.path.join(folder, \"word2idx_inputs.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(word2idx_inputs, f)\n",
        "    with open(os.path.join(folder, \"word2idx_outputs.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(word2idx_outputs, f)\n",
        "\n",
        "    with open(os.path.join(folder, \"history.json\"), \"w\") as f:\n",
        "        json.dump(history, f)\n",
        "\n",
        "    print(f\"Checkpoint guardado en: {folder}\")\n",
        "\n",
        "\n",
        "def load_checkpoint(folder, Encoder, Decoder, Seq2Seq, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Carga todo desde una carpeta y reconstruye el modelo listo para usar.\n",
        "    Retorna: model, optimizer, history, config, tokenizers, vocabularios, embedding_matrix\n",
        "    \"\"\"\n",
        "    # 1. Configuración\n",
        "    config = torch.load(os.path.join(folder, \"config.pth\"), map_location=device)\n",
        "\n",
        "    # 2. Tokenizers y vocabularios\n",
        "    with open(os.path.join(folder, \"input_tokenizer.pkl\"), \"rb\") as f:\n",
        "        input_tokenizer = pickle.load(f)\n",
        "    with open(os.path.join(folder, \"output_tokenizer.pkl\"), \"rb\") as f:\n",
        "        output_tokenizer = pickle.load(f)\n",
        "    with open(os.path.join(folder, \"word2idx_inputs.pkl\"), \"rb\") as f:\n",
        "        word2idx_inputs = pickle.load(f)\n",
        "    with open(os.path.join(folder, \"word2idx_outputs.pkl\"), \"rb\") as f:\n",
        "        word2idx_outputs = pickle.load(f)\n",
        "\n",
        "    # 3. Embedding matrices (encoder obligatoria, decoder opcional)\n",
        "    embedding_matrix_encoder = np.load(os.path.join(folder, \"embedding_matrix.npy\"))\n",
        "\n",
        "    path_decoder = os.path.join(folder, \"embedding_matrix_decoder.npy\")\n",
        "    embedding_matrix_decoder = np.load(path_decoder) if os.path.exists(path_decoder) else None\n",
        "\n",
        "    vocab_size_encoder = int(embedding_matrix_encoder.shape[0])\n",
        "    # 4. Modelo\n",
        "    encoder = Encoder(\n",
        "        vocab_size=vocab_size_encoder,\n",
        "        embedding_matrix=embedding_matrix_encoder\n",
        "    )\n",
        "\n",
        "    if embedding_matrix_decoder is not None:\n",
        "        decoder = Decoder(\n",
        "            vocab_size=config[\"num_words_output\"],\n",
        "            output_dim=config[\"num_words_output\"],\n",
        "            embedding_matrix=embedding_matrix_decoder\n",
        "        )\n",
        "    else:\n",
        "        print(\"No se encontró embedding_matrix_decoder.npy — se entrenará embedding en el Decoder.\")\n",
        "        decoder = Decoder(\n",
        "            vocab_size=config[\"num_words_output\"],\n",
        "            output_dim=config[\"num_words_output\"]\n",
        "        )\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder)\n",
        "    model.load_state_dict(torch.load(os.path.join(folder, \"seq2seq_model.pth\"), map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # 5. Optimizador\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "    optimizer.load_state_dict(torch.load(os.path.join(folder, \"optimizer_state.pth\"), map_location=device))\n",
        "\n",
        "    # 6. Historia\n",
        "    with open(os.path.join(folder, \"history.json\"), \"r\") as f:\n",
        "        history = json.load(f)\n",
        "\n",
        "    print(f\"Checkpoint cargado desde: {folder}\")\n",
        "\n",
        "    return {\n",
        "        \"model\": model,\n",
        "        \"optimizer\": optimizer,\n",
        "        \"history\": history,\n",
        "        \"config\": config,\n",
        "        \"input_tokenizer\": input_tokenizer,\n",
        "        \"output_tokenizer\": output_tokenizer,\n",
        "        \"word2idx_inputs\": word2idx_inputs,\n",
        "        \"word2idx_outputs\": word2idx_outputs,\n",
        "        \"embedding_matrix\": embedding_matrix\n",
        "    }\n",
        "\n",
        "\n",
        "def check_checkpoint_exists(folder):\n",
        "    \"\"\"\n",
        "    Verifica si existen todos los archivos necesarios en la carpeta.\n",
        "    Retorna True si el checkpoint está completo.\n",
        "    \"\"\"\n",
        "    required_files = [\n",
        "        \"seq2seq_model.pth\",\n",
        "        \"optimizer_state.pth\",\n",
        "        \"config.pth\",\n",
        "        \"embedding_matrix.npy\",\n",
        "        \"input_tokenizer.pkl\",\n",
        "        \"output_tokenizer.pkl\",\n",
        "        \"word2idx_inputs.pkl\",\n",
        "        \"word2idx_outputs.pkl\",\n",
        "        \"history.json\"\n",
        "    ]\n",
        "\n",
        "    missing = [f for f in required_files if not os.path.exists(os.path.join(folder, f))]\n",
        "    if missing:\n",
        "        print(f\"Faltan archivos en el checkpoint: {missing}\")\n",
        "        return False\n",
        "    print(f\"Checkpoint completo encontrado en: {folder}\")\n",
        "    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Entrenamiento Baseline\n",
        "Se tomará el modelo entrenado en clase como Baseline para comparación al aplicar cambios:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Limitación dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de rows disponibles: 118964\n",
            "Cantidad de rows utilizadas: 6000\n"
          ]
        }
      ],
      "source": [
        "# Mezclar el dataset, forzar semilla siempre igual\n",
        "np.random.seed([40])\n",
        "np.random.shuffle(lines)\n",
        "\n",
        "def generar_secuencias(lines, MAX_NUM_SENTENCES=6000):\n",
        "    input_sentences = []\n",
        "    output_sentences = []\n",
        "    output_sentences_inputs = []\n",
        "    count = 0\n",
        "\n",
        "    for line in lines:\n",
        "        count += 1\n",
        "        if count > MAX_NUM_SENTENCES:\n",
        "            break\n",
        "\n",
        "        if '\\t' not in line:\n",
        "            continue\n",
        "\n",
        "        # Input sentence --> eng\n",
        "        # output --> spa\n",
        "        input_sentence, output = line.rstrip().split('\\t')\n",
        "\n",
        "        # output sentence (decoder_output) tiene <eos>\n",
        "        output_sentence = output + ' <eos>'\n",
        "        # output sentence input (decoder_input) tiene <sos>\n",
        "        output_sentence_input = '<sos> ' + output\n",
        "\n",
        "        input_sentences.append(input_sentence)\n",
        "        output_sentences.append(output_sentence)\n",
        "        output_sentences_inputs.append(output_sentence_input)\n",
        "    return input_sentences, output_sentences, output_sentences_inputs\n",
        "\n",
        "\n",
        "# Por limitaciones de RAM no se leen todas las filas\n",
        "MAX_NUM_SENTENCES = 6000\n",
        "input_sentences, output_sentences, output_sentences_inputs = generar_secuencias(lines, MAX_NUM_SENTENCES)\n",
        "\n",
        "print(\"Cantidad de rows disponibles:\", len(lines))\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('A deal is a deal.',\n",
              " 'Un trato es un trato. <eos>',\n",
              " '<sos> Un trato es un trato.')"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras en el vocabulario: 3851\n",
            "Sentencia de entrada más larga: 32\n",
            "Palabras en el vocabulario: 5721\n",
            "Sentencia de salida más larga: 36\n"
          ]
        }
      ],
      "source": [
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una máxima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "from torch_helpers import Tokenizer\n",
        "\n",
        "def tokenizar_texto(input_sentences, output_sentences, output_sentences_inputs, MAX_VOCAB_SIZE=8000):\n",
        "    input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "    input_tokenizer.fit_on_texts(input_sentences)\n",
        "    input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "    word2idx_inputs = input_tokenizer.word_index\n",
        "    print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "    max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "    print(\"Sentencia de entrada más larga:\", max_input_len)\n",
        "\n",
        "\n",
        "    # A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
        "    # sacamos los \"<>\" para que no afectar nuestros tokens\n",
        "    output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "    output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "    output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "    output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "    word2idx_outputs = output_tokenizer.word_index\n",
        "    print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "    num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
        "    max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "    print(\"Sentencia de salida más larga:\", max_out_len)\n",
        "\n",
        "    return {\n",
        "        'input_tokenizer': input_tokenizer,\n",
        "        'output_tokenizer': output_tokenizer,\n",
        "        'input_integer_seq': input_integer_seq,\n",
        "        'output_integer_seq': output_integer_seq,\n",
        "        'output_input_integer_seq': output_input_integer_seq,\n",
        "        'word2idx_inputs': word2idx_inputs,\n",
        "        'word2idx_outputs': word2idx_outputs,\n",
        "        'max_input_len': max_input_len,\n",
        "        'max_out_len': max_out_len,\n",
        "        'num_words_output': num_words_output\n",
        "    }\n",
        "\n",
        "# Definir el tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 8000\n",
        "\n",
        "salida_tokenizador = tokenizar_texto(input_sentences, output_sentences, output_sentences_inputs, MAX_VOCAB_SIZE)\n",
        "\n",
        "input_tokenizer = salida_tokenizador[\"input_tokenizer\"]\n",
        "output_tokenizer = salida_tokenizador[\"output_tokenizer\"]\n",
        "input_integer_seq = salida_tokenizador[\"input_integer_seq\"]\n",
        "output_integer_seq = salida_tokenizador[\"output_integer_seq\"]\n",
        "output_input_integer_seq = salida_tokenizador[\"output_input_integer_seq\"]\n",
        "num_words_output = salida_tokenizador[\"num_words_output\"]\n",
        "word2idx_inputs = salida_tokenizador[\"word2idx_inputs\"]\n",
        "word2idx_outputs = salida_tokenizador[\"word2idx_outputs\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
        "# a la mitad:\n",
        "max_input_len = 16\n",
        "max_out_len = 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de rows del dataset: 6000\n",
            "encoder_input_sequences shape: (6000, 16)\n",
            "decoder_input_sequences shape: (6000, 18)\n",
            "decoder_output_sequences shape: (6000, 18)\n"
          ]
        }
      ],
      "source": [
        "from torch_helpers import pad_sequences\n",
        "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)\n",
        "\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_input_size: 16\n",
            "decoder_input_size: 18\n",
            "Output dim 5722\n"
          ]
        }
      ],
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input, decoder_output):\n",
        "        # Convertir los arrays de numpy a tensores. \n",
        "        # pytorch espera en general entradas 32bits\n",
        "        self.encoder_inputs = torch.from_numpy(encoder_input.astype(np.int32))\n",
        "        self.decoder_inputs = torch.from_numpy(decoder_input.astype(np.int32))\n",
        "        # Transformar los datos a oneHotEncoding\n",
        "        # la loss function esperan la salida float\n",
        "        # Para CrossEntropyLoss: guardar los targets como índices de clase (LongTensor),\n",
        "        # shape = (N, seq_len), dtype = torch.int64\n",
        "        self.decoder_outputs = torch.from_numpy(decoder_output).to(torch.int64)\n",
        "\n",
        "        self.len = self.decoder_outputs.shape[0]\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_outputs[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "data_set = Data(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)\n",
        "\n",
        "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
        "print(\"encoder_input_size:\", encoder_input_size)\n",
        "\n",
        "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
        "print(\"decoder_input_size:\", decoder_input_size)\n",
        "\n",
        "output_dim = num_words_output\n",
        "print(\"Output dim\", output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del conjunto de entrenamiento: 4800\n",
            "Tamaño del conjunto de validacion: 1200\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
        "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, drop_last=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Preparar los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los embeddings gloveembedding.pkl ya están descargados\n"
          ]
        }
      ],
      "source": [
        "# Descargar los embeddings desde un gogle drive (es la forma más rápida)\n",
        "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
        "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
        "import os\n",
        "import gdown\n",
        "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
        "    output = 'gloveembedding.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Por una cuestion de RAM se utilizará los embeddings de Glove de dimension 50\n",
        "model_embeddings = GloveEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de embeddings nulos: 30\n"
          ]
        }
      ],
      "source": [
        "# Crear la Embedding matrix de las secuencias\n",
        "# en ingles\n",
        "\n",
        "\n",
        "def preparar_embedding_matrix(model_embeddings, word2idx_inputs, MAX_VOCAB_SIZE):\n",
        "    embed_dim = model_embeddings.N_FEATURES\n",
        "    words_not_found = []\n",
        "\n",
        "    # word_index provieen del tokenizer\n",
        "\n",
        "    nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs) + 1) # vocab_size\n",
        "    embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "    for word, i in word2idx_inputs.items():\n",
        "        if i >= nb_words:\n",
        "            continue\n",
        "        embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
        "        if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "            \n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            words_not_found.append(word)\n",
        "\n",
        "    print('Número de embeddings nulos:', np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
        "    return embedding_matrix, words_not_found, nb_words\n",
        "\n",
        "embedding_matrix, words_not_found, nb_words = preparar_embedding_matrix(model_embeddings, word2idx_inputs, MAX_VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3852"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nb_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3852, 50)"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimensión de los embeddings de la secuencia en ingles\n",
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4. Entrenar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_matrix):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 128\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_matrix.shape[1]\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embedding.weight.requires_grad = False  # marcar como layer no entrenable (freeze)\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
        "                            num_layers=self.num_layers) # LSTM layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm(out)\n",
        "        return (ht, ct)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim, embedding_matrix=None):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 128\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_matrix.shape[1] if embedding_matrix is not None else 50\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "\n",
        "        # Para utilizar versión con embedding preentrenados\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = False  # \n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
        "                            num_layers=self.num_layers) # LSTM layer\n",
        "        self.fc1 = nn.Linear(in_features=self.lstm_size, out_features=self.output_dim) # Fully connected layer\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1) # normalize in dim 1\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
        "        out = self.softmax(self.fc1(lstm_output[:,-1,:])) # take last output (last seq)\n",
        "        return out, (ht, ct)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        \n",
        "        assert encoder.lstm_size == decoder.lstm_size, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.num_layers == decoder.num_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, encoder_input, decoder_input):\n",
        "        batch_size = decoder_input.shape[0]\n",
        "        decoder_input_len = decoder_input.shape[1]\n",
        "        vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        # tensor para almacenar la salida\n",
        "        # (batch_size, sentence_len, one_hot_size)\n",
        "        outputs = torch.zeros(batch_size, decoder_input_len, vocab_size)\n",
        "        \n",
        "        # ultimo hidden state del encoder, primer estado oculto del decoder\n",
        "        prev_state = self.encoder(encoder_input)\n",
        "      \n",
        "        # En la primera iteracion se toma el primer token de target (<sos>)\n",
        "        input = decoder_input[:, 0:1]\n",
        "\n",
        "        for t in range(decoder_input_len):\n",
        "            # t --> token index\n",
        "\n",
        "            # utilizamos método \"teacher forcing\", es decir que durante\n",
        "            # el entrenamiento no realimentamos la salida del decoder\n",
        "            # sino el token correcto que sigue en target\n",
        "            input = decoder_input[:, t:t+1]\n",
        "\n",
        "            # ingresar cada token embedding, uno por uno junto al hidden state\n",
        "            # recibir el output del decoder (softmax)\n",
        "            output, prev_state = self.decoder(input, prev_state)\n",
        "            top1 = output.argmax(1).view(-1, 1)\n",
        "\n",
        "            # Sino se usará \"teacher forcing\" habría que descomentar\n",
        "            # esta linea.\n",
        "            # Hay ejemplos dandos vuelta en donde se utilza un random \n",
        "            # para ver en cada vuelta que técnica se aplica\n",
        "            #input = top1            \n",
        "\n",
        "            # guardar cada salida (softmax)\n",
        "            outputs[:, t, :] = output\n",
        "\n",
        "        return outputs\n",
        "\n",
        "encoder = Encoder(vocab_size=nb_words, embedding_matrix=embedding_matrix)\n",
        "if cuda: encoder.to(device)\n",
        "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
        "# asegurar consistencia: output_dim igual a num_words_output usado por dataset/one-hot\n",
        "decoder = Decoder(vocab_size=num_words_output, output_dim=num_words_output)\n",
        "if cuda: decoder.to(device)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "if cuda: model.to(device)\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
        "\n",
        "\n",
        "### CORREGIR ERROR\n",
        "#summary(model, input_data=(data_set[0:1][0], data_set[0:1][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def sequence_acc(y_pred, y_test):\n",
        "    \"\"\"\n",
        "    Calcula la accuracy promedio por secuencia.\n",
        "    y_pred: logits (batch, seq_len, vocab_size)\n",
        "    y_test: índices (batch, seq_len)\n",
        "    \"\"\"\n",
        "    y_pred_tag = y_pred.argmax(dim=-1)  # (batch, seq_len)\n",
        "    y_test_tag = y_test if y_test.ndim == 2 else y_test.argmax(dim=-1)\n",
        "    acc = (y_pred_tag == y_test_tag).float().mean().item()\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n",
        "    train_loss, train_accuracy = [], []\n",
        "    valid_loss, valid_accuracy = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_train_accuracy = 0.0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "        for train_encoder_input, train_decoder_input, train_target in loop:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward\n",
        "            output = model(train_encoder_input.to(device), train_decoder_input.to(device))\n",
        "\n",
        "\n",
        "            # Calcular loss en toda la secuencia (más eficiente)\n",
        "            loss = criterion(\n",
        "                output.reshape(-1, output.shape[-1]),\n",
        "                train_target.to(device).reshape(-1)\n",
        "            )\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "            epoch_train_accuracy += sequence_acc(output.to(device), train_target.to(device))\n",
        "\n",
        "        epoch_train_loss /= len(train_loader)\n",
        "        epoch_train_accuracy /= len(train_loader)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        train_accuracy.append(epoch_train_accuracy)\n",
        "\n",
        "\n",
        "        # --- VALIDACIÓN COMPLETA ---\n",
        "        model.eval()\n",
        "        epoch_valid_loss = 0.0\n",
        "        epoch_valid_accuracy = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for valid_encoder_input, valid_decoder_input, valid_target in valid_loader:\n",
        "                output = model(valid_encoder_input.to(device), valid_decoder_input.to(device))\n",
        "                loss = criterion(\n",
        "                    output.reshape(-1, output.shape[-1]),\n",
        "                    valid_target.to(device).reshape(-1)\n",
        "                )\n",
        "\n",
        "                epoch_valid_loss += loss.item()\n",
        "                epoch_valid_accuracy += sequence_acc(output.to(device), valid_target.to(device))\n",
        "\n",
        "        epoch_valid_loss /= len(valid_loader)\n",
        "        epoch_valid_accuracy /= len(valid_loader)\n",
        "        valid_loss.append(epoch_valid_loss)\n",
        "        valid_accuracy.append(epoch_valid_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:02}/{epochs} | \"\n",
        "              f\"Train loss: {epoch_train_loss:.3f} | \"\n",
        "              f\"Train acc: {epoch_train_accuracy:.3f} | \"\n",
        "              f\"Val loss: {epoch_valid_loss:.3f} | \"\n",
        "              f\"Val acc: {epoch_valid_accuracy:.3f}\")\n",
        "\n",
        "    return {\n",
        "        \"loss\": train_loss,\n",
        "        \"accuracy\": train_accuracy,\n",
        "        \"val_loss\": valid_loss,\n",
        "        \"val_accuracy\": valid_accuracy,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint completo encontrado en: Modelos_entrenados/Baseline\n",
            "No se encontró embedding_matrix_decoder.npy — se entrenará embedding en el Decoder.\n",
            "Checkpoint cargado desde: Modelos_entrenados/Baseline\n"
          ]
        }
      ],
      "source": [
        "carpeta = \"Modelos_entrenados/Baseline\"\n",
        "\n",
        "modelo_entrenado = check_checkpoint_exists(carpeta)\n",
        "\n",
        "if not modelo_entrenado:\n",
        "    history1 = train(model,\n",
        "                    train_loader,\n",
        "                    valid_loader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    epochs=10\n",
        "                    )\n",
        "    config = {\n",
        "        # Información general\n",
        "        \"max_input_len\": max_input_len,\n",
        "        \"max_out_len\": max_out_len,\n",
        "        \"max_vocab_size\": MAX_VOCAB_SIZE,\n",
        "        \"cuda\": cuda,\n",
        "\n",
        "        # Hiperparámetros de embedding y red\n",
        "        \"embedding_dim\": embedding_matrix.shape[1],\n",
        "        \"hidden_size\": 128,        \n",
        "        \"num_layers\": 1,           \n",
        "        \"lr\": 0.1,\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": 10,\n",
        "\n",
        "        # Vocabularios (usar tamaños reales)\n",
        "        \"num_words_input\": int(embedding_matrix.shape[0]),\n",
        "        \"num_words_output\": int(num_words_output),\n",
        "\n",
        "        # Checkpoint info (opcional)\n",
        "        \"embedding_source\": getattr(model_embeddings, \"name\", \"custom\"),\n",
        "    }\n",
        "    save_checkpoint(carpeta, model, optimizer, history1, config,\n",
        "                    input_tokenizer, output_tokenizer,\n",
        "                    word2idx_inputs, word2idx_outputs, embedding_matrix)\n",
        "else:\n",
        "    data = load_checkpoint(carpeta, Encoder, Decoder, Seq2Seq, device=\"cuda\" if cuda else \"cpu\")\n",
        "    model = data[\"model\"]\n",
        "    optimizer = data[\"optimizer\"]\n",
        "    history1 = data[\"history\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVDdJREFUeJzt3Xl4lNXd//H3ZJKZ7BshK4GEHYEAAiJirVYoWqVqEaViQW1txVhZah/hZ3EX6lJLrQuFuuCjPkWpKAhCBZe6IJsiICRhC4GQhEBIJgvJJDPz++NOJsSEJZBkkpnP67rmSuaee+Y+kyjzyTnfc47J5XK5EBEREeng/DzdABEREZGWoFAjIiIiXkGhRkRERLyCQo2IiIh4BYUaERER8QoKNSIiIuIVFGpERETEKyjUiIiIiFfw93QD2orT6eTw4cOEhYVhMpk83RwRERE5Cy6Xi9LSUhITE/HzO31fjM+EmsOHD5OcnOzpZoiIiMg5OHjwIF26dDntOT4TasLCwgDjhxIeHu7h1oiIiMjZsNlsJCcnuz/HT8dnQk3dkFN4eLhCjYiISAdzNqUjKhQWERERr6BQIyIiIl5BoUZERES8gs/U1IiIiLQGl8tFTU0NDofD003psAICAjCbzef9Ogo1IiIi58hut5OXl0dFRYWnm9KhmUwmunTpQmho6Hm9jkKNiIjIOXA6nezfvx+z2UxiYiIWi0WLu54Dl8tFYWEhhw4dolevXufVY6NQIyIicg7sdjtOp5Pk5GSCg4M93ZwOrXPnzmRnZ1NdXX1eoUaFwiIiIufhTEv3y5m1VA+XfhMiIiLiFRRqRERExCso1IiIiMg5S0lJYf78+Z5uBqBCYREREZ9z+eWXM3jw4BYJI5s2bSIkJOT8G9UCFGrE4HTCjn9D8QFIHAyJF0JwtKdbJSIiHuByuXA4HPj7nzkmdO7cuQ1adHY0/CRQUQT/ugXe/Q18/Bi8MR6eSoW/DYJ3boev/g7ZX0JVmadbKiLSbrlcLirsNR65uVyus27nbbfdxmeffcbf/vY3TCYTJpOJ1157DZPJxIcffsjQoUOxWq188cUX7N27l+uuu464uDhCQ0MZPnw4a9eubfB6Pxx+MplM/POf/+SGG24gODiYXr16sXz58pb6MZ+Wemp83aHNRnApyQGzFXr/FAq+h6J9cDzbuH3/rnGuyQ9i+kDShZA4xPgaNwD8rZ58ByIi7cKJagcXPLjGI9fe+ehYgi1n95H+t7/9jaysLAYMGMCjjz4KwPfffw/ArFmzeOaZZ+jevTtRUVEcPHiQn/3sZzzxxBNYrVZef/11xo0bR2ZmJl27dj3lNR555BGeeuopnn76af7+978zadIkDhw4QHR0644AKNT4KpcLNiyA/8wBZzVEd4cJr0HCIOPxE8fh8LeQ+03919LDULjLuG190zjPbDGCTdKFxpBV0oUQ0xv8zn8PDxERaXkRERFYLBaCg4OJj48HICMjA4BHH32UMWPGuM+Njo5m0KBB7vuPPfYYy5YtY/ny5dxzzz2nvMZtt93GL3/5SwDmzp3Lc889x8aNG7nqqqta4y25KdT4ohPFsPwe2LXCuH/BdfDzv0NgRP05QVHQ4yfGrU5pfm3I+ab+64njxtfD39SfZwk1wlFdb07ihRCVAlo+XES8WFCAmZ2PjvXYtVvCsGHDGtwvKyvj4YcfZuXKleTl5VFTU8OJEyfIyck57eukpaW5vw8JCSE8PJwjR460SBtPR6HG1xzeCu9MMYaV/AJg7BNw0W/PLnCExUPfnxk3MHp7jmefFHK+NV7fXgYHvjRudYKiG4acpAuN1xMR8RImk+msh4Daqx/OYrrvvvv46KOPeOaZZ+jZsydBQUHceOON2O32075OQEBAg/smkwmn09ni7f2hjv3Tl7PncsHml2H1bHDYIbKrMdyUNPTcX9NkguhU4zZgvHHM6YCjWQ17dPK3w4ki2LvOuNUJS2xYn5M4xOghEhGRVmWxWHA4HGc878svv+S2227jhhtuAIyem+zs7FZu3blTqPEFVaWw/N76gt8+18D1L7ROgPAzQ2w/4zZkknGspgoKdjSszynMMGp0Mg5Dxgf1z4/uXtuTM9QIOvFpYNFGcSIiLSklJYUNGzaQnZ1NaGjoKXtRevXqxbvvvsu4ceMwmUzMmTOnTXpczpVCjbfL32EMNx3bA37+MPoRGJnetvUt/tbakHJSr1BVGeR917A+53i2MeuqaB/sWGqcZ6oNSScPXcX1B3NAk5cSEZEzu++++5gyZQoXXHABJ06c4NVXX23yvGeffZY77riDSy65hJiYGO6//35sNlsbt/bsmVzNmdzegdlsNiIiIigpKSE8PNzTzWl9Lhd8+7+w6o9QUwnhScZwU/JFnm7ZqVUU1Yacb+vDTll+4/PMVogf2LA+p1Mv0E65ItKGKisr2b9/P6mpqQQGBnq6OR3a6X6Wzfn8Vk+NN7KXwwczYdu/jPs9x8AN/4CQTp5t15kER0PP0catju1w4xlXlSWQu9m41bGE1a6EPKR+2Cqyq3p0RER8iEKNtzmSYQw3FWYYi+X9ZA6Mmt5xezHCE41bv2uN+y6XMTx1ctDJ+w7spZD9uXGrY/KDiC7GdPKo1NqvKUZhc1SKipJFRLyMQo032fp/sHImVFdAaDzc+AqkjPJ0q1qWyQSdehi3tAnGMUeNEeJO7s0pzIKaE1CcY9z2/7fxawVGNB12olIgvAuY9b+HiEhHon+1vUH1CaN25tv/Ne53vxx+8U8IbT+bjLUqsz/EDzBuF042jrlcUFZQW3y8v37Lh+O135cVGMNYeVuN2w/5+UNEcuOwUxeCAn2gLquZTtgdFFXYOV5up6jczvGK2q/ldkwmEz8fnEiPzqGebqaIeDGFmo7u6B5juKlgB2CCy2fDZfdpmwKTyVjcLyweul7c+HF7ORw/0DjsHM82jjuqao/th32fNH5+cKfGQacuAIUldPiff1WNg+KKancoqQ8r1fVh5aTQUlRhp7L69NM8/7ZuNz/qFcOUkSlc0TcWs18HWGG6qhSKDxq9fSUHjV7QYXeANczTLRORJijUdGTbl8KKacYKviGdYfw/jV4aOTNLCMRdYNx+yOmE0ryGYefk3p6Ko1BxzLjlbmn8fLPFKFJuamgrshtY27a3osbhpPhE9Q96UKobhZL6r9WUVdWc07UsZj+iQyxEhViIDgkgKthCdIiFw8UnWJdxhM93H+Xz3UdJjg7iVxd346ZhyUQGW1r4HZ8ll8uYcVeSYwSXkoMnBZjaY5XFjZ93cCPc/Ia2/RBphxRqOqLqSljz/4wVggG6XQo3vqxtB1qKnx9EJBm3pmqSKm1QfKDpoa3iHGPF5mN7jFtTQmKbruOJSoXQuNMWdTudLmyV1Q3DSYOelJN6UGp7WkpOVJ/Tj8HsZyIq2AgmUSEWOtWFleDGoaXua7DFjOkUH/YHiyp44+sD/GvTQQ4WnWDuqgye/SiL6wcnMeWSFPoltPCQntNpDDOWHKyvraoLLnVfq8vP/DqBkUZIjUiG3f8xFovcsAAuntqy7RWR86Z1ajqaon3wzm3GjB+AH91nDDmpqLV9cDrAltt0Hc/xbGMD0NPxD8QR0ZXj1iQOOGPZXx1JYXUQR6oDya+ycLjSQokrCJsrhFKCqW7G3yWRwQHuQGKEkICGIcUdVozvwwL98WuFIaITdgfLv8vlta8OsCuvfhGvi1KimXJJCj/tH0eA+Sxm6zmqjZ/1ySGlpDa8FB80HnOcfn8awAiSEckQmVz7tWt9iIlMbjjUtOEf8OH/GPum3bEGupzHNiPS4WmdmpbTUuvUKNR0JDuXw/vpUGUzNoj8xSLoNfrMz5P240Rxo7BjL9xHzdF9BFbk4ceZ92I5WRVWKswh2M2hVAeE47CEQ2A4pqAI/IMjsYZEYQ2NJCgsGnNwlFHgHBgB1tqvlhCPDaO4XC42HzjOa19ls3pHPg6n8U9RfHggk0Z0ZeKQznR2Fp7Uw/KDYaLSw+A6w3LtJj9j4cm6gHJyWInoakz5D2jGh5HLZdSw7XzfeP7vPjPWVxKf5MuhJiUlhenTpzN9+nTA2LBy2bJlXH/99U2en52dTWpqKt9++y2DBw9u9LgW3/MlNXb46EHY8JJxP3mEMV07ootn2yXN5gqM4IClFxtPdGJTXiqbsovIPlYBgD81JJiO0c10hEEhxxkaXkK3gGJCqSDIUY7FUUpAdRl+VTZM9lIArFRhdVSBowjswFmMpjRgMjcOOiffGhxr4jxr+Dn3EpqqShkelMfwoQXYkvaTlbmT43l76Vx5hKT/FtL587NYit1sMf4/cIeVrg0DTFhiy/Zimkzw878bPaXHs40/Mia+pfoa8Xl5eXlERXl+7S+FmvauOMcYbqorSL3kXrjyQa2U20E4nC525dnYlF1UeztOYWlVg3NMJugTF8ZFqdEMSxnORSnRxEec4a8+p8PosassMWp8KkuMW5PHSpo+z1kDLocxJHamYbHTsYSeFHTCmwhE4UZ4suWe1NuSY7SjVjgwrO7OSSNPZa5Acl0xlFrjiU7qQdfuffGP7mb0kkQmG/VJbb2wZGAETFgML4+BzFWw/gW45J62bYNIOxMf3z5qOhVq2rPMD2HZXcYMjMBIuGEB9Lna062S06isdvDdwWI2HzjOxv1FfHPgOKU/mElkMfuR1iWC4anRDE+JYmjXaCKCmxlS/czGisjnuiqyy2VMT24yEJWcISTVfl9t9DBhLzNupYeb346gqB/0sHR117Z8XxHBy1uK+WBbPvZSJ2RAp4MWfnlRVyYldyUhLOjc3ntLSBwMY+fCqvtg7UNG72nycM+1R6QZFi5cyMMPP8yhQ4fwO+mPguuuu45OnTrxwAMPMHPmTL7++mvKy8vp168f8+bNY/ToU5c7/HD4aePGjfzud79j165dDBgwgAceeKC13xagUNM+Oaph3aPw1XPG/aShcOOrENXNs+2SRkpOVPPNgeNszC5i0/4ith0qwe5oWOcRavVnaLcohqdEMTwlmkHJkQQGeHgdG5PJqKexhEB4wrm9hqO6NuwUNw4/DQKSzSjYjUhqPER0mvVe+gPP9oQHrqniX5sO8sbXB8grqeT5T/bw0md7Gds/jikjU7goNfqUM65a1fDfwIEv4ftlRm/qXZ+rvsbX1f2x4AkBwWc9DDphwgR+//vf88knn3DllVcCUFRUxOrVq1m1ahVlZWX87Gc/44knnsBqtfL6668zbtw4MjMz6dq16xlfv6ysjGuvvZYxY8bwxhtvsH//fqZNm3Zeb+9sKdS0NyW5sPR2OLjBuD9iKox5FPw9tJaHNFBgq2TjfmMoaeP+IjILSvlhqX1MqJWLUo0AMzwlmn4J4R1jobnmMgcYm6S28kapnUKtpF/Rk99d1p2PdhaweH02X+8rYtX2fFZtz6dvfBhTLknhusGJBFva8J80kwnGPWfU1xTtg/emwsT/67j7rMn5q66AuYmeufb/O2z8kXIWoqKiuPrqq3nrrbfcoWbp0qXExMRwxRVX4Ofnx6BBg9znP/bYYyxbtozly5dzzz1nHmp96623cDqdvPzyywQGBtK/f38OHTrE1KmtvwyCQk17snstvHsnnCgy6hGuex4uuM7TrfJZLpeLfUfL2bS/yOiJyS7iYNGJRueldAo2AkxqNBelRNOtU7Bneg68nL/Zj6sHJnD1wAQy8m0s/uoA732bS0Z+KbPf3c68Vbu4eXgyv7o4ha6dgtumUYHhRn3NP0dD1mpY/3cY1TZ/kYqcj0mTJnHnnXfy4osvYrVaefPNN5k4cSJ+fn6UlZXx8MMPs3LlSvLy8qipqeHEiRPk5OSc1Wvv2rWLtLS0BrOYRo4c2VpvpQGFmvbAUQOfzoPPnzHux6fBTYshurtn2+VjahxOdubZ2Li/iM3Zx9l8oIijZQ3XOfEzQb+EcIanRBuFvd2iiA33ramc7UHf+HDm/WIgs67qyztbDvL6+gPkFFWw6PP9/POL/fykTyyTL0nhRz1jWmWtnQYS0uDqP8MHM2DtI5B8MXQd0brXlPYpINjoMfHUtZth3LhxuFwuVq5cyfDhw/n888/561//CsB9993HRx99xDPPPEPPnj0JCgrixhtvxG4/i3WfPEyhxtNK82Hpr+HAF8b9Yb82ChCbs3aGnJMTdgdbDxa7ZyZ9c+A45faG68RY/P0YnBzJRSnRDEuJYmi3KMICNfOsvYgIDuA3P+rOHaNS+TTrCIu/OsBnWYWsyzjCuowjdI8J4Vcju3Hj0C6t+3sbejtkfwE7/m0MH//u81YflpN2qK5WrQMIDAzkF7/4BW+++SZ79uyhT58+XHjhhQB8+eWX3Hbbbdxwww2AUSOTnZ191q/dr18//vd//5fKykp3b83XX3/d4u+hKQo1nrTvU/j3b6C80JgWO+5vMPBGT7fKaxVX2Nmcfdyoh8kuYkduCdWOhgUxYYH+DOsW5R5KGtglAqt/x96c0hf4+Zn4Sd84ftI3jn2FZby+/gBLtxxi39FyHlmxk2fWZDJ+aBcmj+xGz9hW2IzSZDL+/837ztgeY9nv4Ja3VV8j7dqkSZO49tpr+f7777n11lvdx3v16sW7777LuHHjMJlMzJkzB6fzDAtdnuSWW27hgQce4M4772T27NlkZ2fzzDPPtMZbaEShxhOcDvjvM8aQEy6I7W8MN8X08nTLvMrh4hPugt5N2UVkFZQ1Oicu3OoeShqeEk2fuLDWH66QVtW9cygP/7w/943tw7JvDrF4/QH2HDGCzuvrD3Bpzxgmj+zGlf3iWraA2xpWW19zJez5CL76G1w6o+VeX6SF/eQnPyE6OprMzExuueUW9/Fnn32WO+64g0suuYSYmBjuv/9+bLazWAyzVmhoKCtWrOCuu+5iyJAhXHDBBTz55JOMHz++Nd5GA9omoa2VFcK7vzF6aQCG/AqufgosbVTY6MVqHE427C/ig22H+W/WUXKLGxf1du8cwkW1s5IuSo2mS1SQinq9nMvl4qu9x1j8VTZrdxVQuxsDSZFB/GpkN24elkxUSAvOLtzyGqyYZiw4eNtK6NY2BZLS9nx5m4SW1lLbJJxT3+gLL7xASkoKgYGBjBgxgo0bN572/OLiYtLT00lISMBqtdK7d29WrVrlftzhcDBnzhxSU1MJCgqiR48ePPbYY5yct1wuFw8++CAJCQkEBQUxevRodu/efS7N95zsL2HBpUagCQiG6xcYM5wUaM6Z0+liU3YRD76/g4vnrWPSPzfwfxsPklt8ArOfibQuEfz60lQW3DqUzX8azcd/uJw/j09j/NAuJEdrlpIvMJlMjOoZw8LJw/jsj1fwux93JzI4gNziE/z5wwwunreO+5du4/vDJWd+sbNx4RQYeJOxWvPS26H8aMu8roicUbOHn5YsWcLMmTNZsGABI0aMYP78+YwdO5bMzExiY2MbnW+32xkzZgyxsbEsXbqUpKQkDhw4QGRkpPucJ598kpdeeonFixfTv39/Nm/ezO23305ERAT33nsvAE899RTPPfccixcvJjU1lTlz5jB27Fh27tzZ/hOy0wlf/hU+ftzYgC+mjzHcFNvP0y3rkFwuF9sOlbDiu8Os3J5HXkml+7HI4ACuHpDAVQPiGdYtihCrRlilXnJ0MLOv7seM0b1ZvvUwr32Vzc48G0s2H2TJ5oMMT4li8sgUrhoQf3Y7hTfFZIJr/wqHv4Vju+Hd38KkpaqvEWkDzR5+GjFiBMOHD+f5558HwOl0kpyczO9//3tmzZrV6PwFCxbw9NNPk5GRQUBA07MPrr32WuLi4nj55Zfdx8aPH09QUBBvvPEGLpeLxMRE/vCHP3DfffcBUFJSQlxcHK+99hoTJ048Y7s9NvxUUWT8o7bnI+N+2kS45i9gDW27NngBl8tFRn4pH2w7zIrv8sgpql+1M8zqz0/7xzNuUAKjesac+4eR+ByXy8WWA8dZvP4AH27Po6Z2bCo2zMqkEd345YhkYsPO8Y+mgu9h0ZVQcwJ+Mgcuu68FWy7tgYafWo5Hdum22+1s2bKF2bNnu4/5+fkxevRo1q9f3+Rzli9fzsiRI0lPT+f999+nc+fO3HLLLdx///2YzcaskksuuYSFCxeSlZVF7969+e677/jiiy949tlnAdi/fz/5+fkN9p2IiIhgxIgRrF+/vslQU1VVRVVV/caBzSlyajE5G4zuZ1su+AcatTMXTtaOvs2wt7CMD77LY8W2w+w5Ul/oGxRg5sp+sYwblMiPe3f2/LYD0iGZTCaGpUQzLCWagmv68daGHN7ckMOR0ir+ujaL5z/Zzc8GJjDlkhSGJEc2b7gyrj/87GlYfg988gR0vRhSLm29NyMizQs1R48exeFwEBcX1+B4XFwcGRkZTT5n3759fPzxx0yaNIlVq1axZ88e7r77bqqrq3nooYcAmDVrFjabjb59+2I2m3E4HDzxxBNMmjQJgPz8fPd1fnjdusd+aN68eTzyyCPNeXstx+WC9c/D2oeNnZCjexjDTfEDPdOeDuZgUQUfbMtjxXeH2ZlXH0Yt/n5c3rsz4wYlcmW/2LZdEl+8Xlx4IDPG9Cb9ip58uCOPxV9l801OMe9vPcz7Ww+T1iWCySNTuDYt4exD9JBbjf2hvvs/Yz2qu76A0M6t+0ZEfFirfyo4nU5iY2NZuHAhZrOZoUOHkpuby9NPP+0ONW+//TZvvvkmb731Fv3792fr1q1Mnz6dxMREpkyZck7XnT17NjNnznTft9lsJCcnt8h7Oq0Tx+G9uyGzthC6/y+M9SsCPTjjqgMosFWycpvRI/NtTrH7uL+fiUt7xTAuLZEx/eMI18J30sos/n5cNziJ6wYnsf1QCYvXZ7P8u8NsO1TCfe98xyMrvueGIUncPDyZ/okRp38xk8kYbs79Bo5mGtug3PpvY5d18Ro+Mom4VbXUz7BZoSYmJgaz2UxBQUGD4wUFBcTHxzf5nISEBAICAtxDTWCsNpifn4/dbsdisfDHP/6RWbNmuYeRBg4cyIEDB5g3bx5Tpkxxv3ZBQQEJCfU7ChcUFDB48OAmr2u1WrFarc15e+cvd4uxW29xDpgtxsrAw3+j4aZTOFZWxYc78lnx3WE2Zhe5N4Y0mWBk906MG5TIVf3jW3a6rUgzDOwSwTMTBjH76r4s2XyQtzbkcOj4CfeaNwOTIrh5eDI/H5x46sBtCTF6ahf9BPZ9Ap//BX78P237RqRV1NWJVlRUEBQU5OHWdGx1WzCcnBXORbNCjcViYejQoaxbt47rr78eMHpi1q1bd8qdO0eNGuXesdOvtvo/KyuLhIQELBbjw6qiosL9WB2z2exewTA1NZX4+HjWrVvnDjE2m40NGza0ya6fZ+RywcaFsOYBcFZDVApMeA0Sh3i6Ze1OyYlq1nxvBJmv9h7D4axP58O6RXFtWgI/G5ig/ZSkXekUauXuy3ty12U9+GrvMf61KYf/fF/A9twStueW8PjKnVwzMJGJFyUzrFtU49qb2H5Gj817U41FN7teDKmXeebNSIsxm81ERkZy5MgRAIKDtUzEuXA6nRQWFhIcHIy///kNIDX72TNnzmTKlCkMGzaMiy66iPnz51NeXs7tt98OwOTJk0lKSmLevHkATJ06leeff55p06bx+9//nt27dzN37lz3VG0wNtZ64okn6Nq1K/379+fbb791r2gIRjHf9OnTefzxx+nVq5d7SndiYqI7XHlMZQks/z3sfN+43/dauO4FCIr0aLPak/KqGtbuKmDFd3n8N6sQu6N+ue2BSRGMG5TANWmJJEXqLx1p3/xqh0Mv7RVDUbmdZd/m8q+NOew+Usa/vznEv785RI/OIUwc3pUbLkwiJvSk3uLBtxj7Q21909ge5a4vILTxMhjSsdSNJNQFGzk3fn5+dO3a9bxD4TmtKPz888/z9NNPk5+fz+DBg3nuuecYMcLYlfbyyy8nJSWF1157zX3++vXrmTFjBlu3biUpKYlf//rXDWY/lZaWMmfOHJYtW8aRI0dITEzkl7/8JQ8++KC7N8flcvHQQw+xcOFCiouLufTSS3nxxRfp3bv3WbW51aZ0714Lb44HP38Y8xhcPFXDTUBltYNPM4+w4rs81mUUUFldH2T6xIUxblAC16YlkhLTMTZ/EzkVl8vFNznFLNmUw4rv8jhRbWyKGmA2MeaCOG4e3pVLe8YYWzLYK4xhqMJdRk/Nr95TfY2XcDgcVFdXe7oZHZbFYmk0YlOnOZ/f2iahJXwxH7qNguThLfu6HYy9xskXewpZ8V0eH+0soKyqxv1YSqdgxg1K5Nq0RPrEt8KGgiLtQGllNR9sy+Nfmw7y3cFi9/GkyCAmDOvChGHJJFXnwMLLoboCLp8Nlzde30tE6inUNKHd7P3kZWocTr7eV8SK7w6z+vt8Sk7U/6WSFBnEtWkJjBuUSP/EcI01i0/ZlWdjyaaDLPs21/3/hckEl/XqzMzYbxi0+X7ABJPfg+6Xe7KpHZfLpZ5xH6BQ0wSFmpbjdLrYfOA4H2w7zKrteRwts7sf6xxm5ZqBRpAZkhypHa/F51VWO1jzfT5LNh3kq73H3MfnB73M9a511ATF4H/3lxDW9AxSaYLLBV89B5/MhbgBkHaTsXyG1gDySgo1TVCoOT8n77f0wbY88m31+y1FBQdw9cAExqUlclFqtFE7ICKNZB8t5+3NB3lnyyFspaW8Z5lDP7+D7LCkkfHTN7gmrQtBFtXYnFalDd6/G3ataHjcZDZ6vNJugr7XgFXD3N5CoaYJCjXNV7ffUl2Q+eF+S2MHxHNtmvZbEmmuGoeTTzIL+ezLL5h9aCohpir+VnMD/zT/kp8PTmTi8K4M7HKGhf180ZEMWHKrsVGoXwD89DHj+La34fA39ef5B0Gfq2HgBOg5Gvy11lVHplDTBIWas3e6/ZZGXxDHuLQELtN+SyItonjDm0R+eDdOTEyx38/nzjQA+ieGM3F4Mj8fnEREkFbSZse78P49UF0O4Ulw0+vQZVj948f2wvZ3jIBTtLf+eGAk9L8eBt4EXUdqt/QOSKGmCQo1Z/bO5oO8+mV2o/2Wruhj7Lf0k77ab0mkVayYBlteo9oazSNdFvJ2Ro17PServx/XDEzg5uHJXJQa7XsF945q+OhB+PpF437qZXDjqxAS0/T5Lhcc/ha2L4Ud/4ayk/YHDO8CA8cbPThxA1Rk3EEo1DRBoeb0iivsDHnsI1wuY7+lH/WK4VrttyTSNqpPwD/HQMF26DaK4zcu5b1tBfxr40EyC0rdp3WPCeGm4cmMv7ALncPaeBsYTyjNN7aeyVlv3L90BlzxJzCf5R9XTgdkfw7b3oFdy6Gq/g82OveDgTcaASeqW4s3XVqOQk0TFGpOb8O+Y9y88GsSIgJZde+PtN+SSFs7ugcW/hjsZfCjP8CVD+JyufjuUAlLNuWwfOthyu3Gwn7+fiau7BfLxOFduax3Z+8szj+wHt6ZAmUFYA2H61+Cftee++tVV8LuNcYQVdYacNTP2iR5hBFu+t9w6h4g8RiFmiYo1Jze/67PZs7733Nl31hevs23FxEU8ZjtS+Hfvza+v/XfRpFrrfKqGlZuy+Nfm3L45qSd7BMiApkw1FjYLzk6uI0b3ApcLtiwAP7zJ3DWGD0qN78BMT1b7honio3ZU9vfhv2fA3W76Zqh55VGwOnzM7CGttw15Zwp1DRBoeb0Hli2nTc35HD35T34n6v6ero5Ir7rgxmw+RUI7gS/+xwikhqdkplfypJNB3n320MUV9Qv7HdpzxgmDu/K6Atisfp3wEL+qjJjL73v3zXuD7gRfv6csdN5a7HlGbU329+BvK31xwOCjWCTdhP0+AmYNQzvKQo1TVCoOb0JC75iU/Zx/jZxMNcNbvyPqIi0kepKeHkM5G8zZutM+eCUNSRVNQ7+830BSzYd5Is9R93Ho0Ms/GJIEjcPT6ZXXAdZr+XobmO6dmGGsZfeT5+AEb9r22LewizYsdSYQXV8f/3xoGhjaGrgBGOoSjOo2pRCTRMUak7N5XIx6JH/YKus4cNpP6Jfgn4+Ih51bC/848dgLzWKY0c/fManHCyq4O3NB3l780EKbFXu40O7RXHz8GSuTUtov7MXd62AZVON9xsaDzcthq4Xe649LhfkfmP03uz4N5SftAN3RNfaGVQ3QdwFnmujD1GoaYJCzanll1Ry8bx1mP1M7Hx0bMfsthbxNt8vM2b+ANzyDvT+6Vk9rcbh5L+7C/nXxoOsyziCw2n8Ex9q9WfcoEQmDk8mrUtE+5ga7qiBjx+DL+cb97uNMqZrh8V5tFkNOGog+7+1M6hWGMGrTmx/SJsAA8ZDZFfPtdHLKdQ0QaHm1D7NPMJtr26iV2woH838saebIyJ1Vt4HmxZBUBTc9QVEdGnW04+UVvLvLbks2ZRD9rH6FcH7xodxSY8YBnYJZ2BSJN1jQtp+n7ayQlh6uzHlGmDkPUaPVHuuXak+AVmrjYLu3f9pOIOq68j6GVTB0Z5roxdSqGmCQs2pLfzvXuauyuCatAReuOVCTzdHROrUVBn1NXnfGbUct608pw99l8vF1/uKWLIph1U78rHXOBs8Hmr154LEcNKSIhjYJYKBSRGkdGrFoHNwE7w9GUoPQ0AIXP+CEQY6khPHYedyY4gq+wvcM6j8/I1ZawMnGFs1tGaRczvgdLrIKaogI9/GrrxSgixm7vpxjxa9hkJNExRqTu0Pb3/Hv785xMwxvbn3yl6ebo6InKxon1FfU2WDS+6t3+/oHJVUVLMuo4Bth0rYnlvC94dLqKx2NjovzOpP/6Rw0rpEMiApgrSkCLp1Cj6/YSuXCzb9E1bPBmc1xPQ2pmt37nMe76gdKMmtn0GVv63+eECIsbbOwAnGZpvtuRfqLNgqq8nIK3UHmIx8G5n5pVTUrp8EkNIpmE//eEXLXlehpjGFmlMb9/cv2J5bwoJbh3LVgHhPN0dEfmjn+0bPBsAvl0Cfq1rspWscTvYWlrM9t4Tth4rZllvCzsM2qmqaCDqB/gxMMnpy6np0ukafZdCxVxjT1bf9y7h/wXVw3Qvet5t2YaYRbra/A8ez648Hxxi9UWk3QZfh7XqLBofTxf6j5WTk2xqEmNziE02eb/H3o3dcKP3iw+mXEM7to1JatGZLoaYJCjVNczhd9H9oNZXVTj6973JSYry7q1Skw/rwfmNRusBIo74mMrnVLlXjcLL7SFlt0DF6dHbm2RoNWwFEBAUwMCnC6M2pDTpdooIafqgV7YMlv4KCHcYCd2MeMWpo2vEH+3lzueDQZmOBvx3vQkX9lHsiuxm9NwMnQKxn1wU7Xm5n10nhJSO/lMz80iZDLUBiRCD9EsLpmxBG3/hw+iWEkdIpBH9z601zV6hpgkJN0/YfLeeKZz4lMMCP7x+5yjuXWxfxBjVV8MpVcPgb4y/921aBf9ttZ1LtcLK7oIztucVsO1TCjtwSduWVujfePFlkcIC7R+dKvy0M2TwLP7sNQjobs5tSf9Rm7W4XHDWw71Oj9ybjA2MrjDrxA41FBqO7t2oTapwuCmyV5Baf4NDxE+QWV5B7vJLjFfYmz7ea/UiICiI5KoikyNpbVDAhljPMjrWEGKsytyCFmiYo1DRt9Y587npjCwOTIljx+0s93RwROZ3j2fCPy6CyxOjpGPuER5tjr3GSVVDK9twSd9DJyLdR7XDhh5Pp/ku51/89ALbSh1cTHya5Ww/30FVCRGD7mFreluwVkPWhMUV8z0fGVhDepFMv+P3mFn3J5nx+t9OVmKStZNXuANy7o6w6KuLLolLguhdhySRY/zx0uwT6XuOx5lj8/RhQO/T0y4uMY1U1DvZmHyRy9VQSj34FwGLHWB6vnkT1Phfs2+N+fkyoxV2EbAxfRRIXbvXuoGMJNta1GTAeKoqMeqmMlQ17b86S0+WistpBhd24naj9Wu1seujIbDIRbDETZDG7vwYF+OPfkj30zVx2oKUp1Pi4zNpQ0ydeG7eJdAj9roWL74avX4T3phr7Q0V183Sr3KwF33HBiilQkmPsnzTuOW7u9wsG55eyLbeEHYdK2JZbQlZBKUfL7HyaWcinmYXu58eEWt21OQNr63RiwwM9+I5aUXA0DLvduJ2Gy+XiSGkVO/NOqn3JK2VvYRk1zsaDLSYTpHQKoV9t3Uvf+DD6JYSTFBnU9usRtTGFGh+XmV8XajQkJ9JhjH4EDm6A3C3GAna3r27T+ppT2rIYVt1nLEoX3d2Yrh3Xn0BgUHIkg5Ij3adWVjvYlWdrUIy8+0gZR8uq+DjjCB9n1G9NEBtmBJ26YuQBSRHEhnln0KmsdrC7oIxdebYGBbzHazcu/aHwQH/6JRizjvrGh9E3IZzecaHtd0uMVuab71oAo5t4/9FyAPpo+Emk4/C3wITXYMGlRrBZ+xBcNc9z7ak+YYSZb98w7ve5Bm54CQIjTvmUwAAzQ7pGMaRrlPvYCbuDnXk2dtTW6GzPLWbPkTKOlFaxdtcR1u6qDzrx4YH0TwwnNND4GDMBJpMJU90dwIQJk8l9t/Z7k3vSlan2ZPf9k86pP58Gw2GNXqPuWO2Buus3fo0m2lR70Ol0sf9YORl5NvYfLaeJzhf8TNC9c6g7vNT1wvhkXdJpKNT4sH2F5TicLsID/YkLt3q6OSLSHJFd4foF8K9fGkNR3S6BfuPavh3HD8DbvzJWPTb5wU/+BKNmnNNO1kEWM0O7RTG0W33QqbDXsPNwfY/OttwS9haWkW+rJN9W2ZLvpN2IDrE0GjrqGRtKYID25TsThRofluWupwlT0hfpiPr+zJgFtf55eC/dmB4cldJ219+9Ft79jbFlQHAnGP8y9GjZ1WSDLf4MS4lmWEr9fkrlVTV8f9hGZn7DRQJdLnDVbldgfN/4mPH19Oe4Tjr55Mfdzz/5OQ2ONX3OyXOMXa66KzW8bnJUMH0TwukXH0bnMC8vlm5FCjU+rL6eRkNPIh3W6IeN+ppDm4xdve9YA/6t3PPqdMLnz8AncwEXJF4IN73eqgsCnizE6s9FqdFclKqNI6Wh1lsCUNo9d6hRPY1Ix2UOMBa0C4qCw9/Cf+a07vVOHIf/mwifPAG4YOjtcMfqNgs0IqejUOPDMrVGjYh3iEyGG/5hfL/xH8baJ60hbxssvBx2rwH/QGPNnHHzW79nSOQsKdT4qLKqGg4dNzYnU6gR8QK9x8Koacb3799j7LfUkrb+H7w8xljVOLIb/PojGDKpZa8hcp4UanzU7tpemtgwK1Eh7WB9CxE5fz+ZA8kjoMpm1NdUt8DsoJoq+GAmvHcX1FRCr5/C7z6DhLTzf22RFqZQ46NUJCzihdz1NdHGFOv//On8Xq/kELx6NWx+GTDB5f8PfrnEqN8RaYcUanyUe3sEDT2JeJeIJPjFQuP7TYtgx7vn9jr7PjU2z8zdAoGRMOkduPz+c1p/RqSt6L9OH+XeyFI9NSLep9cYuHSG8f3ye+HY3rN/rssFnz8L/3sDVByD+DRjuKnXmNZpq0gLUqjxUZn5xo6w6qkR8VJX/Am6XgL2UnhnytnV11SWwJJbYd0j4HLC4Fvh1/9p2wX9RM6DQo0POlZWxdGyKkwm6BWn3blFvJLZH2582VjpN387rJl9+vMLdsLCKyDjAzBbYNzf4LrnISCobdor0gIUanxQXT1N1+hgn93JVcQnhCfW1teYYPMrsH1p0+dtXwr/vBKK9kJEsrGY3tDb6ndhFOkgFGp8UFa+Ft0T8Rk9R8OP/mB8v2IaHN1T/1iNHT68H/79a6iugO5XwG8/g6ShnmmryHlSqPFBmQWqpxHxKZfPhm6Xgr2str7mBNjyYPE42LDAOOdH98Gt/4aQTp5tq8h50NiDD9LMJxEfY/aH8f+EBZdCwQ5jYb7cb6D8CFgj4Bf/gD5Xe7qVIudNPTU+xuVyuYef+irUiPiO8AQj2GCCrNVGoIntD7/9RIFGvIZCjY85XFJJaVUNAWYTKZ1CPN0cEWlLPa6AK+cAJkibCL9ZC516eLpVIi1Gw08+pq6XpntMKBZ/ZVoRn/OjP8BFvwWremrF++hTzcdkqp5GRBRoxEsp1PiYTNXTiIiIl1Ko8TGZWqNGRES8lEKND6lxONlTqDVqRETEOynU+JADRRXYa5wEBZjpEqX9XERExLso1PiQ+qGnUPz8tKeLiIh4F4UaH1IXavqoSFhERLyQQo0PcW+PoHoaERHxQgo1PqRujRr11IiIiDdSqPERldUOso+WA5r5JCIi3kmhxkfsOVKG0wVRwQF0DrN6ujkiIiIt7pxCzQsvvEBKSgqBgYGMGDGCjRs3nvb84uJi0tPTSUhIwGq10rt3b1atWuV+PCUlBZPJ1OiWnp7uPufyyy9v9Phdd911Ls33SSfX05hMmvkkIiLep9kbWi5ZsoSZM2eyYMECRowYwfz58xk7diyZmZnExsY2Ot9utzNmzBhiY2NZunQpSUlJHDhwgMjISPc5mzZtwuFwuO/v2LGDMWPGMGHChAavdeedd/Loo4+67wcHBze3+T5L9TQiIuLtmh1qnn32We68805uv/12ABYsWMDKlSt55ZVXmDVrVqPzX3nlFYqKivjqq68ICAgAjJ6Zk3Xu3LnB/T//+c/06NGDH//4xw2OBwcHEx8f39wmC/W7c2vmk4iIeKtmDT/Z7Xa2bNnC6NGj61/Az4/Ro0ezfv36Jp+zfPlyRo4cSXp6OnFxcQwYMIC5c+c26Jn54TXeeOMN7rjjjkbDJG+++SYxMTEMGDCA2bNnU1FRccq2VlVVYbPZGtx8mTayFBERb9esnpqjR4/icDiIi4trcDwuLo6MjIwmn7Nv3z4+/vhjJk2axKpVq9izZw9333031dXVPPTQQ43Of++99yguLua2225rcPyWW26hW7duJCYmsm3bNu6//34yMzN59913m7zuvHnzeOSRR5rz9ryWrbKawyWVAPRST42IiHipZg8/NZfT6SQ2NpaFCxdiNpsZOnQoubm5PP30002Gmpdffpmrr76axMTEBsd/+9vfur8fOHAgCQkJXHnllezdu5cePXo0ep3Zs2czc+ZM932bzUZycnILvrOOY3dtPU1CRCARQQEebo2IiEjraFaoiYmJwWw2U1BQ0OB4QUHBKWtdEhISCAgIwGw2u4/169eP/Px87HY7FovFffzAgQOsXbv2lL0vJxsxYgQAe/bsaTLUWK1WrFZNXQbIzDd25lY9jYiIeLNm1dRYLBaGDh3KunXr3MecTifr1q1j5MiRTT5n1KhR7NmzB6fT6T6WlZVFQkJCg0AD8OqrrxIbG8s111xzxrZs3boVMEKTnF6WZj6JiIgPaPY6NTNnzmTRokUsXryYXbt2MXXqVMrLy92zoSZPnszs2bPd50+dOpWioiKmTZtGVlYWK1euZO7cuQ3WoAEjHL366qtMmTIFf/+GHUh79+7lscceY8uWLWRnZ7N8+XImT57MZZddRlpa2rm8b5+SkW8USWslYRER8WbNrqm5+eabKSws5MEHHyQ/P5/BgwezevVqd/FwTk4Ofn71WSk5OZk1a9YwY8YM0tLSSEpKYtq0adx///0NXnft2rXk5ORwxx13NLqmxWJh7dq1zJ8/n/LycpKTkxk/fjx/+tOfmtt8n+NyubQ7t4iI+ASTy+VyeboRbcFmsxEREUFJSQnh4eGebk6bKSytYvgTazGZYNejVxEYYD7zk0RERNqJ5nx+a+8nL1dXT5PSKUSBRkREvJpCjZfLqBt6Uj2NiIh4OYUaL+feHkH1NCIi4uUUaryceyNL9dSIiIiXU6jxYk6ny72acJ/4UA+3RkREpHUp1Hix3OITlNsdWMx+dOsU4unmiIiItCqFGi9Wtz5Nj9hQAsz6VYuIiHfTJ50Xq6+n0dCTiIh4P4UaL1a3Ro1mPomIiC9QqPFimVqjRkREfIhCjZeqdjjZW1gGaM8nERHxDQo1Xir7aDnVDhchFjNJkUGebo6IiEirU6jxUpkn1dOYTCYPt0ZERKT1KdR4qSzV04iIiI9RqPFSdRtZ9laoERERH6FQ46XqpnP3VZGwiIj4CIUaL3TC7uBAUQWgNWpERMR3KNR4oT1HynC5oFOIhZhQq6ebIyIi0iYUaryQe+aT6mlERMSHKNR4ocx8G6BF90RExLco1HihzAKtJCwiIr5HocYLZWk6t4iI+CCFGi9TUlFNvq0SgN5xoR5ujYiISNtRqPEydUXCSZFBhAUGeLg1IiIibUehxsvUhRrV04iIiK9RqPEyqqcRERFfpVDjZep7alRPIyIivkWhxou4XC4y1VMjIiI+SqHGixwpraLkRDVmPxM9OqunRkREfItCjRep66VJ6RRMYIDZw60RERFpWwo1XiRLM59ERMSHKdR4EdXTiIiIL1Oo8SLumU8KNSIi4oMUaryE0+nS8JOIiPg0hRovcfB4BZXVTiz+fnTrFOLp5oiIiLQ5hRovUVdP0ys2FLOfycOtERERaXsKNV6iLtSonkZERHyVQo2X0EaWIiLi6xRqvERdkXBvhRoREfFRCjVewF7jZF9hOaDhJxER8V0KNV5g/9FyapwuwgL9SYgI9HRzREREPEKhxgtk5NsAo5fGZNLMJxER8U0KNV5A9TQiIiIKNV4hM78MUD2NiIj4NoUaL+DuqVGoERERH6ZQ08GVV9WQU1QBaI0aERHxbQo1HdzuI8bQU+cwK9EhFg+3RkRExHMUajq4LG2PICIiAijUdHiZqqcREREBFGo6PPdGlvGhHm6JiIiIZynUdHD1G1mGe7glIiIinqVQ04EVldspLK0CoFesempERMS3KdR0YHXr0yRHBxFi9fdwa0RERDxLoaYDqws1mvkkIiJyjqHmhRdeICUlhcDAQEaMGMHGjRtPe35xcTHp6ekkJCRgtVrp3bs3q1atcj+ekpKCyWRqdEtPT3efU1lZSXp6Op06dSI0NJTx48dTUFBwLs33Ghn5mvkkIiJSp9mhZsmSJcycOZOHHnqIb775hkGDBjF27FiOHDnS5Pl2u50xY8aQnZ3N0qVLyczMZNGiRSQlJbnP2bRpE3l5ee7bRx99BMCECRPc58yYMYMVK1bwzjvv8Nlnn3H48GF+8YtfNLf5XsW9Ro1WEhYREcHkcrlczXnCiBEjGD58OM8//zwATqeT5ORkfv/73zNr1qxG5y9YsICnn36ajIwMAgICzuoa06dP54MPPmD37t2YTCZKSkro3Lkzb731FjfeeCMAGRkZ9OvXj/Xr13PxxRef8TVtNhsRERGUlJQQHt7xZwq5XC7SHvkPpZU1rJ7+I/pq9pOIiHih5nx+N6unxm63s2XLFkaPHl3/An5+jB49mvXr1zf5nOXLlzNy5EjS09OJi4tjwIABzJ07F4fDccprvPHGG9xxxx2YTCYAtmzZQnV1dYPr9u3bl65du57yut4u31ZJaWUN/n4musdo5pOIiEizpswcPXoUh8NBXFxcg+NxcXFkZGQ0+Zx9+/bx8ccfM2nSJFatWsWePXu4++67qa6u5qGHHmp0/nvvvUdxcTG33Xab+1h+fj4Wi4XIyMhG183Pz2/yulVVVVRVVbnv22y2s3yXHUNdPU1qTAgWf9V7i4iItPqnodPpJDY2loULFzJ06FBuvvlmHnjgARYsWNDk+S+//DJXX301iYmJ53XdefPmERER4b4lJyef1+u1N6qnERERaahZoSYmJgaz2dxo1lFBQQHx8fFNPichIYHevXtjNpvdx/r160d+fj52u73BuQcOHGDt2rX85je/aXA8Pj4eu91OcXHxWV939uzZlJSUuG8HDx4827fZIWRqOreIiEgDzQo1FouFoUOHsm7dOvcxp9PJunXrGDlyZJPPGTVqFHv27MHpdLqPZWVlkZCQgMViaXDuq6++SmxsLNdcc02D40OHDiUgIKDBdTMzM8nJyTnlda1WK+Hh4Q1u3qRujZre6qkREREBzmH4aebMmSxatIjFixeza9cupk6dSnl5ObfffjsAkydPZvbs2e7zp06dSlFREdOmTSMrK4uVK1cyd+7cBmvQgBGOXn31VaZMmYK/f8NSn4iICH79618zc+ZMPvnkE7Zs2cLtt9/OyJEjz2rmk7dxOF3sLigD1FMjIiJSp9lr6998880UFhby4IMPkp+fz+DBg1m9erW7eDgnJwc/v/qslJyczJo1a5gxYwZpaWkkJSUxbdo07r///gavu3btWnJycrjjjjuavO5f//pX/Pz8GD9+PFVVVYwdO5YXX3yxuc33CgeOlVNV4yQwwI/k6GBPN0dERKRdaPY6NR2VN61Ts3pHHne98Q1pXSJYfs+lnm6OiIhIq2m1dWqkfcjMN4aetD2CiIhIPYWaDkgbWYqIiDSmUNMBZeQbCwlq5pOIiEg9hZoOprLaQfaxCgD6KtSIiIi4KdR0MPsKy3E4XUQEBRAbZvV0c0RERNoNhZoO5uR6mroNP0VEREShpsOp28iyd7x25hYRETmZQk0Ho5lPIiIiTVOo6WAy3btzd+wFBEVERFqaQk0HUlpZTW7xCQB6x2n4SURE5GQKNR3I7iPGSsJx4VYigy1nOFtERMS3KNR0IHVDT9oeQUREpDGFmg6kLtRo0T0REZHGFGo6kLqZT+qpERERaUyhpgNxT+dWT42IiEgjCjUdxNGyKo6W2TGZoFesQo2IiMgPKdR0EFm19TTdooMJspg93BoREZH2R6Gmg8hUPY2IiMhpKdR0EKqnEREROT2Fmg4iQ2vUiIiInJZCTQfgcrncNTXqqREREWmaQk0HkFt8gnK7gwCzidSYEE83R0REpF1SqOkA6uppenQOJcCsX5mIiEhT9AnZAWTmGxtZqp5GRETk1BRqOoDMfBugehoREZHTUajpADILjJ6aPuqpEREROSWFmnauxuFk75HaUKOeGhERkVNSqGnnso9VYHc4CbaYSYoM8nRzRERE2i2FmnYus3Z9ml5xYfj5mTzcGhERkfZLoaadq9vzqU9cqIdbIiIi0r4p1LRz9SsJh3u4JSIiIu2bQk07597IUjOfRERETkuhph2rrHaQfawcgN7xGn4SERE5HYWadmzPkTKcLogKDqBzqNXTzREREWnXFGrascyTduY2mTTzSURE5HQUatox1dOIiIicPYWadqxuOndvrSQsIiJyRgo17Zh7+Ek9NSIiImekUNNOlZyoJq+kEjBWExYREZHTU6hpp3bXDj0lRgQSERTg4daIiIi0fwo17ZTqaURERJpHoaadUj2NiIhI8yjUtFN1oaa3Qo2IiMhZUahph1wuV/0aNRp+EhEROSsKNe1QYVkVxyuq8TNBz1jt+SQiInI2FGraoaz8MgBSOoUQGGD2cGtEREQ6BoWadigj3waonkZERKQ5FGraoSxN5xYREWk2hZp2KLPAGH7qq1AjIiJy1hRq2hmn0+VeTVjDTyIiImdPoaadOXT8BBV2BxazHymdgj3dHBERkQ5DoaadqdseoUdsKP5m/XpERETOlj4125m6ImHV04iIiDSPQk07o+0RREREzs05hZoXXniBlJQUAgMDGTFiBBs3bjzt+cXFxaSnp5OQkIDVaqV3796sWrWqwTm5ubnceuutdOrUiaCgIAYOHMjmzZvdj992222YTKYGt6uuuupcmt+u1W+PoJWERUREmsO/uU9YsmQJM2fOZMGCBYwYMYL58+czduxYMjMziY2NbXS+3W5nzJgxxMbGsnTpUpKSkjhw4ACRkZHuc44fP86oUaO44oor+PDDD+ncuTO7d+8mKiqqwWtdddVVvPrqq+77Vqu1uc1v16odTvYWGtO51VMjIiLSPM0ONc8++yx33nknt99+OwALFixg5cqVvPLKK8yaNavR+a+88gpFRUV89dVXBAQEAJCSktLgnCeffJLk5OQGgSU1NbXRa1mtVuLj45vb5A5j/9Fyqh0uQq3+JEUGebo5IiIiHUqzhp/sdjtbtmxh9OjR9S/g58fo0aNZv359k89Zvnw5I0eOJD09nbi4OAYMGMDcuXNxOBwNzhk2bBgTJkwgNjaWIUOGsGjRokav9emnnxIbG0ufPn2YOnUqx44da07z2736eppQTCaTh1sjIiLSsTQr1Bw9ehSHw0FcXFyD43FxceTn5zf5nH379rF06VIcDgerVq1izpw5/OUvf+Hxxx9vcM5LL71Er169WLNmDVOnTuXee+9l8eLF7nOuuuoqXn/9ddatW8eTTz7JZ599xtVXX90gHJ2sqqoKm83W4Nbe1dfTaOhJRESkuZo9/NRcTqeT2NhYFi5ciNlsZujQoeTm5vL000/z0EMPuc8ZNmwYc+fOBWDIkCHs2LGDBQsWMGXKFAAmTpzofs2BAweSlpZGjx49+PTTT7nyyisbXXfevHk88sgjrf32WlSGZj6JiIics2b11MTExGA2mykoKGhwvKCg4JS1LgkJCfTu3Ruz2ew+1q9fP/Lz87Hb7e5zLrjgggbP69evHzk5OadsS/fu3YmJiWHPnj1NPj579mxKSkrct4MHD57Ve/Qkd0+NQo2IiEizNSvUWCwWhg4dyrp169zHnE4n69atY+TIkU0+Z9SoUezZswen0+k+lpWVRUJCAhaLxX1OZmZmg+dlZWXRrVu3U7bl0KFDHDt2jISEhCYft1qthIeHN7i1ZxX2GnKKKgANP4mIiJyLZq9TM3PmTBYtWsTixYvZtWsXU6dOpby83D0bavLkycyePdt9/tSpUykqKmLatGlkZWWxcuVK5s6dS3p6uvucGTNm8PXXXzN37lz27NnDW2+9xcKFC93nlJWV8cc//pGvv/6a7Oxs1q1bx3XXXUfPnj0ZO3bs+f4M2oU9R8pwuSAm1EKnUO+aqi4iItIWml1Tc/PNN1NYWMiDDz5Ifn4+gwcPZvXq1e7i4ZycHPz86rNScnIya9asYcaMGaSlpZGUlMS0adO4//773ecMHz6cZcuWMXv2bB599FFSU1OZP38+kyZNAsBsNrNt2zYWL15McXExiYmJ/PSnP+Wxxx7zmrVqVE8jIiJyfkwul8vl6Ua0BZvNRkREBCUlJe1yKOrxD3byzy/2c9slKTz88/6ebo6IiEi70JzPb+391E5kaiNLERGR86JQ007UzXzqrVAjIiJyThRq2oHiCjsFtioAesVqI0sREZFzoVDTDtRtj5AUGURYYICHWyMiItIxKdS0A9oeQURE5Pwp1LQDmQo1IiIi502hph3Iyi8DtD2CiIjI+VCo8TCXy0VGvrGDuBbeExEROXcKNR5WYKvCVlmD2c9Ej9gQTzdHRESkw1Ko8bC6eprUmBCs/uYznC0iIiKnolDjYVm107lVTyMiInJ+FGo8rK6nRvU0IiIi50ehxsPqFt7rE6+VhEVERM6HQo0HOZwudh9RT42IiEhLUKjxoINFFVRWO7H6+9Gtk2Y+iYiInA+FGg+qq6fpFReK2c/k4daIiIh0bAo1HlRXT6OhJxERkfOnUONB7j2fFGpERETOm0KNB7nXqNFGliIiIudNocZDqmoc7D9aDijUiIiItASFGg/ZV1hOjdNFWKA/8eGBnm6OiIhIh6dQ4yFZJ9XTmEya+SQiInK+FGo8xD3zSUNPIiIiLUKhxkPqemr6KtSIiIi0CIUaD9FGliIiIi1LocYDyqpqOFh0AlCoERERaSkKNR6wu7aXpnOYlegQi4dbIyIi4h0UajxA9TQiIiItT6HGAzLzywANPYmIiLQkhRoPyCywAdrzSUREpCUp1HiAu6dGw08iIiItRqGmjR0rq+JoWRUAvWJDPdwaERER76FQ08ayCoxemq7RwYRY/T3cGhEREe+hUNPGMvONehoVCYuIiLQshZo2llnbU9MnXkNPIiIiLUmhpo1laXsEERGRVqFQ04ZcLhdZ+XUL74V7uDUiIiLeRaGmDeWVVFJaVYO/n4nUmBBPN0dERMSrKNS0oczaXprunUOw+OtHLyIi0pL0ydqGMlVPIyIi0moUatpQfT2NQo2IiEhLU6hpQ+qpERERaT0KNW2kxuFk95G6NWoUakRERFqaQk0bOVBUgb3GSWCAH8lRwZ5ujoiIiNdRqGkjdfU0vePC8PMzebg1IiIi3kehpo3U1dP0UT2NiIhIq1CoaSN12yOonkZERKR1KNS0kYx8zXwSERFpTQo1baCy2kH20XJAPTUiIiKtRaGmDewtLMPpgsjgAGLDrJ5ujoiIiFdSqGkDWSctumcyaeaTiIhIa1CoaQN19TSa+SQiItJ6FGragHuNGtXTiIiItBqFmjaQVVC7PYJ6akRERFqNQk0rK62sJrf4BKBQIyIi0prOKdS88MILpKSkEBgYyIgRI9i4ceNpzy8uLiY9PZ2EhASsViu9e/dm1apVDc7Jzc3l1ltvpVOnTgQFBTFw4EA2b97sftzlcvHggw+SkJBAUFAQo0ePZvfu3efS/DZVVyQcHx5IRHCAh1sjIiLivZodapYsWcLMmTN56KGH+Oabbxg0aBBjx47lyJEjTZ5vt9sZM2YM2dnZLF26lMzMTBYtWkRSUpL7nOPHjzNq1CgCAgL48MMP2blzJ3/5y1+Iiopyn/PUU0/x3HPPsWDBAjZs2EBISAhjx46lsrLyHN5228nMN4aeVE8jIiLSuvyb+4Rnn32WO++8k9tvvx2ABQsWsHLlSl555RVmzZrV6PxXXnmFoqIivvrqKwICjJ6KlJSUBuc8+eSTJCcn8+qrr7qPpaamur93uVzMnz+fP/3pT1x33XUAvP7668TFxfHee+8xceLE5r6NNuPeHiEu1MMtERER8W7N6qmx2+1s2bKF0aNH17+Anx+jR49m/fr1TT5n+fLljBw5kvT0dOLi4hgwYABz587F4XA0OGfYsGFMmDCB2NhYhgwZwqJFi9yP79+/n/z8/AbXjYiIYMSIEae8blVVFTabrcHNEzLrpnPHh3vk+iIiIr6iWaHm6NGjOBwO4uLiGhyPi4sjPz+/yefs27ePpUuX4nA4WLVqFXPmzOEvf/kLjz/+eINzXnrpJXr16sWaNWuYOnUq9957L4sXLwZwv3Zzrjtv3jwiIiLct+Tk5Oa81RaTpd25RURE2kSzh5+ay+l0Ehsby8KFCzGbzQwdOpTc3FyefvppHnroIfc5w4YNY+7cuQAMGTKEHTt2sGDBAqZMmXJO1509ezYzZ85037fZbG0ebApLqzhWbsdkgp6xGn4SERFpTc3qqYmJicFsNlNQUNDgeEFBAfHx8U0+JyEhgd69e2M2m93H+vXrR35+Pna73X3OBRdc0OB5/fr1IycnB8D92s25rtVqJTw8vMGtrdX10nSLDibIYj7D2SIiInI+mhVqLBYLQ4cOZd26de5jTqeTdevWMXLkyCafM2rUKPbs2YPT6XQfy8rKIiEhAYvF4j4nMzOzwfOysrLo1q0bYBQNx8fHN7iuzWZjw4YNp7xue1BXT9NbQ08iIiKtrtlTumfOnMmiRYtYvHgxu3btYurUqZSXl7tnQ02ePJnZs2e7z586dSpFRUVMmzaNrKwsVq5cydy5c0lPT3efM2PGDL7++mvmzp3Lnj17eOutt1i4cKH7HJPJxPTp03n88cdZvnw527dvZ/LkySQmJnL99def54+g9dT11PTVdG4REZFW1+yamptvvpnCwkIefPBB8vPzGTx4MKtXr3YX8ebk5ODnV5+VkpOTWbNmDTNmzCAtLY2kpCSmTZvG/fff7z5n+PDhLFu2jNmzZ/Poo4+SmprK/PnzmTRpkvuc//mf/6G8vJzf/va3FBcXc+mll7J69WoCAwPP5/23qgzt+SQiItJmTC6Xy+XpRrQFm81GREQEJSUlbVJf43S6GPjwGsrtDj6acRm9NAQlIiLSbM35/NbeT60kt/gE5XYHAWYTKTEhnm6OiIiI11OoaSV19TQ9OocSYNaPWUREpLXp07aVZNYtuqd6GhERkTahUNNKNJ1bRESkbSnUtBL3nk8KNSIiIm1CoaYVVDuc7CssBzT8JCIi0lYUalrBgWPl2B1OQixmkiKDPN0cERERn6BQ0wrqFt3rFReGn5/Jw60RERHxDQo1rSBL9TQiIiJtTqGmFdRN59b2CCIiIm1HoaYVZBWUAdrIUkREpC0p1LSwE3YH2ceMmU9ao0ZERKTtKNS0sD1HynC5IDrEQkyoxdPNERER8RkKNS3MXU8TF4rJpJlPIiIibUWhpoXVbWSpmU8iIiJtS6Gmhbm3R4gP93BLREREfItCTQurDzWhHm6JiIiIb1GoaUElFdXk2yoBYzVhERERaTsKNS0o64jRS5MYEUh4YICHWyMiIuJbFGpaUP3Qk3ppRERE2ppCTQuqCzXaHkFERKTtKdS0oExN5xYREfEYhZoW4nK53GvUaHsEERGRtqdQ00IKS6sorqjGzwQ9YzWdW0REpK0p1LSQuqGnlJgQAgPMHm6NiIiI71GoaSHumU8aehIREfEIhZoW4p75pFAjIiLiEQo1LcS9kaWmc4uIiHiEQk0LcDpdZBWUAQo1IiIinqJQ0wIOHq/gRLUDi78f3aKDPd0cERERn6RQ0wLq6ml6dg7F36wfqYiIiCfoE7gFqJ5GRETE8xRqWkCm6mlEREQ8TqGmBWTm2wCtUSMiIuJJCjXnyV7jZF9hOaDduUVERDxJoeY87T9aTo3TRajVn8SIQE83R0RExGf5e7oBHV1kcAD3X9WXymoHJpPJ080RERHxWQo15ykuPJCpl/fwdDNERER8noafRERExCso1IiIiIhXUKgRERERr6BQIyIiIl5BoUZERES8gkKNiIiIeAWFGhEREfEKCjUiIiLiFRRqRERExCso1IiIiIhXUKgRERERr6BQIyIiIl5BoUZERES8gs/s0u1yuQCw2WwebomIiIicrbrP7brP8dPxmVBTWloKQHJysodbIiIiIs1VWlpKRETEac8xuc4m+ngBp9PJ4cOHCQsLw2Qyebo57ZLNZiM5OZmDBw8SHh7u6eb4PP0+2hf9Ptof/U7al9b6fbhcLkpLS0lMTMTP7/RVMz7TU+Pn50eXLl083YwOITw8XP9AtCP6fbQv+n20P/qdtC+t8fs4Uw9NHRUKi4iIiFdQqBERERGvoFAjblarlYceegir1erppgj6fbQ3+n20P/qdtC/t4ffhM4XCIiIi4t3UUyMiIiJeQaFGREREvIJCjYiIiHgFhRoRERHxCgo1wrx58xg+fDhhYWHExsZy/fXXk5mZ6elmSa0///nPmEwmpk+f7umm+Kzc3FxuvfVWOnXqRFBQEAMHDmTz5s2ebpZPcjgczJkzh9TUVIKCgujRowePPfbYWe0LJC3jv//9L+PGjSMxMRGTycR7773X4HGXy8WDDz5IQkICQUFBjB49mt27d7dJ2xRqhM8++4z09HS+/vprPvroI6qrq/npT39KeXm5p5vm8zZt2sQ//vEP0tLSPN0Un3X8+HFGjRpFQEAAH374ITt37uQvf/kLUVFRnm6aT3ryySd56aWXeP7559m1axdPPvkkTz31FH//+9893TSfUV5ezqBBg3jhhReafPypp57iueeeY8GCBWzYsIGQkBDGjh1LZWVlq7dNU7qlkcLCQmJjY/nss8+47LLLPN0cn1VWVsaFF17Iiy++yOOPP87gwYOZP3++p5vlc2bNmsWXX37J559/7ummCHDttdcSFxfHyy+/7D42fvx4goKCeOONNzzYMt9kMplYtmwZ119/PWD00iQmJvKHP/yB++67D4CSkhLi4uJ47bXXmDhxYqu2Rz010khJSQkA0dHRHm6Jb0tPT+eaa65h9OjRnm6KT1u+fDnDhg1jwoQJxMbGMmTIEBYtWuTpZvmsSy65hHXr1pGVlQXAd999xxdffMHVV1/t4ZYJwP79+8nPz2/w71ZERAQjRoxg/fr1rX59n9nQUs6O0+lk+vTpjBo1igEDBni6OT7rX//6F9988w2bNm3ydFN83r59+3jppZeYOXMm/+///T82bdrEvffei8ViYcqUKZ5uns+ZNWsWNpuNvn37YjabcTgcPPHEE0yaNMnTTRMgPz8fgLi4uAbH4+Li3I+1JoUaaSA9PZ0dO3bwxRdfeLopPuvgwYNMmzaNjz76iMDAQE83x+c5nU6GDRvG3LlzARgyZAg7duxgwYIFCjUe8Pbbb/Pmm2/y1ltv0b9/f7Zu3cr06dNJTEzU70M0/CT17rnnHj744AM++eQTunTp4unm+KwtW7Zw5MgRLrzwQvz9/fH39+ezzz7jueeew9/fH4fD4ekm+pSEhAQuuOCCBsf69etHTk6Oh1rk2/74xz8ya9YsJk6cyMCBA/nVr37FjBkzmDdvnqebJkB8fDwABQUFDY4XFBS4H2tNCjWCy+XinnvuYdmyZXz88cekpqZ6ukk+7corr2T79u1s3brVfRs2bBiTJk1i69atmM1mTzfRp4waNarREgdZWVl069bNQy3ybRUVFfj5NfzoMpvNOJ1OD7VITpaamkp8fDzr1q1zH7PZbGzYsIGRI0e2+vU1/CSkp6fz1ltv8f777xMWFuYe94yIiCAoKMjDrfM9YWFhjeqZQkJC6NSpk+qcPGDGjBlccsklzJ07l5tuuomNGzeycOFCFi5c6Omm+aRx48bxxBNP0LVrV/r378+3337Ls88+yx133OHppvmMsrIy9uzZ476/f/9+tm7dSnR0NF27dmX69Ok8/vjj9OrVi9TUVObMmUNiYqJ7hlSrconPA5q8vfrqq55umtT68Y9/7Jo2bZqnm+GzVqxY4RowYIDLarW6+vbt61q4cKGnm+SzbDaba9q0aa6uXbu6AgMDXd27d3c98MADrqqqKk83zWd88sknTX5mTJkyxeVyuVxOp9M1Z84cV1xcnMtqtbquvPJKV2ZmZpu0TevUiIiIiFdQTY2IiIh4BYUaERER8QoKNSIiIuIVFGpERETEKyjUiIiIiFdQqBERERGvoFAjIiIiXkGhRkRERLyCQo2IiIh4BYUaERER8QoKNSIiIuIVFGpERETEK/x/7Hr03cS9BHAAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def graficar_accuracy(history):\n",
        "    epoch_count = range(1, len(history['accuracy']) + 1)\n",
        "    sns.lineplot(x=epoch_count,  y=history['accuracy'], label='train')\n",
        "    sns.lineplot(x=epoch_count,  y=history['val_accuracy'], label='valid')\n",
        "    plt.show()\n",
        "\n",
        "graficar_accuracy(history1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5. Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Armar lo conversores de indice a palabra:\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: My mother say hi.\n",
            "Representacion en vector de tokens de ids [15, 225, 134]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0  15 225 134]]\n",
            "Index/token de salida: 6\n",
            "Palabra de salida: tom\n"
          ]
        }
      ],
      "source": [
        "input_test = \"My mother say hi.\"\n",
        "print('Input:', input_test)\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
        "\n",
        "# Se obtiene la salida del encoder (el estado oculto para el decoder)\n",
        "prev_state = model.encoder(encoder_sequence_test_tensor.to(device))\n",
        "\n",
        "# Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
        "target_seq = np.zeros((1, 1))\n",
        "target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n",
        "\n",
        "# Se obtiene la primera palabra de la secuencia de salida del decoder\n",
        "output, prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n",
        "\n",
        "top1 = output.argmax(1).view(-1, 1)\n",
        "idx = int(top1.cpu())\n",
        "print(\"Index/token de salida:\", idx)\n",
        "\n",
        "word = idx2word_target[idx]\n",
        "print(\"Palabra de salida:\", word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_sentence(input_seq):\n",
        "    # Se transforma la sequencia de entrada a los stados \"h\" y \"c\" de la LSTM\n",
        "    # para enviar la primera vez al decoder\"\n",
        "    prev_state = model.encoder(encoder_sequence_test_tensor.to(device))\n",
        "\n",
        "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "    target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n",
        "\n",
        "    # Se obtiene el indice que finaliza la inferencia\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    \n",
        "    output_sentence = []\n",
        "    for _ in range(max_out_len):\n",
        "        # Predicción del próximo elemento\n",
        "        output, new_prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n",
        "        top1 = output.argmax(1).view(-1, 1)\n",
        "        idx = int(top1.cpu())\n",
        "\n",
        "        # Si es \"end of sentece <eos>\" se acaba\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        # Transformar ídx a palabra\n",
        "        word = ''        \n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        # Actualizar los estados dado la ultimo prediccion\n",
        "        prev_state = new_prev_state\n",
        "\n",
        "        # Actualizar secuencia de entrada con la salida (re-alimentacion)\n",
        "        target_seq_tensor = top1\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: My mother say hi.\n",
            "Representacion en vector de tokens de ids [15, 225, 134]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0  15 225 134]]\n",
            "Response: tom\n"
          ]
        }
      ],
      "source": [
        "input_test = \"My mother say hi.\"\n",
        "print('Input:', input_test)\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
        "\n",
        "translation = translate_sentence(encoder_sequence_test)\n",
        "print('Response:', translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: Mary wants to buy a dress.\n",
            "Response: tom no quiero que\n"
          ]
        }
      ],
      "source": [
        "i = np.random.choice(len(input_sentences))\n",
        "input_seq = encoder_input_sequences[i:i+1]\n",
        "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
        "translation = translate_sentence(encoder_sequence_test_tensor)\n",
        "print('-')\n",
        "print('Input:', input_sentences[i])\n",
        "print('Response:', translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Aumentar tamaño dataset entrenamiento\n",
        "Duplicamos el tamaño del dataset de entrenamiento a 12 líneas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras en el vocabulario: 5409\n",
            "Sentencia de entrada más larga: 32\n",
            "Palabras en el vocabulario: 8584\n",
            "Sentencia de salida más larga: 36\n"
          ]
        }
      ],
      "source": [
        "MAX_NUM_SENTENCES = 12000\n",
        "input_sentences, output_sentences, output_sentences_inputs = generar_secuencias(lines, MAX_NUM_SENTENCES)\n",
        "\n",
        "\n",
        "salida_tokenizador = tokenizar_texto(input_sentences, output_sentences, output_sentences_inputs, MAX_VOCAB_SIZE)\n",
        "\n",
        "input_tokenizer = salida_tokenizador[\"input_tokenizer\"]\n",
        "output_tokenizer = salida_tokenizador[\"output_tokenizer\"]\n",
        "input_integer_seq = salida_tokenizador[\"input_integer_seq\"]\n",
        "output_integer_seq = salida_tokenizador[\"output_integer_seq\"]\n",
        "output_input_integer_seq = salida_tokenizador[\"output_input_integer_seq\"]\n",
        "num_words_output = salida_tokenizador[\"num_words_output\"]\n",
        "word2idx_inputs = salida_tokenizador[\"word2idx_inputs\"]\n",
        "word2idx_outputs = salida_tokenizador[\"word2idx_outputs\"]\n",
        "\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "data_set = Data(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)\n",
        "\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, drop_last=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False, drop_last=True)\n",
        "\n",
        "# --- CONTROL DE ÍNDICES VÁLIDOS ---\n",
        "num_words_input = len(word2idx_inputs) + 1  # +1 por padding\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "encoder_input_sequences[encoder_input_sequences >= num_words_input] = 0\n",
        "decoder_input_sequences[decoder_input_sequences >= num_words_output] = 0\n",
        "decoder_output_sequences[decoder_output_sequences >= num_words_output] = 0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de embeddings nulos: 53\n",
            "Checkpoint completo encontrado en: Modelos_entrenados/Aumentar_datos\n",
            "No se encontró embedding_matrix_decoder.npy — se entrenará embedding en el Decoder.\n",
            "Checkpoint cargado desde: Modelos_entrenados/Aumentar_datos\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix, words_not_found, nb_words = preparar_embedding_matrix(\n",
        "    model_embeddings, word2idx_inputs, MAX_VOCAB_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "encoder = Encoder(vocab_size=nb_words, embedding_matrix=embedding_matrix)\n",
        "if cuda: encoder.cuda()\n",
        "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
        "decoder = Decoder(vocab_size=num_words_output, output_dim=num_words_output)\n",
        "if cuda: decoder.cuda()\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "if cuda: model.cuda()\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
        "\n",
        "# Verificar que si el modelo ya existe para cargarlo. Sino entrenar\n",
        "carpeta = \"Modelos_entrenados/Aumentar_datos\"\n",
        "\n",
        "modelo_entrenado = check_checkpoint_exists(carpeta)\n",
        "\n",
        "if not modelo_entrenado:\n",
        "    history2 = train(model,\n",
        "                    train_loader,\n",
        "                    valid_loader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    epochs=10\n",
        "                    )\n",
        "    config = {\n",
        "        # Información general\n",
        "        \"max_input_len\": max_input_len,\n",
        "        \"max_out_len\": max_out_len,\n",
        "        \"max_vocab_size\": MAX_VOCAB_SIZE,\n",
        "        \"cuda\": cuda,\n",
        "\n",
        "        # Hiperparámetros de embedding y red\n",
        "        \"embedding_dim\": embedding_matrix.shape[1],\n",
        "        \"hidden_size\": 128,        \n",
        "        \"num_layers\": 1,            \n",
        "        \"lr\": 0.1,\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": 10,\n",
        "\n",
        "        # Vocabularios (usar tamaños reales)\n",
        "        \"num_words_input\": int(embedding_matrix.shape[0]),\n",
        "        \"num_words_output\": int(num_words_output),\n",
        "\n",
        "        # Checkpoint info (opcional)\n",
        "        \"embedding_source\": getattr(model_embeddings, \"name\", \"custom\"),\n",
        "    }\n",
        "    save_checkpoint(carpeta, model, optimizer, history2, config,\n",
        "                    input_tokenizer, output_tokenizer,\n",
        "                    word2idx_inputs, word2idx_outputs, embedding_matrix)\n",
        "else:\n",
        "    data = load_checkpoint(carpeta, Encoder, Decoder, Seq2Seq, device=\"cuda\" if cuda else \"cpu\")\n",
        "    model = data[\"model\"]\n",
        "    optimizer = data[\"optimizer\"]\n",
        "    history2 = data[\"history\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "graficar_accuracy(history2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Aumentar tamaño de las secuencias\n",
        "Aumentamos el tamaño de input maximo a 25 (la más larga en el dataset es 32) y del output a 30 (la más larga en el dataset es 36)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras en el vocabulario: 3851\n",
            "Sentencia de entrada más larga: 32\n",
            "Palabras en el vocabulario: 5721\n",
            "Sentencia de salida más larga: 36\n"
          ]
        }
      ],
      "source": [
        "MAX_NUM_SENTENCES = 6000\n",
        "max_input_len = 25\n",
        "max_out_len = 30\n",
        "\n",
        "input_sentences, output_sentences, output_sentences_inputs = generar_secuencias(lines, MAX_NUM_SENTENCES)\n",
        "\n",
        "\n",
        "salida_tokenizador = tokenizar_texto(input_sentences, output_sentences, output_sentences_inputs, MAX_VOCAB_SIZE)\n",
        "\n",
        "input_tokenizer = salida_tokenizador[\"input_tokenizer\"]\n",
        "output_tokenizer = salida_tokenizador[\"output_tokenizer\"]\n",
        "input_integer_seq = salida_tokenizador[\"input_integer_seq\"]\n",
        "output_integer_seq = salida_tokenizador[\"output_integer_seq\"]\n",
        "output_input_integer_seq = salida_tokenizador[\"output_input_integer_seq\"]\n",
        "num_words_output = salida_tokenizador[\"num_words_output\"]\n",
        "word2idx_inputs = salida_tokenizador[\"word2idx_inputs\"]\n",
        "word2idx_outputs = salida_tokenizador[\"word2idx_outputs\"]\n",
        "\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "data_set = Data(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)\n",
        "\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, drop_last=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de embeddings nulos: 30\n",
            "Checkpoint completo encontrado en: Modelos_entrenados/Aumentar_secuencias\n",
            "No se encontró embedding_matrix_decoder.npy — se entrenará embedding en el Decoder.\n",
            "Checkpoint cargado desde: Modelos_entrenados/Aumentar_secuencias\n"
          ]
        }
      ],
      "source": [
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs) + 1)\n",
        "embedding_matrix, words_not_found, nb_words = preparar_embedding_matrix(model_embeddings, word2idx_inputs, MAX_VOCAB_SIZE)\n",
        "\n",
        "encoder = Encoder(vocab_size=nb_words, embedding_matrix=embedding_matrix)\n",
        "if cuda: encoder.cuda()\n",
        "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
        "decoder = Decoder(vocab_size=num_words_output, output_dim=num_words_output)\n",
        "if cuda: decoder.cuda()\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "if cuda: model.cuda()\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
        "\n",
        "\n",
        "# Verificar que si el modelo ya existe para cargarlo. Sino entrenar\n",
        "carpeta = \"Modelos_entrenados/Aumentar_secuencias\"\n",
        "\n",
        "modelo_entrenado = check_checkpoint_exists(carpeta)\n",
        "\n",
        "if not modelo_entrenado:\n",
        "    history3 = train(model,\n",
        "                    train_loader,\n",
        "                    valid_loader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    epochs=10\n",
        "                    )\n",
        "    config = {\n",
        "        # Información general\n",
        "        \"max_input_len\": max_input_len,\n",
        "        \"max_out_len\": max_out_len,\n",
        "        \"max_vocab_size\": MAX_VOCAB_SIZE,\n",
        "        \"cuda\": cuda,\n",
        "\n",
        "        # Hiperparámetros de embedding y red\n",
        "        \"embedding_dim\": embedding_matrix.shape[1],\n",
        "        \"hidden_size\": 128,        \n",
        "        \"num_layers\": 1,           \n",
        "        \"lr\": 0.1,\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": 10,\n",
        "\n",
        "        # Vocabularios (usar tamaños reales)\n",
        "        \"num_words_input\": int(embedding_matrix.shape[0]),\n",
        "        \"num_words_output\": int(num_words_output),\n",
        "\n",
        "        # Checkpoint info (opcional)\n",
        "        \"embedding_source\": getattr(model_embeddings, \"name\", \"custom\"),\n",
        "    }\n",
        "    save_checkpoint(carpeta, model, optimizer, history3, config,\n",
        "                    input_tokenizer, output_tokenizer,\n",
        "                    word2idx_inputs, word2idx_outputs, embedding_matrix)\n",
        "else:\n",
        "    data = load_checkpoint(carpeta, Encoder, Decoder, Seq2Seq, device=\"cuda\" if cuda else \"cpu\")\n",
        "    model = data[\"model\"]\n",
        "    optimizer = data[\"optimizer\"]\n",
        "    history3 = data[\"history\"]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAS9JJREFUeJzt3XlcU2fePv4rCRB2ZEcFBBVFXHBBGLGLVurSlhm7OHa6qf22fTo/7VNLO1OXaherTDfHaWt1OqPtM9M62s5oxy5SLVpbWwVFraIIoiCgrIIJhCUkOb8/DglEUAkGTpbr/XrlpZ4kJ3cEyeV9PvfnlgmCIICIiIjIhsmlHgARERHRjTCwEBERkc1jYCEiIiKbx8BCRERENo+BhYiIiGweAwsRERHZPAYWIiIisnkMLERERGTzXKQegLUYDAZcunQJPj4+kMlkUg+HiIiIukEQBNTX12PAgAGQy689j+IwgeXSpUuIiIiQehhERETUA6WlpQgPD7/m/Q4TWHx8fACIb9jX11fi0RAREVF3qNVqREREmD7Hr8VhAovxMpCvry8DCxERkZ25UTkHi26JiIjI5jGwEBERkc1jYCEiIiKb5zA1LN2h1+vR2toq9TDslkKhgIuLC5eNExFRn3OawNLQ0ICysjIIgiD1UOyap6cn+vfvDzc3N6mHQkRETqRHgWX9+vV46623UFFRgfj4eLz33ntITEy85uPXrVuHDRs2oKSkBEFBQXjggQeQnp4Od3d3AEB6ejq2b9+OM2fOwMPDA8nJyXjjjTcwfPjwnr2rq+j1epSVlcHT0xPBwcGcIegBQRCg1WpRXV2NoqIixMTEXLfBDxERkTVZHFi2bduGtLQ0bNy4EUlJSVi3bh1mzJiB/Px8hISEdHr8li1bsGTJEmzevBnJyckoKCjA/PnzIZPJsHbtWgDA/v37sXDhQkycOBE6nQ7Lli3D9OnTcfr0aXh5ed30m2xtbYUgCAgODoaHh8dNn89ZeXh4wNXVFRcuXIBWqzUFTiIiot4mEyy8RpKUlISJEyfi/fffByC2xI+IiMAzzzyDJUuWdHr8okWLkJeXh8zMTNOx559/HllZWThw4ECXr1FdXY2QkBDs378ft912W7fGpVar4efnB5VK1akPS3NzM4qKihAdHc0P2ZvEv0siIrKm631+d2TRnL5Wq0VOTg5SUlLaTyCXIyUlBQcPHuzyOcnJycjJyUF2djYA4Pz58/jmm29w1113XfN1VCoVACAgIOCaj2lpaYFarTa7ERERkWOy6JJQTU0N9Ho9QkNDzY6HhobizJkzXT7noYceQk1NDW655RYIggCdToenn34ay5Yt6/LxBoMBixcvxuTJkzFq1KhrjiU9PR2vvvqqJcMnIiIiO9XrVZPff/891qxZgw8++ABHjx7F9u3b8fXXX2PVqlVdPn7hwoXIzc3F1q1br3vepUuXQqVSmW6lpaW9MXyHERUVhXXr1kk9DCIioh6xaIYlKCgICoUClZWVZscrKysRFhbW5XNWrFiBRx99FE888QQAYPTo0dBoNHjqqaewfPlys5UmixYtwldffYUffvjhujs2AoBSqYRSqbRk+HZnypQpGDt2rFWCxuHDh61SwExERCQFi2ZY3NzcMGHCBLMCWoPBgMzMTEyaNKnL5zQ2NnZa/qpQKADA1BNFEAQsWrQIO3bswN69exEdHW3Rm3BWxkts3REcHAxPT89eHhERETkKvUHA+eoGZORW4N3Ms0j77LikvcwsviSUlpaGv/3tb/i///s/5OXl4fe//z00Gg0WLFgAAHjsscewdOlS0+NTU1OxYcMGbN26FUVFRdizZw9WrFiB1NRUU3BZuHAhPvnkE2zZsgU+Pj6oqKhARUUFmpqarPQ2zQmCgEatTpJbd7/Y8+fPx/79+/GXv/wFMpkMMpkMH3/8MWQyGXbt2oUJEyZAqVTiwIEDOHfuHH7zm98gNDQU3t7emDhxIr777juz8119SUgmk+Hvf/877r33Xnh6eiImJgY7d+605l8zERHZAYNBQGltIzLzKvHB94V4bttx3PWXHxG3MgN3vLMfT3+Sg7V7CrD96EWUq5olG6fFfVjmzp2L6upqrFy5EhUVFRg7diwyMjJMhbglJSVmMyovvfQSZDIZXnrpJVy8eBHBwcFITU3F6tWrTY/ZsGEDAPESSEcfffQR5s+f34O3dX1NrXrErfzW6uftjtOvzYCn243/2v/yl7+goKAAo0aNwmuvvQYAOHXqFABgyZIlePvttzF48GD4+/ujtLQUd911F1avXg2lUol//OMfSE1NRX5+PiIjI6/5Gq+++irefPNNvPXWW3jvvffw8MMP48KFC9ddnUVE1NsKqxrwfX4VDIKACH9PRAR4IsLfE36erlIPza4JgoAKdTPyK+pxtrIB+ZX1OFtZj7NVDWjU6rt8jrurHDEhPogJ9cawUB8oXaRrGNqjTreLFi3CokWLurzv+++/N38BFxe8/PLLePnll695PrbL78zPzw9ubm7w9PQ01QcZV2K99tpruPPOO02PDQgIQHx8vOnPq1atwo4dO7Bz585rfp0AcRbnd7/7HQBgzZo1ePfdd5GdnY2ZM2f2xlsiIuqSwSDgeNkV7D5Vid2nK3C+WtPl43zcXdoCjAciA9qDTESAB8L9PeHuqujjkdsmQRBQ06BFQWV9h1sDCirrUd/cdRmBm0KOwcFeGBbqg+FhPogJ8cbwMB+E+3tCIbeN7vBOs5dQRx6uCpx+bYZkr32zEhISzP7c0NCAV155BV9//TXKy8uh0+nQ1NSEkpKS655nzJgxpt97eXnB19cXVVVVNz0+IqIbadHp8fO5y9h9qhLf5VWiur7FdJ+rQoZJQ4LQz8MVJbWNKKtrRE2DFvXNOpwuV+N0edd9t4J9lIjw9zALMsYZmv5+7nBRON52InWatmBS1YCCivaAUtfY9Ua/CrkM0UFeGB4qzpqIv/ogKtDT5v9+nDKwyGSybl2WsVVXr/Z54YUXsGfPHrz99tsYOnQoPDw88MADD0Cr1V73PK6u5tOrMpkMBoPB6uMlIgIAdXMr9p2pwu7Tlfj+TBU0HS5D+ChdMDU2BNNHhuL2YcHwcTf/+dSo1aGsrgmltY3izfj7uiaU1TaivkWH6voWVNe34GjJlU6vrZDL0N/P3SzIRAZ6Irztz8HeSpveZ66+udU0S9Jx1qRj0OtIJgMGBXhiWKiPeAvzwbBQb0QHeUHpYp8zUfb7qe0E3NzcoNd3fV2xo59++gnz58/HvffeC0CccSkuLu7l0RER3ViFqhl7Tldg9+lKHDp/Ga369hKAUF8l7owLxfS4MPxqcCDcrlMf4enmYvrwvZogCFA1taK0tgmldcZA04iSWjHMlNU1Qas3oKyuCWV1TTh4vvP53V3lYni5aoYmvG2Gxs+jb+pnGrU6FFY1iHUmxl8r63HpOsWu4f4e7cGkrdZkSLA3PNzsM5hcCwOLDYuKikJWVhaKi4vh7e19zdmPmJgYbN++HampqZDJZFixYgVnSohIEoIgoLCqAbtPV2L3qQr8UqYyuz8mxBvTR4ohZfRAP8itUB8hk8nQz9MN/TzdMDrcr9P9BoOAqvqW9jDTIdiU1TWhXNWE5lYDCqsaUFjV0OVr+Lq7mF9qusn6meZWPc5XazrNmJTWNeJaZZ1hvu6myzjGWZOhId7wVjrHR7lzvEs79cILL2DevHmIi4tDU1MTPvrooy4ft3btWjz++ONITk5GUFAQXnzxRe6tRER9Rm8QcKykzhRSii83mu6TyYAJkf64My4Ud8aFYnCwd5+PTy6XIczPHWF+7pgY1XkVpFZnQLmq6aoZmiaxfqa2EZc1WqibdTh1SY1Tl65dPxMZYD5DE9526ampVS8Gkoq24teqehTXaGC4RjAJ8nbrMGMizprEhPr02SyPrbJ4t2Zbxd2a+wb/LokIEGcIfj5XYyqarWlor5lzc5HjlqFBmB4XimkjQhHsY99dyTUtHepn6jrP0DS0dK+B59X8PFzbi1/DfBATIoaTQG/7/vuyVHd3a+YMCxERdYuqsRV78yux+1Ql9hdUm/Xu8HV3wbQR4izKbcOCHeoyhZfSBcPDxOW+VxMEAVcaWzsFGWMxcFldE9xc5GYrcoa1/T7Yx7YLfW2N43xHERGR1V260oQ9p8X+KIfO10Lf4TpGfz93TI8LxfSRYUiMDoCrjS+L7Q0ymQz+Xm7w93LDmPB+ne43GATIZGAwsQIGFiIiMhEEAfmV9aYmbrkXzWs2YsN8TCt7Rg305QfxDVijqJhEDCxERE5ObxBwpLgWu09XYs/pSpTUthfNymVAwqAATB8pXu4ZFMhd30kaDCxERE6ouVWPH8/WYPepCmSeqUKtpr1oVukix60xwZg+MhTTYkOcrgiUbBMDCxGRk6jTaJF5pgp7Tlfgh4IaNLW2F836ebhi2ogQTI8Lw23Dguy6Gzg5Jn5HEhE5sNLaRlPR7OHiOrOi2YH9PExN3CZG+dv8XjLk3BhYiIgciCAIOF2uFkPKqcpOGwWO6O/btrInFHH9WTRL9oOBxYFFRUVh8eLFWLx4MQBxWd2OHTswe/bsLh9fXFyM6OhoHDt2DGPHju2zcRJRzxlb4R8ursPh4lpknb9stu+MXAYkRgdgelwY7owLRUSAp4SjJeo5BhYnUl5eDn9/f6mHQUQ3QaszIPeSCkeKa5FdVIecC7Woa2w1e4y7qxy3xQRj+sgw3BEbggAvN4lGS2Q9DCxOJCwsTOohEJGFGlp0OHqhTgwoxbU4XnoFza3mm5t6uCowLrIfEqICkBgVgAmD/B1up14iBhYb9eGHH+KVV15BWVkZ5PL2Qrjf/OY3CAwMxPLly5GWloZDhw5Bo9FgxIgRSE9PR0pKyjXPefUloezsbPzP//wP8vLyMGrUKCxfvry33xYR3UBVfTOOtF3eOVxci9OX1J02yQvwckPCIH9MjArAxOgAjBzg65RdZsm5OGdgEQSgtfHGj+sNrp7i9qU3MGfOHDzzzDPYt28fpk2bBgCora1FRkYGvvnmGzQ0NOCuu+7C6tWroVQq8Y9//AOpqanIz89HZGTkDc/f0NCAe+65B3feeSc++eQTFBUV4dlnn73pt0dE3ScIAoovN+JwUa0poHTc6dgoIsADEweJ4WRiVACGBHuxWJacjnMGltZGYM0AaV572SXA7cadIv39/TFr1ixs2bLFFFj+/e9/IygoCFOnToVcLkd8fLzp8atWrcKOHTuwc+dOLFq06Ibn37JlCwwGAzZt2gR3d3eMHDkSZWVl+P3vf9/z90ZE16XTG5BXXo/s4locKa7F4eI61DS0mD1GJgNiw3wxMaptBiUqAGF+3BmdyDkDi514+OGH8eSTT+KDDz6AUqnEp59+igcffBByuRwNDQ145ZVX8PXXX6O8vBw6nQ5NTU0oKSnp1rnz8vIwZswYuLu3/yCcNGlSb70VIqfUpNXjWGkdDhfV4ciFWhy9UAdNhx2OAcDNRY6x4f2QEOWPidEBGB/pDz8PV4lGTGS7nDOwuHqKMx1SvXY3paamQhAEfP3115g4cSJ+/PFH/PnPfwYAvPDCC9izZw/efvttDB06FB4eHnjggQeg1WpvcFYi6i21Gm3bzIk4e5J7UQXdVQUovu4uSIgKQEKUPxKjAjBqoB/cXVkgS3QjzhlYZLJuXZaRmru7O+677z58+umnKCwsxPDhwzF+/HgAwE8//YT58+fj3nvvBSDWpBQXF3f73CNGjMA///lPNDc3m2ZZDh06ZPX3QOSoBEFAWV2TqfbkcHEdCqsaOj0uzNcdE6MDkNg2gzIsxIc7+BL1gHMGFjvy8MMP45577sGpU6fwyCOPmI7HxMRg+/btSE1NhUwmw4oVK2AwGK5zJnMPPfQQli9fjieffBJLly5FcXEx3n777d54C0QOQW8QkF9RjyMXapFdVIsjxXWoUDd3elxMiLe4vDjaHwmDAhDu78ECWSIrYGCxcXfccQcCAgKQn5+Phx56yHR87dq1ePzxx5GcnIygoCC8+OKLUKvV1zmTOW9vb3z55Zd4+umnMW7cOMTFxeGNN97A/fff3xtvg8juNLfqcaJMZZpByblQh/pmndljXOQyjA73MxXHThjkzyZtRL1EJgiCcOOH2T61Wg0/Pz+oVCr4+vqa3dfc3IyioiJER0ebFZmS5fh3SY5K1dSKoxfqkF1ci8NFtThRpoJWbz5r6eWmwPhB7at3xkb0Y4M2opt0vc/vjjjDQkROq0LVjG9PVSAjtwJZRZc7NWgL8laalhcnRgcgNsyHOxoTSYSBhYicSmltI3blliMjtwJHS66Y3Rcd5CV2kG1r0BYV6Mn6EyIbwcBCRA6vsKoeu05WIONUBU5dMq/1mjDIHzNHhmHmqDDuZExkwxhYiMjhCIKAU5fUyMitwK7ccpyr1pjuk8uAXw0OxMxRYZgxMgyhvqzFIrIHDCxE5BAMBgHHSuuQkSvOpJTWNpnuc1XIcMvQIMwa1R8pcaFcyUNkh5wqsDjIgihJ8e+QbIlOb0B2US0yTlXg21MVqFS378vj7irHlGEhmDU6DFNjQ+Drznb3RPbMKQKLQiEuO9RqtfDw8JB4NPatsVHcSdbVlT/8SRotOj1+LryMjNwK7MmrRK2mfTsKH6UL7hgRglmjwnD7sBAuOSZyIE4RWFxcXODp6Ynq6mq4urpCLueyREsJgoDGxkZUVVWhX79+phBI1BeatHrsL6hCRm4FMvOqUN/S3sDN39MV0+PEotnkoYFQuvB7k8gROUVgkclk6N+/P4qKinDhwgWph2PX+vXrh7CwMKmHQU6gvrkVe89UYdfJCnxfUIXm1vYmbiE+SswcFYaZI8OQGB3A3ihETsApAgsAuLm5ISYmhrsZ3wRXV1fOrFCvqtNosed0JXblluOnwstmnWbD/T0wa5Q4kzIuwp8bCBI5GacJLAAgl8vZTp7IxlSqm7H7VAV25VYgq6gW+g7tZocEe2HWqP6YOSoMIwf4sokbkRNzqsBCRLahtLYR37aFlKMldei4+GzkAF/MHBmGWaPDMDTER7pBEpFNYWAhoj5RWNWAjNxyZJyqQO5F826z4yP7tdWk9EdkILvNElFnDCxE1CsEQcDpcrHbbEZuBc5WNZjuk8uApOj2brNhfrxUS0TXx8BCRFZjMAg4XnbFFFJKahtN97kqZJg8NAizRoUhZUQoAr2VEo6UiOwNAwsR3RS9QRC7zeaW49tTlahQN5vuc3eV4/ZhwZg1qj+mxobAz4MNB4moZxhYiKhHtDoD/nGwGBv3n0NNQ3u7AG+lC+6Ibes2OzwYnm78MUNEN48/SYjIYt/nV+G1r07jfNsuyP6errgzLhQzR4Vh8tAgdpslIqtjYCGibiuu0eD1r0/ju7wqAECQtxv+OCMW940fyG6zRNSrGFiI6IYaWnR4f28hNh8oglZvgItchgWTo/DMtBjugkxEfYKBhYiuyWAQsOPYRbyRcQZV9S0AgNuHBWPFPXEYGuIt8eiIyJkwsBBRl34pvYJXvjyFYyVXAACDAj2x8p443BEbwhb5RNTnGFiIyEx1fQvezDiDz3PKAABebgosuiMGj98SxWJaIpIMAwsRARCXKf/fz8V4N/Ms6lt0AID7xg/EizNjEerLTrREJC0GFiLCvvwqrOqwTDk+3A8v/3okxkf6SzwyIiIRAwuREyuq0WDVV6ex94xxmbISf5w5HA+MD4dczjoVIrIdDCxETqihRYf39p7F5gNFaNULcJHL8Pgt0XjmjqHw4TJlIrJBDCxETsRgELC9bZlyddsy5SnDxWXKQ4K5TJmIbBcDC5GTOF56Ba/sPIXjpVcAANFBXlhxzwjcERsq7cCIiLqBgYXIwVXVN+PNjHz8u8My5WemxWDBZC5TJiL7wcBC5KC0OgM+/rkI72YWoqFtmfL948Px4szhCOEyZSKyMwwsRA5o35m2Zco1bcuUI/rhldQ4jOMyZSKyUwwsRA7kfHUDVn11GvvyqwGIy5SXzIrFfeMGcpkyEdk1BhYiB1Df3CrupvyTuEzZVSHD45OjsYjLlInIQch78qT169cjKioK7u7uSEpKQnZ29nUfv27dOgwfPhweHh6IiIjAc889h+bmZtP9P/zwA1JTUzFgwADIZDJ88cUXPRkWkdMxGAR8fqQUU9/ej7/+cB6tegFThwfj28W3YeldIxhWiMhhWDzDsm3bNqSlpWHjxo1ISkrCunXrMGPGDOTn5yMkJKTT47ds2YIlS5Zg8+bNSE5ORkFBAebPnw+ZTIa1a9cCADQaDeLj4/H444/jvvvuu/l3ReQEjpXU4ZUvT+OXDsuUV94Th6mxnf8dEhHZO5kgCIIlT0hKSsLEiRPx/vvvAwAMBgMiIiLwzDPPYMmSJZ0ev2jRIuTl5SEzM9N07Pnnn0dWVhYOHDjQeUAyGXbs2IHZs2db9EbUajX8/PygUqng6+tr0XOJ7EmVuhlvZOTjP0fFZcreShf877ShmJ8cDTeXHk2aEhFJpruf3xb9dNNqtcjJyUFKSkr7CeRypKSk4ODBg10+Jzk5GTk5OabLRufPn8c333yDu+66y5KX7qSlpQVqtdrsRuTItDoD/rr/HKa+/b0prDwwIRx7X7gdT902hGGFiByaRZeEampqoNfrERpq3hkzNDQUZ86c6fI5Dz30EGpqanDLLbdAEATodDo8/fTTWLZsWc9HDSA9PR2vvvrqTZ2DyF7sPVOJVV/loahtmfLYiH545dcjMTain7QDIyLqI73+X7Lvv/8ea9aswQcffICjR49i+/bt+Prrr7Fq1aqbOu/SpUuhUqlMt9LSUiuNmMh2nKtuwPyPsvH4x0dQVKNBsI8S78yJx/bfJzOsEJFTsWiGJSgoCAqFApWVlWbHKysrERYW1uVzVqxYgUcffRRPPPEEAGD06NHQaDR46qmnsHz5csjlPctMSqUSSqWyR88lsnX1za14N/MsPvqpGDpD2zLlW6LxzB0x8FayGwEROR+L0oKbmxsmTJhgVkBrMBiQmZmJSZMmdfmcxsbGTqFEoRD3L7Gw3pfI4RkMAj5rW6b8tx+LoDMImBYbgt3P3Y6ls0YwrBCR07L4p19aWhrmzZuHhIQEJCYmYt26ddBoNFiwYAEA4LHHHsPAgQORnp4OAEhNTcXatWsxbtw4JCUlobCwECtWrEBqaqopuDQ0NKCwsND0GkVFRTh+/DgCAgIQGRlpjfdJZPOOltTh1Z2n8EuZCgAwOMgLK1LjMHU4lykTEVkcWObOnYvq6mqsXLkSFRUVGDt2LDIyMkyFuCUlJWYzKi+99BJkMhleeuklXLx4EcHBwUhNTcXq1atNjzly5AimTp1q+nNaWhoAYN68efj44497+t6I7EKVuhl/yjiD7UcvAhCXKT87LQbzkqO48oeIqI3FfVhsFfuwkL1p0emx+UAx3t97FhqtHgAwZ0I4/jBzOEJ8uJsyETmH7n5+84I4UR8TBAG7T1ci/Zs8FF9uBACMi+yHV1JHIp4rf4iIusTAQtSHjpbUIf2bPBwurgMAhPiIuynPHsvdlImIroeBhagPFNdo8Oa3Z/DNyQoAgLurHE/cMhhPTxnClT9ERN3An5REvahWo8W7mWfxadYFtOoFyGRinUrancMR5sc6FSKi7mJgIeoFza16bP6pCBv2nUN9iw4AMGV4MJbMikVsGIvCiYgsxcBCZEV6g4Adxy7ind35KFc1AwBGDvDFsrtGYPLQIIlHR0RkvxhYiKzkh4JqpO86g7xycefwgf088MKMYfhNPAtqiYhuFgML0U06fUmN9F15+PFsDQDAx90Fi6YOxbzkKLi7KiQeHRGRY2BgIeqhS1ea8M7uAmw/VgZBAFwVMjz6qyg8c8dQ+Hu5ST08IiKHwsBCZCF1cys2fH8Omw8UoUVnAADcM6Y//jgjFpGBnhKPjojIMTGwEHWTVmfAp1kX8G7mWdQ1tgIAEqMCsOzuERjLDrVERL2KgYXoBgRBwK7cCryZccbUSn9IsBeWzBqBlBEhkMlYUEtE1NsYWIiu43BxLdZ8k4djJVcAAEHeSjx3ZwzmJkTARcGdlImI+goDC1EXzlU34I1dZ7D7dCUAwMNVgaduG4ynbhsML7bSJyLqc/zJS9RBdX0L/pJZgH9ll0JvECCXAXMnRuK5lBiE+LKVPhGRVBhYiAA0anXY9GMRNu4/B41WDwBIGRGCF2fGIibUR+LRERERAws5Nb1BwL9zSrF2TwEq1S0AgDHhflg6awQmDQmUeHRERGTEwEJOSRAEfJ9fjfRdeSiobAAAhPt74I8zY3HP6P5spU9EZGMYWMjpnCxTYc03eTh4/jIAwM/DFc/cMRSPThoEpQtb6RMR2SIGFnIapbWNeHt3Pv57/BIAwE0hx/zJUVg4ZSj8PF0lHh0REV0PAws5PFVjK9Z/X4iPfyqGVi+20p89dgCenz4cEQFspU9EZA8YWMhhtej0+OfBC3hvbyFUTWIr/UmDA7HsrhEYHe4n8eiIiMgSDCzkcAwGAV+euIS3vs1HWV0TAGBYqDeWzhqBKcOD2UqfiMgOMbCQQzl47jLSd+XhRJkKABDio8Tz04fh/vHhbKVPRGTHGFjIIZytrMefdp1B5pkqAICXmwJP3z4E/+/WaHi68duciMje8Sc52bUqdTP+/F0Bth0uhUEAFHIZHkqMxP9Oi0Gwj1Lq4RERkZUwsJBd0rTo8NcfzuNvP5xHU6vYSn96XChenBWLIcHeEo+OiIisjYGF7IpOb8DWw6VY991Z1DSIrfTHRfbDsrtGYGJUgMSjIyKi3sLAQnbjRNkVvPifk8grVwMABgV64sWZsZg1Kowrf4iIHBwDC9k8TYsOa/cU4KOfimAQxFb6i1Ni8HDSILi5cOUPEZEzYGAhm/Z9fhWW78jFxStiP5Vfxw/AytQ4BHmzoJaIyJkwsJBNqmlowaqvTpv2/RnYzwOv3zsKU4eHSDwyIiKSAgML2RRBEPCfoxfx+tencaWxFXIZMD85Gs9PHwYvJb9diYicFT8ByGZcuKzBsh0n8VPhZQBAbJgP3rh/DOIj+kk7MCIikhwDC0muVW/A338swrrvCtCiM0DpIsfilGF44tZouLKdPhERgYGFJHb1UuXkIYFYc+9oRAV5iQ8QBODyOeBiDnDxiPhrQzUwfCYw7hGgf7yEoycior7CwEKSaNTq8M5u86XKL909Ag/EukN26QBwoi2cXMwBmq90PkH2h+ItbDQw7lFg9BzAk43jiIgclUwQBEHqQViDWq2Gn58fVCoVfH19pR4OXYdxqXLNFRVGyorxSHg17g68BGXFUeDKhc5PUCjFmZTwBGDgBMDNGzixDTjzFaDXtj3GDYi9W5x1GTwVkCv69k0REVGPdPfzm4GF+obBgCulp/D1ri9hKMvBWHkhRshL4QJ958cGDQMGJgDhE8SAEjoKULh2flxjLXDy38CxfwIVJ9qP+w4E4n8HjHsYCBjce++JiIhuGgMLSau+0lR3IpQdga40B666hs6P8wppmzkZL4aUgeMBdz/LX6/8F+DYp8DJz4Cmuvbjg24RZ13ifg24efX8/RARUa9gYKG+o9WIgaGsQ92JqrTTw5oENxS6xCB0RDJCRkwWZ0/8IgBr7gOkawHyvwGOfQIUZgJo+/Z28wFG3SfWu4QnWPc1iYioxxhYqHcY9EB1fvuKnbIcoOo0IJhf2hEgQ53XYOytj0COfghOy2Iw846peOL2YX23VFlVBvzyLzG81BW3Hw8aLs66xD8IeLNzLhGRlBhYyDrUl8xnTi4dA7RdXNrx6S/OmIQn4LxbLP7wsxw5FToAXSxV7msGA1DysxhcTn0B6MR9iSBTAMNmiOElZnrXdTJERNSrGFjIci31wKXj4uxJ2RHg4lGg/lLnx7l6tdWctNWdhCcAvgPQqNVh7e4CbO6wVHn53SMwZ0I4ZLZyCaZZDZzaLoaXssPtx72CxRmXsY8AIbHSjY+IRILAS7dOgoGFrk+vA6rz2oJJWzipPgMIBvPHyeRAyEgxnIQniAEleHinZcP7C6qxfMdJlNW176q84p44BPvY8K7K1flicPllK6Cpaj8ePlGcdRl5H+DO7yWiPqPXAef3if8m83cB/oOAO18DYu6UemTUixhYyFzTFfEHgbHupPw40NrY+XG+4W3Lidt6ngwYe93VNZfbdlX+ouOuyrNHYWqsHdWG6FuBs3vE8FKQ0V6P4+IBjJwthpdBk/m/PaLeIAjiz6MTn4ltCjr+58Fo6J3AjNXif5bI4TCwkKihCjj4PnB4U+faE6UvMGBce0O2gRMAn7BunVYQBGxv21W5zpF2Va6vFJvSHfsEqMlvP+4fDYx9GBj7O8AvXLrxETmKK6ViG4Jftpn/W/MMBEbdD8TNFlf8ZW0EDDqx5mziE8CUJexq7WAYWJzdlVLg53eBo/8AdM3iscAYIPrW9rqTwBhAbvmKnZLLjVj+xUn8eLYGgIPuqiwI4uWyY/8EcrcD2vq2O2TAkDvEWZfYuwEXG77kRWRrmlXA6f+KIeXCgfbjCiUQexcw5kFg6DTzAviaQmDPCjG8AIB7P2DqMiDhcRbKOwgGFmdVUwgc+DNwYqv4vxJADCi3vQDEzOhRQDHS6Q3YdKAIf/6uAM2t4q7Kz6bE4MlbBzv2rspaDZD3pTjrUvxj+3EPf2D0b9s2YRwj3fiIbJm+FSj8Tpy5zN/V/h8oAIi6FRjzWyDuNzduGHluL/DtcrGNAiC2J5ixBohJ6b2xU59gYHE2FSeBH98Rl+0am6VF3wbc+jwQfftN11/kXlThxf+cwKlL7bsqr753NKKlWqosldrzwPEt4k19sf142Ji2TRgf4HQ1kSCIhfwntgK5/wEaL7ffFzQciJ8rhv1+EZadV68Djv4fsG91+zmH3ikGl+Bh1hs/9SkGFmdRehj48W2xWNRo2Ezg1heAiIk3ffpGrQ5/3lOATQdseKmyFAx6sYj52CfAma+5CSMRIDZoPPGZOJtyubD9uFeIGObHzBU3Mr3Znx1NV4Af3jKvb0l8Erj9Rf6HwQ4xsDgyQQCK9gM/vN3hEoUMGHkvcGsaEDbaKi/zQ0E1ln9xEqW14lLl1PgBWGnrS5Wl0FgLnPy8bRPGk+3HfQcCYx8Si3UDoqUbH1FvaqoTZ3ZPbANKDrYfd/EARtwj1qUMngIoeqEYv6YQ2P0SULBL/LOHPzBlGZCwgPUtdoSBxREZDOJMyo9vi8uTAUDuIjY8m/wcEDTUKi9zuaEFr3+dhx3HxEsedrlUWSrGTRhPbAOar7Qfj7pVnHUZ8WvAzVOy4RFZhU4LnN0tXvIp+LZ9hhEyYPDt4kzKiFRA6dM34zm3F8hYJvaWAsTLTjPXAENZ32IPGFgciUEPnNoB/LgWqDolHnNxB8bPA5Kfsfw68DUIgoAdxy5i1VfiUmWZDJifHIUXpg+376XKUmhtbt+E8dxemG3COPp+sd5l4AT2diH7IQhAabYYUk7tMN8VPWRkW13KHMB3gDTj0+uAox8De1cDTbXisZjpwPTVrG+xcQwsjkCnFX84HPizWOwJiB94E/8fMGmhVTfu62qp8p/uH4OxjrRUWSqqMuD4v4DjV23CGDBEDJtu3mJzPuOvSp+2PxuPGY97m//ZzYs1MtT7Lp9rr0upK2o/7h0GjJkjzqZY6TK0VVxd3yJ3Efu3sL7l5jTWinvJDZ1m9VMzsNgzbaPYP+Xnd9tXonj4A7/6/8TCMg9/q72UTm/A5p+KsHaPky1VloLBAFz4SZx1Of3f9k0Yb4arZ4dw49Mh2Hh1DjemIHR1COpwzNWDsz4kfjjl/kcMKR333HL1Ei/1xM8VVx/acmC+Zn3L471TT+OIWpvEpegnPxe7gcvkwB/O3ngJuoUYWOxRswo4/Hfg4AdAozjTAe8w8bLPhPnih4sV5V5UYcn2E8i9KC5VnjQ4EGvuc8KlylJoVgEXDgItanHTSa2m7dYg3loazP9svL+lQWxid/WeT9Yik5uHnC7DTYcZIKW32DHZP1qcdrfyDzLqQ63NYo3cic/E+hRDq3hcJhdXvMU/KK6Au85WHTapMFPs32KsbwmOFdv8s76la3qduKjj5OdA3lcdmmYCCB0F3PchEDrSqi/JwGJPNJeBrA1A1odAi0o81m8QcMtiIP4hwNXdqi/XpNXjz9+JS5X1BoFLle2NIIjNt4yBpqtw09Ix6Fx9vItjrRrrjM07TAwuwbFA0DBx75eg4eLlS35v2R6DASg9JG42eOqL9p8/gNhbKP5BsU1+N7fssFmsb7k+Y9+ck5+LM2sd93PyixSXpI+eA4TG9crLM7DYA/Ul4Of3gZyP2jciDBouLk0e9UCvTFv+eLYay3ZwqTJdxWAQvwc7hhxTuKm/aobnqtDTdEXsuVFffu3zu/t1DjHBwwG/iJvqvkw9VHNWDCknPwOulLQf9x0ofjDFPwiEjJBufL2lqQ7Y/xaQ/dcO9S1PArf/0TnrW2oKxZBy8nOg9lz7cY8AsU3GmN8C4Ym9/m+UgcWW1RYBP60Tu6UalwP2jxebvcXe0yvfHHUaLVZ9dRrbOyxVXjV7JO6IDbX6a5GTalaJH4TV+UD1GaCmQPx9XTFMq6Su5uoJBA4Vw0vHIBMwmH00rK2huq0uZatYPGnk5iO2xo+fCwy6xTkCZE0hsHt5e8NND39g6nJgwgLHr2+prxD3Rzv5mfn3gYuHeMlv9BxxvzQXtz4bEgOLLarKE1f8nPw3IOjFY5HJwG3PA0Om9eqU+eMfH8beM1Vcqkx9r7VJnIGpzm8PMTUFYrgx1klcTe4ihpaOISZomHhjH5vua20Sl9f/sk3cz8f4c0emEGs44ucCw2Y579+ps9S3NKvF/dBOfgYU/dBeAydTiOFk9BwxrFi5TrK7ejWwrF+/Hm+99RYqKioQHx+P9957D4mJidd8/Lp167BhwwaUlJQgKCgIDzzwANLT0+Hu7t7jc17NpgPLxaPiPj9nvmo/NjRF3OdnUHKvv3yTVo8xr36LVr2Afz35K0waEtjrr0l0Q3qdOPtSk982K5Mv/r7mrHipqUsycSm4McSYAs0wq66es2sGg7gT8i/bxNVoHYsmB4wTO8+Ouh/wDpZujLZErxMvy+9b06G+ZYYYXIJipB3bzdC1iCt7Tn4G5GcA+pb2+8ITxZAy8l6b+D7o7ue3xf/F3rZtG9LS0rBx40YkJSVh3bp1mDFjBvLz8xES0rkvyJYtW7BkyRJs3rwZycnJKCgowPz58yGTybB27doendNuFP8kdqU9t7ftgExcEnhrmviDo48cLalDq17AAD93/GqwE16nJdukcBG7MwcNFf93ZyQI4nL+jiGmukC8zNRUK9ZcXCkBCveYn88rpHOICRouFozaS8GvXicGjJaGttVjbb+a/b5tpVjLNR7XeNm8y7JfpFiLMGYuC0y7onAR20WMfgDY/yaQ/SFw9lvgXCaQ+JRY32IvYdjYOuHkZ2JYbe5QRB00TNxwcvQDdrtViMUzLElJSZg4cSLef/99AIDBYEBERASeeeYZLFmypNPjFy1ahLy8PGRmZpqOPf/888jKysKBAwd6dM6u2MwMiyCIU68/vtO+r4ZMIabZW54DQmL7fEhrd+fj3b2FuHfcQPx57tg+f30iq9HUdA4xNQXmO2dfTenXHl5Mvw4H+kVap4+IvvWqUGEMER1ChbahbQl7w1WPU5sHEWv05gHE9zxythhSIic5R12KtdScbevfYif1LYIg7mF28jPg5H+A+kvt9/n0F2fTxvxWXPVlo8G9V2ZYtFotcnJysHTpUtMxuVyOlJQUHDx4sMvnJCcn45NPPkF2djYSExNx/vx5fPPNN3j00Ud7fE4AaGlpQUtL+xSXWq225K1Yn8EA5O0Ug0rFCfGYwk3cP2bys4B/lGRDO3RenObk7ArZPa8g8RY12fx4S31bfUzBVQW/ReJS3bLD5g3QAHF7i8CY9mXYgUPbz9VxxuJGQUTXbP33qXBra/TnLf5q9ntvsVDW+PurH6f0Ed+XldshOI2gGOChbeb1Ld+8IPbImrGmVzq99khdcdsKn3+L3/NGSj8g7tdiSBk02bab+1nIosBSU1MDvV6P0FDzlSWhoaE4c+ZMl8956KGHUFNTg1tuuQWCIECn0+Hpp5/GsmXLenxOAEhPT8err75qyfB7h75V/IY5sFb8IQmI3SATFgCTFgG+/SUdXnOrHsdLrwAAfjWYtSvkoJQ+4t5MAyeYH9e1iK3lO4YYY8GvrhmoPCnerMHFvfuh4rpBxBtwYZsByQ2dJnbzNda3VJ8BPrlP2voWTY24j9PJz4HSrPbjCiUwbIYYUobe6bBhtdfnt77//nusWbMGH3zwAZKSklBYWIhnn30Wq1atwooVK3p83qVLlyItLc30Z7VajYgI62wC2C2tzeLeMD/9pb2PgbsfkPg/wK9+bzNr+o+W1EGrNyDM1x2RAU66EoCcl4tSbHZ1dcMrg76t4LdDiLl8TlydZBYw2jr5dieIcBm247GF+hatBjjzjXjJ59xesX8MAEAGRN8mhpQRqU7RZdqiwBIUFASFQoHKykqz45WVlQgL67oT4ooVK/Doo4/iiSeeAACMHj0aGo0GTz31FJYvX96jcwKAUqmEUinB/0JaGoAjm4GD7wMNbWP2ChY3I0z4f4C7ba1Q6ng5iF1sidrIFUDgEPE2fJbUoyFb5+EPzEwX9yH6drkYWg59IDbfm7rM+vUt+lbg3D4xpJz5ur2xKAD0HyuGlJH3ST6D39cs+ht2c3PDhAkTkJmZidmzZwMQC2QzMzOxaNGiLp/T2NgI+VUFXwqFeE1NEIQenVMSjbVA9t/EFvrGbdV9w8X6lPGPipvG2aCs85cBAEm8HEREdHOCYoCHPxMXVny7XLxMZK36FkEASrPFkHJqh7jay8g/Wgwpox5w6pVeFkfCtLQ0zJs3DwkJCUhMTMS6deug0WiwYMECAMBjjz2GgQMHIj09HQCQmpqKtWvXYty4caZLQitWrEBqaqopuNzonJKqrwQOrQcOb2rvDREwRFyaPPq3fdoN0FLNrXocY/0KEZF1DU0Boqe01besbq9vGTYTmP66ZfUtVWfaVvh8br5NglewOIsy5rdibRZnyC0PLHPnzkV1dTVWrlyJiooKjB07FhkZGaai2ZKSErMZlZdeegkymQwvvfQSLl68iODgYKSmpmL16tXdPqdkNJeBd8e2T8eFjhKDStxsu6i8PlZyBVqdAaG+SkQFsn6FiMhquqpvKcgQZ19uVN+iugjk/hs48bl50bebt7g9y5g5YiCyxWXUEmJr/hvZ9oi498KtL4hV2HaUctd9V4B1353Fr+MH4N3f9V2jOiIip1NdIPZvOfut+GePAPP6lqY6sZnbic/F5m7G/bXkLuLKnjFznHabhF7rdOt07v2ruEGbHQUVo0Nt9Su8HERE1MuCh7XXt2QsE5sbfvOCWE4QOAQ4u7t9s1tA3EduzBxxxt5GVpXaOgaWG3HzknoEPdLcqsexkisAgCQ2jCMi6htDU4DfT+lQ35LXvrliyEgxpIy6X+y0TBZhYHFQv5ReQYvOgGAfJQYH2WfoIiKySx3rW7L/Lm48OPJeIHSk1COzawwsDsrYfyUpmv1XiIgk4eEP3P4HqUfhMLgjloPKKmL9ChEROQ4GFgfUotMj54LY3I6BhYiIHAEDiwM6UaZCi86AIG8lhgSzfoWIiOwfA4sDOnTO2I6f9StEROQYGFgcUFZR24aH0VzOTEREjoGBxcFodQYcuWDcoZn1K0RE5BgYWBzMibIraG41INDLDUNDvKUeDhERkVUwsDgY4+Ug1q8QEZEjYWBxMNw/iIiIHBEDiwNp1RtwpFjsv5IUzcBCRESOg4HFgZwoU6GpVY8ALzfEsH6FiIgcCAOLAzFeDkqMCoBczvoVIiJyHAwsDsTUf2Uw+68QEZFjYWBxEGL9SltgGcL6FSIiciwMLA4i96IKjVo9+nm6YliIj9TDISIisioGFgdx6Hxb/5Vo1q8QEZHjYWBxEMaCWy5nJiIiR8TA4gB0HetX2DCOiIgcEAOLA8i9pIZGq4efhytiw1i/QkREjoeBxQFkGfuvsH6FiIgcFAOLA+D+QURE5OgYWOycTm/AYdP+QWwYR0REjomBxc6dLlejoUUHX3cXjOjvK/VwiIiIegUDi5071KF+RcH6FSIiclAMLHYu6zyXMxMRkeNjYLFjeoOA7CIGFiIicnwMLHYsr1yN+hYdfFi/QkREDo6BxY6Z6leiWL9CRESOjYHFjpn2DxrM5cxEROTYGFjsFOtXiIjImTCw2Km8cjXUzTr4KF0Qx/oVIiJycAwsdiqrbXYlIcofLgp+GYmIyLHxk85Ocf8gIiJyJgwsdsjQoX4liYGFiIicAAOLHTpTUQ9VUyu83BQYNYD1K0RE5PgYWOyQ8XJQQlQA61eIiMgp8NPODmUVsX6FiIicCwOLnTEYBNMKoV+xYRwRETkJBhY7k19ZjyuNrfB0U2DUQD+ph0NERNQnGFjsTFaH+hVX1q8QEZGT4CeenTl0vm05czQvBxERkfNgYLEjBoOA7GLuH0RERM6HgcWOnK1qQK1GCw9XBcaEs36FiIicBwOLHTEuZ06I8mf9ChERORV+6tkR7h9ERETOioHFTgiCgCwW3BIRkZNiYLEThVUNuKzRwt1VjjHh/aQeDhERUZ9iYLETxstBEwb5w82FXzYiInIu/OSzE4eM7fijWb9CRETOh4HFDoj1K20Ft0MYWIiIyPkwsNiBc9UNqGnQQukiZ/8VIiJySgwsdsDYjn/CIH8oXRQSj4aIiKjvMbDYAWPBbRLrV4iIyEkxsNg4QRCQZSy4Hcz+K0RE5JwYWGzc+RoNqutboHSRIz6in9TDISIikgQDi40zXg4aF9kP7q6sXyEiIufEwGLjjO34uX8QERE5sx4FlvXr1yMqKgru7u5ISkpCdnb2NR87ZcoUyGSyTre7777b9JjKykrMnz8fAwYMgKenJ2bOnImzZ8/2ZGgORRAEFtwSERGhB4Fl27ZtSEtLw8svv4yjR48iPj4eM2bMQFVVVZeP3759O8rLy0233NxcKBQKzJkzB4D4oTx79mycP38e//3vf3Hs2DEMGjQIKSkp0Gg0N/fu7Fzx5UZU1bfAzUWOcZH9pB4OERGRZCwOLGvXrsWTTz6JBQsWIC4uDhs3boSnpyc2b97c5eMDAgIQFhZmuu3Zsweenp6mwHL27FkcOnQIGzZswMSJEzF8+HBs2LABTU1N+Ne//nVz787OGWdXxkawfoWIiJybRYFFq9UiJycHKSkp7SeQy5GSkoKDBw926xybNm3Cgw8+CC8vLwBAS0sLAMDd3d3snEqlEgcOHLjmeVpaWqBWq81ujsYYWFi/QkREzs6iwFJTUwO9Xo/Q0FCz46GhoaioqLjh87Ozs5Gbm4snnnjCdCw2NhaRkZFYunQp6urqoNVq8cYbb6CsrAzl5eXXPFd6ejr8/PxMt4iICEveis0T9w9i/xUiIiKgj1cJbdq0CaNHj0ZiYqLpmKurK7Zv346CggIEBATA09MT+/btw6xZsyCXX3t4S5cuhUqlMt1KS0v74i30mQuXG1GhboabQo7xkf5SD4eIiEhSLpY8OCgoCAqFApWVlWbHKysrERYWdt3najQabN26Fa+99lqn+yZMmIDjx49DpVJBq9UiODgYSUlJSEhIuOb5lEollEqlJcO3K1lFrF8hIiIysmiGxc3NDRMmTEBmZqbpmMFgQGZmJiZNmnTd537++edoaWnBI488cs3H+Pn5ITg4GGfPnsWRI0fwm9/8xpLhORTjhodJvBxERERk2QwLAKSlpWHevHlISEhAYmIi1q1bB41GgwULFgAAHnvsMQwcOBDp6elmz9u0aRNmz56NwMDOBaSff/45goODERkZiZMnT+LZZ5/F7NmzMX369B6+Lfsm1q+w4JaIiMjI4sAyd+5cVFdXY+XKlaioqMDYsWORkZFhKsQtKSnpVHuSn5+PAwcOYPfu3V2es7y8HGlpaaisrET//v3x2GOPYcWKFT14O46htLYJl1TNcFXIWL9CREQEQCYIgiD1IKxBrVbDz88PKpUKvr6+Ug/npnx2uBR//M8JJAzyx79/nyz1cIiIiHpNdz+/uZeQDTpUxMtBREREHTGw2KAsFtwSERGZYWCxMaW1jbh4pQkuchkmDGL9ChEREcDAYnOM7fjHhPvB083immgiIiKHxMBiYw6Z2vGzfoWIiMiIgcXGZLHgloiIqBMGFhtSVteIsromKFi/QkREZIaBxYYYVweNCfeDl5L1K0REREYMLDbEWHCbFM3LQURERB0xsNiQ9oZx7L9CRETUEQOLjbh4pQmltWL9SkIUAwsREVFHDCw2wrg786iBfvBm/QoREZEZBhYbkWXqv8LZFSIioqsxsNgIU/0KC26JiIg6YWCxAeWqJly43Ai5DEiIYv8VIiKiqzGw2ADj5aBRA/3g4+4q8WiIiIhsDwOLDTD2X2E7fiIioq4xsNiArCIW3BIREV0PA4vEKtXNKKrRtNWvMLAQERF1hYFFYsbLQSMH+MGX9StERERdYmCR2KG2gtukaM6uEBERXQsDi8SyWHBLRER0QwwsEqpSN+N8jQYyGTCRMyxERETXxMAioUNtq4Pi+vvCz4P1K0RERNfCwCIhXg4iIiLqHgYWCRlXCLHgloiI6PoYWCRSVd+Mc9Vi/UoiAwsREdF1MbBIJLutfiU2zBf9PN0kHg0REZFtY2CRSPv+QZxdISIiuhEGFokYd2hmwS0REdGNMbBIoKahBWerGgAAidw/iIiI6IYYWCTQXr/iA38v1q8QERHdCAOLBA6x/woREZFFGFgkwIJbIiIiyzCw9LHLDS0oqGyrX4nmDAsREVF3MLD0MWP9yvBQHwSwfoWIiKhbGFj6WFaRcTkzLwcRERF1FwNLHzPtH8SCWyIiom5jYOlDtRotzlTUA+D+QURERJZgYOlDxvqVmBBvBHkrJR4NERGR/WBg6UPsv0JERNQzDCx9qL3gloGFiIjIEgwsfeRKoxZnKtQAWL9CRERkKQaWPpJVVAtBAIaGeCPYh/UrRERElmBg6SNZ58XLQUmcXSEiIrIYA0sfYcEtERFRzzGw9AFVYyvy2upXktjhloiIyGIMLH0gu1isXxkc7IUQH3eph0NERGR3GFj6AC8HERER3RwGlj6QVdS2fxALbomIiHqEgaWXqZpaceqSWL/CGRYiIqKeYWDpZUfa6leig7wQ6sv6FSIiop5gYOll7fUrvBxERETUUwwsvYz7BxEREd08BpZepG5uRe5FFQAgKZqBhYiIqKcYWHrRkeJaGAQgKtATYX6sXyEiIuopBpZe1L5/EGdXiIiIbgYDSy8yFdwOYcEtERHRzWBg6SX1za3Ibeu/whkWIiKim8PA0kuOXKiD3iAgMsATA/p5SD0cIiIiu9ajwLJ+/XpERUXB3d0dSUlJyM7OvuZjp0yZAplM1ul29913mx7T0NCARYsWITw8HB4eHoiLi8PGjRt7MjSbwf4rRERE1mNxYNm2bRvS0tLw8ssv4+jRo4iPj8eMGTNQVVXV5eO3b9+O8vJy0y03NxcKhQJz5swxPSYtLQ0ZGRn45JNPkJeXh8WLF2PRokXYuXNnz9+ZxFhwS0REZD0WB5a1a9fiySefxIIFC0wzIZ6enti8eXOXjw8ICEBYWJjptmfPHnh6epoFlp9//hnz5s3DlClTEBUVhaeeegrx8fHXnbmxZQ0tOpw09l/hDAsREdFNsyiwaLVa5OTkICUlpf0EcjlSUlJw8ODBbp1j06ZNePDBB+Hl5WU6lpycjJ07d+LixYsQBAH79u1DQUEBpk+ffs3ztLS0QK1Wm91sRU5b/Uq4vwfC/T2lHg4REZHdsyiw1NTUQK/XIzQ01Ox4aGgoKioqbvj87Oxs5Obm4oknnjA7/t577yEuLg7h4eFwc3PDzJkzsX79etx2223XPFd6ejr8/PxMt4iICEveSq9qr1/h5SAiIiJr6NNVQps2bcLo0aORmJhodvy9997DoUOHsHPnTuTk5OCdd97BwoUL8d13313zXEuXLoVKpTLdSktLe3v43cbAQkREZF0uljw4KCgICoUClZWVZscrKysRFhZ23edqNBps3boVr732mtnxpqYmLFu2DDt27DCtHBozZgyOHz+Ot99+2+zyU0dKpRJKpdKS4fcJTYsOJ8uM+wexfoWIiMgaLJphcXNzw4QJE5CZmWk6ZjAYkJmZiUmTJl33uZ9//jlaWlrwyCOPmB1vbW1Fa2sr5HLzoSgUChgMBkuGZxNyLtRBZxAwsJ8HIgJYv0JERGQNFs2wAOIS5Hnz5iEhIQGJiYlYt24dNBoNFixYAAB47LHHMHDgQKSnp5s9b9OmTZg9ezYCA80vk/j6+uL222/HH/7wB3h4eGDQoEHYv38//vGPf2Dt2rU38dakkVUkXg7i6iAiIiLrsTiwzJ07F9XV1Vi5ciUqKiowduxYZGRkmApxS0pKOs2W5Ofn48CBA9i9e3eX59y6dSuWLl2Khx9+GLW1tRg0aBBWr16Np59+ugdvSVqH2vqvsH6FiIjIemSCIAhSD8Ia1Go1/Pz8oFKp4OvrK8kYGrU6xL+6G616AT/+cSovCREREd1Adz+/uZeQFR29cAWtegED/NwR7s/9g4iIiKyFgcWKOi5nlslkEo+GiIjIcTCwWBELbomIiHoHA4uVNGn1OF56BQALbomIiKyNgcVKjpXUoVUvIMzXHZEstiUiIrIqBhYraa9fCWD9ChERkZUxsFgJ+68QERH1HgYWK2huba9fSWJgISIisjoGFis4WlIHrd6AUF8logJZv0JERGRtDCxWkNV2OSgpmv1XiIiIegMDixV0bBhHRERE1sfAcpOaW/U4Zuq/woZxREREvYGB5SYdL70Crc6AYB8looO8pB4OERGRQ2JguUncP4iIiKj3MbDcpPaCW14OIiIi6i0MLDehRafH0ZI6ACy4JSIi6k0MLDfhl1IVWnQGBHkrMSSY9StERES9hYHlJhjrV5K4fxAREVGvYmC5Cey/QkRE1DcYWHrIrH6FBbdERES9ioGlh06UqdDcakCglxuGhnhLPRwiIiKHxsDSQ1msXyEiIuozDCw9dKit/wrrV4iIiHofA0sPaHUGHLnAwEJERNRXGFh64OTFK2huNSDAyw0xrF8hIiLqdQwsPXCoQzt+1q8QERH1PgaWHjA1jONyZiIioj7BwGKhVr0BR4rb+q8MYf0KERFRX2BgsdCJMhWaWvXo5+mKYSE+Ug+HiIjIKTCwWCirqP1ykFzO+hUiIqK+wMBiIfZfISIi6nsMLBZo1RuQU2xcIcTAQkRE1FcYWCyQe1EFjVYPPw9XxIaxfoWIiKivMLBYwHg5KJH1K0RERH2KgcUCxoJb1q8QERH1LQaWbtLpDThcZCy4ZcM4IiKivsTA0k2nLqmh0erh6+6C2DBfqYdDRETkVBhYusnYjj8xOhAK1q8QERH1KQaWbsri5SAiIiLJMLB0g3n9CgtuiYiI+hoDSzecLlejvkUHH3cXjOjP+hUiIqK+xsDSDVnG/itRAaxfISIikgADSzcYC255OYiIiEgaDCw3oDcIyDbuH8SCWyIiIkkwsNxAXrka9c06+ChdEMf6FSIiIkkwsNyA8XJQQpQ/XBT86yIiIpICP4FvwLjhIetXiIiIpMPAch16g4BsbnhIREQkORepB2DLdAYDlt01AjkX6jByAOtXiIiIpCITBEGQehDWoFar4efnB5VKBV9fhgsiIiJ70N3Pb14SIiIiIpvHwEJEREQ2j4GFiIiIbB4DCxEREdk8BhYiIiKyeQwsREREZPMYWIiIiMjmMbAQERGRzWNgISIiIpvHwEJEREQ2j4GFiIiIbB4DCxEREdk8BhYiIiKyeS5SD8BajJtOq9VqiUdCRERE3WX83DZ+jl+LwwSW+vp6AEBERITEIyEiIiJL1dfXw8/P75r3y4QbRRo7YTAYcOnSJfj4+EAmk0k9HJujVqsRERGB0tJS+Pr6Sj0cp8evh+3h18S28OthW3rz6yEIAurr6zFgwADI5deuVHGYGRa5XI7w8HCph2HzfH19+Y/fhvDrYXv4NbEt/HrYlt76elxvZsWIRbdERERk8xhYiIiIyOYxsDgJpVKJl19+GUqlUuqhEPj1sEX8mtgWfj1siy18PRym6JaIiIgcF2dYiIiIyOYxsBAREZHNY2AhIiIim8fAQkRERDaPgcXBpaenY+LEifDx8UFISAhmz56N/Px8qYdFbf70pz9BJpNh8eLFUg/FaV28eBGPPPIIAgMD4eHhgdGjR+PIkSNSD8sp6fV6rFixAtHR0fDw8MCQIUOwatWqG+4xQ9bzww8/IDU1FQMGDIBMJsMXX3xhdr8gCFi5ciX69+8PDw8PpKSk4OzZs30yNgYWB7d//34sXLgQhw4dwp49e9Da2orp06dDo9FIPTSnd/jwYfz1r3/FmDFjpB6K06qrq8PkyZPh6uqKXbt24fTp03jnnXfg7+8v9dCc0htvvIENGzbg/fffR15eHt544w28+eabeO+996QemtPQaDSIj4/H+vXru7z/zTffxLvvvouNGzciKysLXl5emDFjBpqbm3t9bFzW7GSqq6sREhKC/fv347bbbpN6OE6roaEB48ePxwcffIDXX38dY8eOxbp166QeltNZsmQJfvrpJ/z4449SD4UA3HPPPQgNDcWmTZtMx+6//354eHjgk08+kXBkzkkmk2HHjh2YPXs2AHF2ZcCAAXj++efxwgsvAABUKhVCQ0Px8ccf48EHH+zV8XCGxcmoVCoAQEBAgMQjcW4LFy7E3XffjZSUFKmH4tR27tyJhIQEzJkzByEhIRg3bhz+9re/ST0sp5WcnIzMzEwUFBQAAH755RccOHAAs2bNknhkBABFRUWoqKgw+7nl5+eHpKQkHDx4sNdf32E2P6QbMxgMWLx4MSZPnoxRo0ZJPRyntXXrVhw9ehSHDx+WeihO7/z589iwYQPS0tKwbNkyHD58GP/7v/8LNzc3zJs3T+rhOZ0lS5ZArVYjNjYWCoUCer0eq1evxsMPPyz10AhARUUFACA0NNTseGhoqOm+3sTA4kQWLlyI3NxcHDhwQOqhOK3S0lI8++yz2LNnD9zd3aUejtMzGAxISEjAmjVrAADjxo1Dbm4uNm7cyMAigc8++wyffvoptmzZgpEjR+L48eNYvHgxBgwYwK8H8ZKQs1i0aBG++uor7Nu3D+Hh4VIPx2nl5OSgqqoK48ePh4uLC1xcXLB//368++67cHFxgV6vl3qITqV///6Ii4szOzZixAiUlJRINCLn9oc//AFLlizBgw8+iNGjR+PRRx/Fc889h/T0dKmHRgDCwsIAAJWVlWbHKysrTff1JgYWBycIAhYtWoQdO3Zg7969iI6OlnpITm3atGk4efIkjh8/brolJCTg4YcfxvHjx6FQKKQeolOZPHlyp2X+BQUFGDRokEQjcm6NjY2Qy80/lhQKBQwGg0Qjoo6io6MRFhaGzMxM0zG1Wo2srCxMmjSp11+fl4Qc3MKFC7Flyxb897//hY+Pj+k6o5+fHzw8PCQenfPx8fHpVD/k5eWFwMBA1hVJ4LnnnkNycjLWrFmD3/72t8jOzsaHH36IDz/8UOqhOaXU1FSsXr0akZGRGDlyJI4dO4a1a9fi8ccfl3poTqOhoQGFhYWmPxcVFeH48eMICAhAZGQkFi9ejNdffx0xMTGIjo7GihUrMGDAANNKol4lkEMD0OXto48+knpo1Ob2228Xnn32WamH4bS+/PJLYdSoUYJSqRRiY2OFDz/8UOohOS21Wi08++yzQmRkpODu7i4MHjxYWL58udDS0iL10JzGvn37uvzMmDdvniAIgmAwGIQVK1YIoaGhglKpFKZNmybk5+f3ydjYh4WIiIhsHmtYiIiIyOYxsBAREZHNY2AhIiIim8fAQkRERDaPgYWIiIhsHgMLERER2TwGFiIiIrJ5DCxERERk8xhYiIiIyOYxsBAREZHNY2AhIiIim8fAQkRERDbv/we34Ruy8bDh/AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "graficar_accuracy(history3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se observa una mejora significativa del accuracy respecto a las variantes anteriores, por lo que se mantiene la modificación para las siguientes variantes a entrenar:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Aumentar cantidad de hidden units de LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_matrix):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 256\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_matrix.shape[1]\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embedding.weight.requires_grad = False  # marcar como layer no entrenable (freeze)\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
        "                            num_layers=self.num_layers) # LSTM layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm(out)\n",
        "        return (ht, ct)\n",
        "\n",
        "class Decoder_2(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim, embedding_matrix=None):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 256\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_matrix.shape[1] if embedding_matrix is not None else 50\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "\n",
        "        # Para utilizar versión con embedding preentrenados\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = False  # \n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
        "                            num_layers=self.num_layers) # LSTM layer\n",
        "        self.fc1 = nn.Linear(in_features=self.lstm_size, out_features=self.output_dim) # Fully connected layer\n",
        "\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
        "        out = self.fc1(lstm_output[:,-1,:])\n",
        "        return out, (ht, ct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint completo encontrado en: Modelos_entrenados/Aumentar_hidden_size\n",
            "No se encontró embedding_matrix_decoder.npy — se entrenará embedding en el Decoder.\n",
            "Checkpoint cargado desde: Modelos_entrenados/Aumentar_hidden_size\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder_2(vocab_size=nb_words, embedding_matrix=embedding_matrix)\n",
        "if cuda: encoder.cuda()\n",
        "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
        "decoder = Decoder_2(vocab_size=num_words_output, output_dim=num_words_output)\n",
        "if cuda: decoder.cuda()\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "if cuda: model.cuda()\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
        "\n",
        "# Verificar que si el modelo ya existe para cargarlo. Sino entrenar\n",
        "carpeta = \"Modelos_entrenados/Aumentar_hidden_size\"\n",
        "\n",
        "modelo_entrenado = check_checkpoint_exists(carpeta)\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "if not modelo_entrenado:\n",
        "    history4 = train(model,\n",
        "                    train_loader,\n",
        "                    valid_loader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    epochs=n_epochs\n",
        "                    )\n",
        "    config = {\n",
        "        # Información general\n",
        "        \"max_input_len\": max_input_len,\n",
        "        \"max_out_len\": max_out_len,\n",
        "        \"max_vocab_size\": MAX_VOCAB_SIZE,\n",
        "        \"cuda\": cuda,\n",
        "\n",
        "        # Hiperparámetros de embedding y red\n",
        "        \"embedding_dim\": embedding_matrix.shape[1],\n",
        "        \"hidden_size\": 256,      \n",
        "        \"num_layers\": 1,           \n",
        "        \"lr\": 0.1,\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": n_epochs,\n",
        "\n",
        "        # Vocabularios (usar tamaños reales)\n",
        "        \"num_words_input\": int(embedding_matrix.shape[0]),\n",
        "        \"num_words_output\": int(num_words_output),\n",
        "\n",
        "        # Checkpoint info (opcional)\n",
        "        \"embedding_source\": getattr(model_embeddings, \"name\", \"custom\"),\n",
        "    }\n",
        "    save_checkpoint(carpeta, model, optimizer, history4, config,\n",
        "                    input_tokenizer, output_tokenizer,\n",
        "                    word2idx_inputs, word2idx_outputs, embedding_matrix)\n",
        "else:\n",
        "    data = load_checkpoint(carpeta, Encoder_2, Decoder_2, Seq2Seq, device=\"cuda\" if cuda else \"cpu\")\n",
        "    model = data[\"model\"]\n",
        "    optimizer = data[\"optimizer\"]\n",
        "    history4 = data[\"history\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVt5JREFUeJzt3XtclGXeP/DPzMDMMBxGOYNyMM8mooKQ1polGx7WzTLT1DQz3fbRtmTtl5TaVlt0WmJrLZ96cE9puGy2WRarkVmWhqGkFAJqhgcYwAMjA8zAzP3742ZmGBmUQWCYmc/79ZoXcM8991wDyny4rut7XRJBEAQQERERuTipsxtARERE1B0YaoiIiMgtMNQQERGRW2CoISIiIrfAUENERERugaGGiIiI3AJDDREREbkFhhoiIiJyC17ObkBvMZlMOHfuHPz9/SGRSJzdHCIiIuoEQRBw+fJlREZGQiq9el+Mx4Sac+fOISoqytnNICIioi44ffo0Bg4ceNVzPCbU+Pv7AxC/KQEBAU5uDREREXWGVqtFVFSU5X38ajwm1JiHnAICAhhqiIiIXExnpo5wojARERG5BYYaIiIicgsMNUREROQWGGqIiIjILTDUEBERkVvoUqjZuHEjYmNjoVQqkZycjIKCgquen5WVheHDh8PHxwdRUVFYvXo1mpqaHLrmlClTIJFIbG4PP/xwV5pPREREbsjhULNt2zakpaXh6aefxqFDhxAfH4/U1FRUV1fbPX/r1q1Yu3Ytnn76aZSUlCA7Oxvbtm3Dk08+6fA1ly9fjsrKSsvt5ZdfdrT5RERE5KYcDjWZmZlYvnw5li5dilGjRmHTpk1QqVTYvHmz3fO/+eYb3HzzzViwYAFiY2Nxxx134L777rPpiensNVUqFcLDwy03rjdDREREZg6FGoPBgMLCQqSkpFgvIJUiJSUF+/fvt/uYSZMmobCw0BJiTp48iU8++QQzZsxw+JpbtmxBcHAwRo8ejfT0dDQ0NHTYVr1eD61Wa3MjIiIi9+XQisK1tbUwGo0ICwuzOR4WFoZjx47ZfcyCBQtQW1uLW265BYIgoKWlBQ8//LBl+Kmz11ywYAFiYmIQGRmJI0eO4IknnkBpaSm2b99u93kzMjLwzDPPOPLyiIiIyIX1+DYJX3zxBV544QW8+eabSE5OxvHjx/Hoo4/iueeew/r16zt9nRUrVlg+j4uLQ0REBKZOnYoTJ05g8ODB7c5PT09HWlqa5Wvz3hFERETknhwKNcHBwZDJZNBoNDbHNRoNwsPD7T5m/fr1uP/++/HQQw8BEAOJTqfDihUr8NRTT3XpmgCQnJwMADh+/LjdUKNQKKBQKBx5eUREROTCHJpTI5fLkZCQgPz8fMsxk8mE/Px8TJw40e5jGhoaIJXaPo1MJgMACILQpWsCQFFREQAgIiLCkZdA7k57DjjwFvDdZqCpztmtISKiXuTw8FNaWhqWLFmCxMREJCUlISsrCzqdDkuXLgUALF68GAMGDEBGRgYAYNasWcjMzMS4ceMsw0/r16/HrFmzLOHmWtc8ceIEtm7dihkzZiAoKAhHjhzB6tWrMXnyZIwZM6a7vhfkqgw6oORj4Pv3gJNfABDE4/9dB8TPB5KWA6EjndlCIiLqBQ6Hmnnz5qGmpgYbNmxAVVUVxo4di7y8PMtE34qKCpuemXXr1kEikWDdunU4e/YsQkJCMGvWLDz//POdvqZcLsdnn31mCTtRUVGYM2cO1q1bd72vn1yVyQT8vA/4Pgf48UPAUG+9L+omsZempgT4Llu8xf4CmPAQMGImIPN2XruJiKjHSARBEJzdiN6g1WqhVqtRV1fH9W1cWW252CNz5F9A3Wnr8f6xQPx9wJh7gcAbAEEATu0DCt4Gju0EBKN4nn8kkPggkLAE8At1yksgcqoWPdB4Sfz3L5E4uzVE1+TI+zdDDfV9DReA4vfFXpmz31mPK9TAjbOBsQuAqOSOf0HXnQUK/woU/g3Q1YjHpN7AjXeJQ1MDJ/CXO7k3QQDOHBT/ICjeDjRdAkb8CpjxKhDAeYnUtzHU2MFQ42JaDMDx3eIv4dI8wNQsHpfIgCFTxV6Z4dMBbx8HrqkXh6oK3hZ/wZtFxANJK4DRcxy7HlFfd/FnsVfz+/eACyfa369QA3c8B4xfzGBPfRZDjR0MNS5AEIBzh8UemeJ/Aw3nrfeFx4lBZvQ9gH9Yx9forHOHgYL/A47mAka9eMynPzDufmDCMnE4i8gVNWnF8P59jjjvzMzbFxj1a3HyvCoI2PE74Nwh8b7YXwCz/gwEtV8eg8jZGGrsYKjpw+rOAkf/Jf4SrmmzMrVfGBA3Vwwz4aN75rkbLgCH/iFOJr5U0XpQAgybJg5N3XAbIO3SZvZEvcdkBE7uEf8PlXwMtDS23iEBBk0W/w+NnAUo/Gwfc+At4PM/iud7+QC3PQnc9D+ArMfXZSXqNIYaOxhq+hiDDij5qLUMey8sZdheSrFCKX4BcMOU3vvlajIC5bvEoakTn1uPBw4Ww038fYBPv95pC1FnaX60Tpyvr7IeDx5mnTivHnj1a1z4CfjoUeCnveLXEWOBO/8i9o4S9QEMNXYw1PQBJhNw6itrGXazznpfzM1it/ioOwGl2nltBIDa48DB/wOKtgD61o1QvVXAmHliwAm70bntI89WXyMOm37/HlB1xHrcJxCIu0f8fxQ53rE5MoIg/nv/75PicghSL+DmR4HJ/w/wVnb/ayByAEONHQw1TmQuw/5+G6A9Yz3ef1CbMuxBzmtfR/T1wJFtYsCp/tF6POYWIOkhsXqEa95Qb2huAso+Ff8gKN9tXaJA6g0MSxX/Hw29A/CSX9/zXK4CPnkcKNkhfh00FPj1G0BMx6u795YWowlNLSY0NRstN0OLAIW3FCq5DD7eMvjIZZDLpJBw0rNbYaixg6Gml1nKsN8DzhZajyvUwOi7xOGlqCTXqLgQBODnr8WhqZKP26x5EyGueTN+SfdMXiZqSxCA0wXi/6Eftttu+zEgoXXi/BxAFdj9z/3jDuCTNUB96558Ex4Cpj4NKK2/OwVBQLNRQFOLEU0GI5qaTWhsEzjEz03QtxjRaDAfaw0lbR7TZL6/xSQea7F9vPl6zcbOvVXJpBJLwPHxlkEll0HZ+tF83Pq5l/UcuQyqKz63nNvmPIWX64cmo0lAU7MR+hbx56NvNlk+N//M2h7Tt5igbxZ/RvrmNsdaz2tqvV/fYkLcADXWpA7v1vYy1NjBUNMLWgzivJTv3wPK/mtbhj30l2K3+LDprt2dXXdWXO+m8K+2a96MulMsC+/GoFavb4G+2Yj+KjmkUtf+JUoOuHhK7NX8/j3g4k/W4wEDgfh5wJj5QMiwLl260WDEsSotTp3XocFgGxquDBLSpku4u/Z/MaUhDwBQLQnCy14PY49pnOVck5PePRReUii9ZfCWSVvfiDsfeq6XRAIxELULSOYQ5WUJUTaBql2o8rJ8rvSSodlkDQxNNsHBGhisQcRO8Gj7mDaf2zym9fOWHvzB/WJoMP65LLlbr8lQYwdDTQ8RBLEs9Psc4Oi/gcYL1vvCx4h/Tcbd436r97boxb9mD74DnP7Wejx8jDjvZvQ9gFx1zcsIgoCaej1OVOtwvKYeJ6rrcbz1VqVtAgB4yyQIC1AiPECJcHWbj2olItRKhAWIN28Zq7RcVlNdmzLsr63HvX3FwBw/Xyy77mQlniAIqLmsxw+VWpRUavHjOS1+rNTiVK3O4SAySVqMDK//Q4y0GgDwH+MkPNu8GBdg/T0qlQBKb/EN3MdbBoW3FEov8Q1c2fq5svXN20fe+nXrG7w5oPi0Pl7pLW29hvmY7f0KL6ndkN9sFHuKGg3ircFgRGNzCxoNJjQYWqz3NRtbA5340fp5CxqbTWhsPbfBIPYmNbR+bmgxOfaNcxHeMgmUXuLPTOElfn/lXlIovK0/G4WXtPVmPq/t8daPrY+PVCsxaUhwt7aRocYOhppuVnemdVGvHKC21HrcL0ycIxN/n+dMqD1XJIabo/8GWsQgAmU/YPz9QOIyIHAQjCYBZy42WALLiRpreNE2tVx3EyQSIMhXYQk5Eer2ASg8QAlfBUt1+wxji7gB6/fvAcc+tv7bgQS44Vbx/9CIX9mWYdvRYjThp1odfmwTXkoqtaitN9g9P9hPgaGhfvBXetmECOUVQaJtyFBJDBjyw+uIKNkMiWCCURmI+tueA+LuhdJD5rEYTYJNaGo0B6E2Qcl+cGqxCVGNbc5rMFh7yLxlUptwoGwTMjobKGweY/P4Nvd5W68n95JC5gK9wAw1djDUdAN9vbUM+6cvYS3D9gFG/kr8a3LQFM9d46LhApoL/wGhIBvyy+KaNyZIcNArAW/rU/B582gIaP+XtkQCRPVXYUioHwaH+GJIqF/r535Qyb1QfbkJVXVNqNK2fqxrQqW2CZq6JlTWNaH6clOnu979lV42PT4RaiXC2vT4RKh90F/l7fZvUE6l+QEo2ipWMJnnrABA8HBg7H1A3L2AeoDdh15uasaxqss2vS+lVZeht9OLIJUAN4T4YWREAEZFBGBUZABGRvgj1P86hn/PFoqL9mmKxa+H3gH86rVrl40TXQeGGjsYarrIZGxThr3jijLsW9qUYXvW97SuoRnHay639rroLL0upy82QCKYcKv0eyyR7cIU2feWx5wSwvFfn5koHzAbA8LDLeFlULAvlN6yLrfFZBJwXmeARiuGnKo2gUc81oiquiboDMZOXU/uJRWDzxW9PG0/D/VXwIvDXZ1XX92mDPuo9bhPYOsCk/OByHGW+ViCIOBcXRNKWoPLj+e0KKnS4ufzDXYvr5LLrggvARge5g8fedf/XXXI2Ax8nQXsfRkwGgC5H5DyB7FXkgtVUg9gqLGDocZBNWWti3ptA7RnrccDb2gtw54H9I9xXvt6gSAIqNI2WQKLddhIh9p6fYePC1B6WQLLeL8LmHThPxh4ajukhrZr3twLTFjecysl23G5qdkafOqu6P1p/XheZ3/I4kpSiTiM0Xa468oen/AAZc+8qbqK5iag9BPxD4Ljn9mWYQ+fJv4/GvJLGOCF49X1lmEjcw9MXWOz3ctGqJUYFSEGl1GRYpCJDlT1/mTymlKx1+b0AfHr6InArNe7PImZqCMMNXYw1HRCfbU4WbFoq3VPGEBcDG/0HPGXsBvuaN1sNOHn8w2WeS4nqustk3av1rsRoVZahokGh/phSIgYZIL95O2Hbww6cQ5SwTtA9Q/W49GTxInFI2f1iTVv9C1GVGv1NkNdVwYfjbap09UTah9vsWcnQIF+KjkCVd7op5Kjv8ob/X3l1s9VcvRTecNP4eXaQ1+CIE4cL9oK/PAfQN+2DDsRjaPuRXH/qThyQWYJL8erL9sdPvSSSjAk1M+m92VkRAACfa9zLZruZDKJW4x89gfAUA/I5MCt/w+4+bE+8e+5zzPPq/rpC0AdDQxMAMLirn+9ITfDUGMHQ00bDRfEv7JqSoDqY9aPumrrORKZOF4eP1/cB8mVy7BbNRhaWquMWoeNWiuOfj6v63BOikwqQUyQyhJY2oYYv65MuhUE4OdvxInFP+6w/vXuFy6ueZOwBPAPv45X2fNMJgG1Oj00dXpU1jXaDHu1DT8NnRzuastbJoHaxzbo9FfJ0c9X/NjfEoqsn/dTeTu/8uvCT2Kv5vc5NmXYjT4ROBKYih2Ygi/Oq3H2UqPdh/srvdr1vgwN84PCy0V6ui6dBj5eDRzfLX4dNlpctG/AeOe2qy8SBODMd+J+d8XbgYZa2/tlCiBiDDAgERjYeusX43Z/TDqCocYOjww1jZfEDSKrS2w/tp2ceKWIeOtu2H4hvdbU7lTX2IxjlVocb1NhdKK6Hufqmjp8jEouE8NKm4m6Q0L9EB3oC7lXD71has+1rnnzN+vPROrVZs2bZJf9RSYIAi7rWyxze2ou63GxwYBLDc02Hy82NONSgwEXGwxoau56yay/wssSfK7s/Wn70fK5rxy+ctn19Qo11QE//AemovcgPb3fcrhR4oP/mpKxrflmHDCNbDc5fGB/H5vel1ERARjY38e1e6gA8c36aC7w6RPi0g4SKTBxJTDlyU4tb+D2asrEIHM0V1yLyEwVJK7fVa8Bzn4HNF5s/1hVsBhuBiSKvTmR4z1qLzqGGjvcOtQ0XrLf89J2g7srqaOAkBFAyHAgdCQQMlIcC1f491qzu9P5ej12/ajBJ0crsf/E+Q6HR4J85eJQUetwkfnziACl8xa4azGIy9IXvGOdnwCI3dCJDwAjZnnEisVNzUYx6OjMQcccgNp+bvuxrrEZXf0NJpdJoVZ5t+n96SAU+Vp7hQRjCzSHP4Xyx22IrvkCckGcg2QSJNhnGo3txl/gv6ZENEIJuUyKYeF+GBlu7X0ZEREAtY+bD8voasVgU/xv8ev+g4Bfvy7uFu5ptOfEldWP/Mt2ny5vX7FiNG5u68a9rf8mBAG4cFKsMjvzHXDmoDix3GRnflXwMGvIGZAoLqHhpkN+DDV2uEWoaaoTw4tNz0spcPlcx48JGAiEjmgNMCNaA8xwlw0vbVVrm/DfH6rwydEqfPvTeZtFxQb298HQ1qGitsNG/fvSfAR7Ko+IQ1NHcoEW81CFRPwrbcRMYPhMTsRsw2gSoG28stfH2vtzQWf9vG3vkCMLqSlgwETpj7hdehjTZQUIkVjnyZSbBuB94y+wRz4FwQMG2fTADA7xc/6wmDOV/VcckjIXGoxfDPzyOffvYWi8JM5NPJoLnNoHy9IXUi9gSIoYZIZPB+S+nbtec5MYbM5+Jwads9/Z9vSYefkAkWPFLTTMvTrqgS7b29sWQ40dLhVqmrRX9Ly03tpWIV0pYIAYVkJGtoaY1vDiZqXW5y41Iq+4Cp8WV+K7ny/a/JU+ekAApo+OwPTR4bgh5OoLlvV5DRdaJ5tut907CxA3GRwxU7wNSGQZrYMEQVxE7WJDMy7q2vb+WHuEhLpziLnwNUbV78cYw2H4wFrtdgkBKFJPheaGuxEyLAmjIvshLEDh+sNHPaFJK04i/i5b/NovHJj5qjgx3p00NwFleWKQKd8llrqbRU8Ug8yo2YBvUPc8n67W2ptz9jvx87Z7g5n5hdn25gwY75J/0DLU2NEnQ43+sm3PS80xMcS03cn6Sv4RbXpc2vS8KNW91+5eVnG+AZ8WV+LT4ioUnb5kc9/YqH6YEReO6aMjEBXopuP22kqxNLj0E+DkXtuuaN9Q8a++Eb8Su/fdYEK3U5hMwLnD4htTWZ7tUAEA+EfCNPQOtAyZBvmwqaxOcdTP3wA7HgHOHxe/HnUnMP0V1x5WNRnFRUiP5oqLkuq11vtCR4lBJu4eoF90L7TFJH5v2/bmaH4ATFeuVi4R3zcGJoiVrAMSxfcQad+ekM5QY4dTQ42+3trzYg4uNceAutMdP8Yv3Nrj0rbnxd27bludrKnHp609MsVnrb8sJBIgMaY/po+OwLTR4Yjs5+PEVjpBk1Zc8+TYTvEvwra/SOV+wJCpYsAZ+kvAp7/z2ukK9JeBE3vEYZLyXbbVf5CI3fjDpgHDUoHwOLfoxneq5ibgy5eBfVli1Z+yH5D6PDB2oet8bwVBDL9Hc8W5Mm2LLgIGiiFmzL19Y4uY5kag8ntryDlTCNRVtD/P21dc+NHcmzMwEQiI7P32XgVDjR29EmoMutYel7bzXo7Z/4dk5hdmv+fFw96QBEFAeXU9PjlaibziKhyrumy5TyoBbrohCNNHhyP1xnCEBrA3AoA4wfjnfWLAOfaJ7dwqqRcQc3PrPJwZQL8o57WzL7nwkxhiyvLE+Q5te73k/sCQ28UgM+SXLlv91+dVHgF2rBLfcAFxouyvsoDAQc5s1dWdPyEGmaO51t4mQPw9feNdYq9M1E19fyj4skYcqjrbOgn57GHAcLn9ef6RtiEnclzn5wD1AIYaO3os1FQcAL7KFHthLl0lvPiGXtHz0npTBXZfW1yMIAj4sVKLT4+KPTInaqxbMHhJJZg0JBjTR4fjjlFhCPJTOLGlLsD8F+SxneIwVfWPtvdHxIuTjEfMFP+KdJW/jK+XsUVcDK8sTwwzbTdfBcTKnOHTxd6Y6EkcVuotxhbgwEZgzwviRp7eKuD2dUDyw31nKOSyRpzTduRftouRevkAI2aIQWawiw9FmoxAbZltb071D4BwxUR6iVQcUrOUlSeK1Ve99LNiqLGjx0LNyS+Af9xp/do3xLbHJWSk+LkHh5e2BEHAkTN1+KRY7JFpu5eNXCbFL4YGY9rocPxyVBj6qVz4l4WzXTgp9t4c2ymWibf9JdUvWhyiGj5DnMTobhuQNlwQh+jK8sSPbSdQSmRAzCQxxAybBgQN8ZyA1xedPwF89Ki4vxwgDvn9+i9A2CjntKdJK86POZoL/LTX+v9GIgMG3yZuNjpihktOtu00gw44V9Rmfk6h/SIVuT8wYJw15AxI7LE5Ugw1dvRYqGm8CBz9t3Wtl+6a3e5GTCYBh09fxCdHq5BXXGWzqqrCS4opw0MwfXQEbh8ZigCle66z4FS6WvEN/thO4MTn4l/GZj79xTf3ETOBwbc7tYu5ywRBHOo198ac/tY2xPkEiqtjD0sVX6OHzEtzGYIAHPo7sGu9OEdM6g38Ig34xe8Br17ooW3RA+W7xSBTlmf7/2PgBDHI3HiXZw9HaiutQ1ZnCsVe4babG5upo8TfJzNf7d6nZ6hpr09WP7kxo0nAwVMX8OnRSuT9UAWN1loSq5LLcNuIUEwfHY7bhofCtyvbDVDXGHTi5NjST4DST8WVX828lMANt4kBZ9i0vv1LvLlJnE9knh9z5dBv6I3W3piBiX1nSIM6pq0EPlkDHPtY/Dp4OHDnX4CopO5/LpMJ+PlrcYXfHz+07c0LHiYGmbh7+vY8H2cyGcV5o217c6pLAAhiL/D8Ld36dAw1djDU9LwWowkHTl7AJ8WV2PVDFWrrrWs1+Cm8kDIyFNPjInDrsBAovfkm43Tm+SbHdopvJJd+bnOnBIi+yTrROGiw05ppcbnKWql0Yo/tX4oyhVjSPixVvPVGGS11P0EQQ8YnawBdDQAJkPwb4Pb1gOI6154SBHERu6P/Ao6+bzux3j9C3LR3zL1A+BgOSXaF/rLYg+Ol7PYgylBjB0NNzzC0mPD1iVp8erQSu3/U4GKDtZpE7eONX44Kw4y4cNw8JNh1NufzRIIgTi4+tlO8VRbZ3h8yUpxLMGImEDGud6o8TCaxHebemCvb5B9h7Y0ZNNk1h87IvoYLwK51QFHrX/zqaGDWa+KKvI66eEocWjqSaztRXKkW18uJmytWCrI3r89iqLGDoab7NDUb8VV5a5Ap0eByk3WBp0BfOVJvDMP00RGYODjIs5eJd2WXTovDU6U7W0uf2yzi5R8h9t6MmAnE/qJ7qz/09eLk+7I8sUfmys1XbdaO4V/Ubu94PvDxY9bhxTHzgWkZ1y680NUCP3wgVi6dKbAelymA4dPEIDP0jt6Zs0PXjaHGDoaa69NoMOKL0mp8UlyFz0s00BmMlvtC/BWYdmM4pseFIyk2EF4MMu6l8ZI4kfLYx2I1kaHeep8iQFzob/gM8WNXVra+eAoo29W6dsxXtkvMy/3EqhPz2jGuvAItdY2+HtjzPHDgLQCCuGP1jJeBG++2DbX6enGu2JF/iRPihdbfURKp2JMXd6+4iaQbr77urno81GzcuBGvvPIKqqqqEB8fjzfeeANJSR2PoWVlZeGtt95CRUUFgoODcc899yAjIwNKpbLT12xqasLvf/975OTkQK/XIzU1FW+++SbCwjr3S46hxnH1+hZ8fqwanx6txBelNWhstgaZCLUS00aHY0ZcBMZH94fMWTtcU+9q0YtLwx/7WOzJaduTIvUGBv3COg+no1VJjS3iX89leWKYqSmxvb9/LDCsde2YmEn8a5pEpw+KWy2Y/70Mmw5Mf1Fc4PRorhhomq1LRCBynBhkRt8N+Ic7p83ULXo01Gzbtg2LFy/Gpk2bkJycjKysLOTm5qK0tBShoaHtzt+6dSsefPBBbN68GZMmTUJZWRkeeOABzJ8/H5mZmZ2+5m9/+1vs3LkTf/vb36BWq7Fq1SpIpVJ8/fXX3f5N8WR1jc3IL9Hgk6NV+LK8xmY346hAH8uGkfED+0HKIOPZTCax6qG0dR5ObZnt/ZHjrRtv+oeLQwlleWKvT9Ml63kSmbhejnl+TPBQDiuRfS0GYF8m8OWrtqtBmwXe0Fq5NBcIHtL77aMe0aOhJjk5GRMmTMBf/vIXAIDJZEJUVBQeeeQRrF27tt35q1atQklJCfLz8y3Hfv/73+Pbb7/Fvn37OnXNuro6hISEYOvWrbjnnnsAAMeOHcPIkSOxf/9+3HTTTddsN0PN1bUYTVj9r++RV1yJZqP1n8SgYF9Mb+2RuTEygDsRU8dqy60Tjc8cBHCVXy0+/cXhpGGp4n5VHrYtCF2n6hKx1+bMQXG19tFzgDFzxSDN31Fux5H3b4cWCDEYDCgsLER6errlmFQqRUpKCvbv32/3MZMmTcK7776LgoICJCUl4eTJk/jkk09w//33d/qahYWFaG5uRkqKdeb7iBEjEB0d3WGo0ev10Outa6Notdp255BV0elL+Oh7scRxWJgfpo2OwIy4cAwP82eQoc4JHgrc8ph4u6wByj4VVzU++QVg1IvLrJt7YwYkut9KxtR7QkcCD+4Sy7L9wvlviSwc+pdQW1sLo9HYbh5LWFgYjh07ZvcxCxYsQG1tLW655RYIgoCWlhY8/PDDePLJJzt9zaqqKsjlcvTr16/dOVVVVXafNyMjA88884wjL8+jlWnEyZ+/GBqMfy5LdnJryOX5hwEJD4g3fb246B8n+VJ3kkoB9UBnt4L6mB4vU/niiy/wwgsv4M0338ShQ4ewfft27Ny5E88991yPPm96ejrq6uost9OnT/fo87m6Mo24U+vwMDfe04ScQ+HHQENEvcKhnprg4GDIZDJoNLZrR2g0GoSH259dvn79etx///146KGHAABxcXHQ6XRYsWIFnnrqqU5dMzw8HAaDAZcuXbLprbna8yoUCigUrJrorPJqMdQMY6ghIiIX5VBPjVwuR0JCgs2kX5PJhPz8fEycONHuYxoaGiC9YvVRmUxcuVEQhE5dMyEhAd7e3jbnlJaWoqKiosPnJceYh5+GhF3nUuRERERO4vDsqrS0NCxZsgSJiYlISkpCVlYWdDodli5dCgBYvHgxBgwYgIyMDADArFmzkJmZiXHjxiE5ORnHjx/H+vXrMWvWLEu4udY11Wo1li1bhrS0NAQGBiIgIACPPPIIJk6c2KnKJ7q6Sw0G1FwWJ1UPDWWoISIi1+RwqJk3bx5qamqwYcMGVFVVYezYscjLy7NM9K2oqLDpmVm3bh0kEgnWrVuHs2fPIiQkBLNmzcLzzz/f6WsCwGuvvQapVIo5c+bYLL5H16+8WuyliVQr4a/0dnJriIiIuobbJBC2fPsznvqgGLcOC8HfH+ze3VWJiIiuhyPv39ykh1DeOp9mGOfTEBGRC2OoIUs591BWPhERkQtjqCFL5RPLuYmIyJUx1Hi4izoDauvFyqchrHwiIiIXxlDj4cxDTwP6+cBPwf1TiIjIdTHUeDhzOfdQThImIiIXx1Dj4co13B6BiIjcA0ONhzNPEuZKwkRE5OoYajwcN7IkIiJ3wVDjwS7oDKitNwBg5RMREbk+hhoPZq58GtjfB76sfCIiIhfHUOPBzJOEOZ+GiIjcAUONB+NKwkRE5E4YajyYeZIw93wiIiJ3wFDjwbg7NxERuROGGg91vl6P8zpWPhERkftgqPFQ5vk0UYE+UMlZ+URERK6PocZDWRbdC+V8GiIicg8MNR7KvEYNJwkTEZG7YKjxUNzziYiI3A1DjYc6Xs01aoiIyL0w1Hig2no9LugMkEhY+URERO6DocYDmefTRPVXwUcuc3JriIiIugdDjQfiontEROSOGGo8ECufiIjIHTHUeCD21BARkTtiqPEwgiCgzLyRJRfeIyIiN8JQ42Fq6vW41NAMiQQYHMKeGiIich8MNR7meOvQU3QgK5+IiMi9MNR4GMskYQ49ERGRm2Go8TBl1ZwkTERE7omhxsOUt/bUcHsEIiJyN10KNRs3bkRsbCyUSiWSk5NRUFDQ4blTpkyBRCJpd5s5c6blHI1GgwceeACRkZFQqVSYNm0aysvLr3mdhx9+uCvN91iCIFg3smRPDRERuRmHQ822bduQlpaGp59+GocOHUJ8fDxSU1NRXV1t9/zt27ejsrLScisuLoZMJsPcuXMBiG+0s2fPxsmTJ/Hhhx/i8OHDiImJQUpKCnQ6nc21li9fbnOtl19+uQsv2XPVXNajrrEZUlY+ERGRG3I41GRmZmL58uVYunQpRo0ahU2bNkGlUmHz5s12zw8MDER4eLjltnv3bqhUKkuoKS8vx4EDB/DWW29hwoQJGD58ON566y00Njbivffes7mWSqWyuVZAQEAXXrLnKmtT+aT0ZuUTERG5F4dCjcFgQGFhIVJSUqwXkEqRkpKC/fv3d+oa2dnZmD9/Pnx9fQEAer0eAKBUKm2uqVAosG/fPpvHbtmyBcHBwRg9ejTS09PR0NDQ4fPo9XpotVqbm6crr+b2CERE5L4cCjW1tbUwGo0ICwuzOR4WFoaqqqprPr6goADFxcV46KGHLMdGjBiB6OhopKen4+LFizAYDHjppZdw5swZVFZWWs5bsGAB3n33XezZswfp6en45z//iUWLFnX4XBkZGVCr1ZZbVFSUIy/VLZVxewQiInJjXr35ZNnZ2YiLi0NSUpLlmLe3N7Zv345ly5YhMDAQMpkMKSkpmD59OgRBsJy3YsUKy+dxcXGIiIjA1KlTceLECQwePLjdc6WnpyMtLc3ytVar9fhgw8onIiJyZw6FmuDgYMhkMmg0GpvjGo0G4eHhV32sTqdDTk4Onn322Xb3JSQkoKioCHV1dTAYDAgJCUFycjISExM7vF5ycjIA4Pjx43ZDjUKhgEKh6MzL8ghi5RMX3iMiIvfl0PCTXC5HQkIC8vPzLcdMJhPy8/MxceLEqz42NzcXer3+qkNGarUaISEhKC8vx3fffYc777yzw3OLiooAABEREY68BI9VfVkPbVMLpBLghhBfZzeHiIio2zk8/JSWloYlS5YgMTERSUlJyMrKgk6nw9KlSwEAixcvxoABA5CRkWHzuOzsbMyePRtBQUHtrpmbm4uQkBBER0fj6NGjePTRRzF79mzccccdAIATJ05g69atmDFjBoKCgnDkyBGsXr0akydPxpgxY7ryuj2OuZcmNsiXlU9EROSWHA418+bNQ01NDTZs2ICqqiqMHTsWeXl5lsnDFRUVkEptO4BKS0uxb98+7Nq1y+41KysrkZaWBo1Gg4iICCxevBjr16+33C+Xy/HZZ59ZAlRUVBTmzJmDdevWOdp8j8VF94iIyN1JhLazcd2YVquFWq1GXV2dR65vs/b9I8g5eBqrbhuCNanDnd0cIiKiTnHk/Zt7P3mI8mr21BARkXtjqPEAbSufWM5NRETuiqHGA2i0elxuaoFMKmHlExERuS2GGg9g7qWJCVJB4cXKJyIick8MNR7AMvTERfeIiMiNMdR4gHLu+URERB6AocYDlLXuzj2Ek4SJiMiNMdS4OUEQcJw9NURE5AEYatxclbYJl/Vi5dOgYFY+ERGR+2KocXPm7RFiWflERERujqHGzZVz0T0iIvIQDDVuzlzOPZShhoiI3BxDjZsr4yRhIiLyEAw1bkwQBByvNoca9tQQEZF7Y6hxY+fqmlCvb4GXVILYIFY+ERGRe2OocWPmScKxwb6Qe/FHTURE7o3vdG6M2yMQEZEnYahxY5bKJ25kSUREHoChxo2VcZIwERF5EIYaNyXu+WReeI/DT0RE5P4YatzU2UuN0BmMYuUT93wiIiIPwFDjpsyThAcF+8Jbxh8zERG5P77buanyau75REREnoWhxk2Zt0cYyvk0RETkIRhq3BR35yYiIk/DUOOGTCYB5dVceI+IiDwLQ40bOnupEQ0GI7xlEsRwzyciIvIQDDVuyDxJ+IZgP1Y+ERGRx+A7nhviJGEiIvJEDDVuiHs+ERGRJ2KocUPHOUmYiIg8UJdCzcaNGxEbGwulUonk5GQUFBR0eO6UKVMgkUja3WbOnGk5R6PR4IEHHkBkZCRUKhWmTZuG8vJym+s0NTVh5cqVCAoKgp+fH+bMmQONRtOV5rs1k0mwrCY8lOXcRETkQRwONdu2bUNaWhqefvppHDp0CPHx8UhNTUV1dbXd87dv347KykrLrbi4GDKZDHPnzgUgbrw4e/ZsnDx5Eh9++CEOHz6MmJgYpKSkQKfTWa6zevVqfPTRR8jNzcXevXtx7tw53H333V182e7r7KVGNDYbIZdJERukcnZziIiIeo/goKSkJGHlypWWr41GoxAZGSlkZGR06vGvvfaa4O/vL9TX1wuCIAilpaUCAKG4uNjmmiEhIcI777wjCIIgXLp0SfD29hZyc3Mt55SUlAgAhP3793fqeevq6gQAQl1dXafOd1Wf/VglxDzxsZD62l5nN4WIiOi6OfL+7VBPjcFgQGFhIVJSUizHpFIpUlJSsH///k5dIzs7G/Pnz4evr7h+il6vBwAolUqbayoUCuzbtw8AUFhYiObmZpvnHTFiBKKjozt8Xr1eD61Wa3PzBGUceiIiIg/lUKipra2F0WhEWFiYzfGwsDBUVVVd8/EFBQUoLi7GQw89ZDlmDifp6em4ePEiDAYDXnrpJZw5cwaVlZUAgKqqKsjlcvTr16/Tz5uRkQG1Wm25RUVFOfJSXZZle4RQThImIiLP0qvVT9nZ2YiLi0NSUpLlmLe3N7Zv346ysjIEBgZCpVJhz549mD59OqTSrjcvPT0ddXV1ltvp06e74yX0eWWtC++xp4aIiDyNlyMnBwcHQyaTtas60mg0CA8Pv+pjdTodcnJy8Oyzz7a7LyEhAUVFRairq4PBYEBISAiSk5ORmJgIAAgPD4fBYMClS5dsemuu9rwKhQIKhcKRl+fyTCbBUs7NhfeIiMjTONQVIpfLkZCQgPz8fMsxk8mE/Px8TJw48aqPzc3NhV6vx6JFizo8R61WIyQkBOXl5fjuu+9w5513AhBDj7e3t83zlpaWoqKi4prP60nOXGxEU7MJcpkUMYGsfCIiIs/iUE8NAKSlpWHJkiVITExEUlISsrKyoNPpsHTpUgDA4sWLMWDAAGRkZNg8Ljs7G7Nnz0ZQUFC7a+bm5iIkJATR0dE4evQoHn30UcyePRt33HEHADHsLFu2DGlpaQgMDERAQAAeeeQRTJw4ETfddFNXXrdbMq8kfEOIL7y45xMREXkYh0PNvHnzUFNTgw0bNqCqqgpjx45FXl6eZfJwRUVFu7kwpaWl2LdvH3bt2mX3mpWVlUhLS4NGo0FERAQWL16M9evX25zz2muvQSqVYs6cOdDr9UhNTcWbb77paPPdmnk+zTDOpyEiIg8kEQRBcHYjeoNWq4VarUZdXR0CAgKc3ZwesXpbET44fBZr7hiGVbcPdXZziIiIrpsj798co3Ajlo0s2VNDREQeiKHGTRjbVD5x+ImIiDwRQ42bOHOxAfoWE+ReUkSz8omIiDwQQ42bMG+PMDjEDzKpxMmtISIi6n0MNW7CPJ9mGBfdIyIiD8VQ4yYsez5xPg0REXkohho3YdmdmxtZEhGRh2KocQNGk4ATNax8IiIiz8ZQ4wYqLoiVTwovKaJY+URERB6KocYNmCcJDwll5RMREXkuhho3YF50j/NpiIjIkzHUuAFuj0BERMRQ4xbMlU+cJExERJ6MocbF2VY+cfiJiIg8F0ONi/v5vA6GFhOU3lJE9WflExEReS6GGhdnHnoaEuoHKSufiIjIgzHUuDjL9gihnE9DRESejaHGxZW3lnMP4XwaIiLycAw1Lq6MPTVEREQAGGpcWovRhJM1OgAs5yYiImKocWE/X2iAwWiCj7cMA/v7OLs5RERETsVQ48LK2+z5xMonIiLydAw1Lsxczj2Uk4SJiIgYalyZZZIw59MQEREx1Liycg23RyAiIjJjqHFRLUYTTta2Dj+xnJuIiIihxlWdOt+AZqMAH28ZBvRj5RMRERFDjYsyVz4NDWPlExEREcBQ47IslU8ceiIiIgLAUOOyyqrNlU+cJExERAQw1LiscpZzExER2WCocUHNRhN+qhX3fOLCe0RERKIuhZqNGzciNjYWSqUSycnJKCgo6PDcKVOmQCKRtLvNnDnTck59fT1WrVqFgQMHwsfHB6NGjcKmTZuueZ2HH364K813eT+f16HZKMBXzsonIiIiMy9HH7Bt2zakpaVh06ZNSE5ORlZWFlJTU1FaWorQ0NB252/fvh0Gg8Hy9fnz5xEfH4+5c+dajqWlpeHzzz/Hu+++i9jYWOzatQv/8z//g8jISPz617+2nLd8+XI8++yzlq9VKpWjzXcL5knCQ0L9IJGw8omIiAjoQk9NZmYmli9fjqVLl1p6VFQqFTZv3mz3/MDAQISHh1tuu3fvhkqlsgk133zzDZYsWYIpU6YgNjYWK1asQHx8fLseIJVKZXOtgIAAR5vvFsos5dycT0NERGTmUKgxGAwoLCxESkqK9QJSKVJSUrB///5OXSM7Oxvz58+Hr6+v5dikSZOwY8cOnD17FoIgYM+ePSgrK8Mdd9xh89gtW7YgODgYo0ePRnp6OhoaGjp8Hr1eD61Wa3NzF9wegYiIqD2Hhp9qa2thNBoRFhZmczwsLAzHjh275uMLCgpQXFyM7Oxsm+NvvPEGVqxYgYEDB8LLywtSqRTvvPMOJk+ebDlnwYIFiImJQWRkJI4cOYInnngCpaWl2L59u93nysjIwDPPPOPIy3MZ7KkhIiJqz+E5NdcjOzsbcXFxSEpKsjn+xhtv4MCBA9ixYwdiYmLw5ZdfYuXKlYiMjLT0Cq1YscJyflxcHCIiIjB16lScOHECgwcPbvdc6enpSEtLs3yt1WoRFRXVQ6+s9xharJVPLOcmIiKycijUBAcHQyaTQaPR2BzXaDQIDw+/6mN1Oh1ycnJsJvoCQGNjI5588kl88MEHloqoMWPGoKioCK+++qrNUFdbycnJAIDjx4/bDTUKhQIKhaLTr81VnDqvQ4tJgJ/CC5FqpbObQ0RE1Gc4NKdGLpcjISEB+fn5lmMmkwn5+fmYOHHiVR+bm5sLvV6PRYsW2Rxvbm5Gc3MzpFLbpshkMphMpg6vV1RUBACIiIhw5CW4PPPQEyufiIiIbDk8/JSWloYlS5YgMTERSUlJyMrKgk6nw9KlSwEAixcvxoABA5CRkWHzuOzsbMyePRtBQUE2xwMCAnDrrbfi8ccfh4+PD2JiYrB371784x//QGZmJgDgxIkT2Lp1K2bMmIGgoCAcOXIEq1evxuTJkzFmzJiuvnaXVG7Z84mThImIiNpyONTMmzcPNTU12LBhA6qqqjB27Fjk5eVZJg9XVFS063UpLS3Fvn37sGvXLrvXzMnJQXp6OhYuXIgLFy4gJiYGzz//vGVxPblcjs8++8wSoKKiojBnzhysW7fO0ea7vPJqbo9ARERkj0QQBMHZjegNWq0WarUadXV1Lr2+TUrmXhyvrsfflk7AlOHtFzskIiJyJ468f3PvJxdiaDHhFCufiIiI7GKocSE/1YqVT/4KL0Sw8omIiMgGQ40LsVQ+hbHyiYiI6EoMNS6kvDXUDAvl0BMREdGVGGpcSHl1azk393wiIiJqh6HGhXDPJyIioo4x1LgIfYsRp86Lu5Jzd24iIqL2GGpcxE+1OhhbK5/CA1j5REREdCWGGhdRprHOp2HlExERUXsMNS7CUvnE+TRERER2MdS4CE4SJiIiujqGGhdh3p2bk4SJiIjsY6hxAWLlE/d8IiIiuhqGGhdwskYHkwD4K70Q6q9wdnOIiIj6JIYaF1DWZpIwK5+IiIjsY6hxAZxPQ0REdG0MNS7AUvnEjSyJiIg6xFDjAswbWXKSMBERUccYavq4pmYjfrZUPnH4iYiIqCMMNX2cufJJ7eONEFY+ERERdYihpo8rrzbPp+GeT0RERFfDUNPHcXsEIiKizmGo6ePKWM5NRETUKQw1fRx35yYiIuochpo+rKnZiJ8vNAAAhrKnhoiI6KoYavqw49X1EASgn8obIX6sfCIiIroahpo+zFz5NCyUez4RERFdC0NNH2be84lDT0RERNfGUNOHmSufhoYy1BAREV0LQ00fZhl+YuUTERHRNTHU9FGNBiMqLJVPDDVERETX0qVQs3HjRsTGxkKpVCI5ORkFBQUdnjtlyhRIJJJ2t5kzZ1rOqa+vx6pVqzBw4ED4+Phg1KhR2LRpk811mpqasHLlSgQFBcHPzw9z5syBRqPpSvNdwokasfKpv8obwX5yZzeHiIioz3M41Gzbtg1paWl4+umncejQIcTHxyM1NRXV1dV2z9++fTsqKystt+LiYshkMsydO9dyTlpaGvLy8vDuu++ipKQEjz32GFatWoUdO3ZYzlm9ejU++ugj5ObmYu/evTh37hzuvvvuLrxk19B2ewRWPhEREV2bw6EmMzMTy5cvx9KlSy09KiqVCps3b7Z7fmBgIMLDwy233bt3Q6VS2YSab775BkuWLMGUKVMQGxuLFStWID4+3tIDVFdXh+zsbGRmZuL2229HQkIC/vrXv+Kbb77BgQMHuvjS+zZuj0BEROQYh0KNwWBAYWEhUlJSrBeQSpGSkoL9+/d36hrZ2dmYP38+fH19LccmTZqEHTt24OzZsxAEAXv27EFZWRnuuOMOAEBhYSGam5ttnnfEiBGIjo7u9PO6muOcJExEROQQL0dOrq2thdFoRFhYmM3xsLAwHDt27JqPLygoQHFxMbKzs22Ov/HGG1ixYgUGDhwILy8vSKVSvPPOO5g8eTIAoKqqCnK5HP369Wv3vFVVVXafS6/XQ6/XW77WarWdeYl9hrmnZgjLuYmIiDqlV6ufsrOzERcXh6SkJJvjb7zxBg4cOIAdO3agsLAQf/rTn7By5Up89tlnXX6ujIwMqNVqyy0qKup6m99rGg1GnL4oVj6xp4aIiKhzHAo1wcHBkMlk7aqONBoNwsPDr/pYnU6HnJwcLFu2zOZ4Y2MjnnzySWRmZmLWrFkYM2YMVq1ahXnz5uHVV18FAISHh8NgMODSpUudft709HTU1dVZbqdPn3bkpTqVec+nQF85grnnExERUac4FGrkcjkSEhKQn59vOWYymZCfn4+JEyde9bG5ubnQ6/VYtGiRzfHm5mY0NzdDKrVtikwmg8lkAgAkJCTA29vb5nlLS0tRUVHR4fMqFAoEBATY3FyFpfKJQ09ERESd5tCcGkAsv16yZAkSExORlJSErKws6HQ6LF26FACwePFiDBgwABkZGTaPy87OxuzZsxEUFGRzPCAgALfeeisef/xx+Pj4ICYmBnv37sU//vEPZGZmAgDUajWWLVuGtLQ0BAYGIiAgAI888ggmTpyIm266qauvvc8q4yRhIiIihzkcaubNm4eamhps2LABVVVVGDt2LPLy8iyThysqKtr1upSWlmLfvn3YtWuX3Wvm5OQgPT0dCxcuxIULFxATE4Pnn38eDz/8sOWc1157DVKpFHPmzIFer0dqairefPNNR5vvEspZzk1EROQwiSAIgrMb0Ru0Wi3UajXq6ur6/FDULS99jjMXG5Gz4ibcdEPQtR9ARETkphx5/+beT31Mg6EFZy42AuDwExERkSMYavqY49Xi0FOQrxyBvtzziYiIqLMYavoY86J7QzmfhoiIyCEMNX1MuYaVT0RERF3BUNPHtN2dm4iIiDqPoaaPsezOzYX3iIiIHMJQ04fo9C04e4mVT0RERF3BUNOHmCufgv0U6M/KJyIiIocw1PQhZZZJwhx6IiIichRDTR9S3tpTw40siYiIHMdQ04ew8omIiKjrGGr6EOtGlgw1REREjmKo6SPqbSqfOPxERETkKIaaPsK8knCIvwL9VKx8IiIichRDTR9hHXpiLw0REVFXMNT0EeXVrZOEQzmfhoiIqCsYavoI7s5NRER0fRhq+gjuzk1ERHR9GGr6gMtNzThX1wQAGMbhJyIioi5hqOkDzCsJh/oroFZ5O7k1REREromhpg/g0BMREdH1Y6jpAzhJmIiI6Pox1PQB5uEn9tQQERF1HUNNH2AdfmJPDRERUVcx1DiZtqkZla2VT0NY+URERNRlDDVOZt4eISxAAbUPK5+IiIi6iqHGyVj5RERE1D0YapzMUvnEoSciIqLrwlDjZOaNLDlJmIiI6Pow1DhZWevw01AOPxEREV0XhhonqmtshkarB8CF94iIiK4XQ40THW8degoPUCJAyconIiKi69GlULNx40bExsZCqVQiOTkZBQUFHZ47ZcoUSCSSdreZM2dazrF3v0QiwSuvvGI5JzY2tt39L774Ylea32dwewQiIqLu4+XoA7Zt24a0tDRs2rQJycnJyMrKQmpqKkpLSxEaGtru/O3bt8NgMFi+Pn/+POLj4zF37lzLscrKSpvHfPrpp1i2bBnmzJljc/zZZ5/F8uXLLV/7+7v2PJQylnMTERF1G4dDTWZmJpYvX46lS5cCADZt2oSdO3di8+bNWLt2bbvzAwMDbb7OycmBSqWyCTXh4eE253z44Ye47bbbcMMNN9gc9/f3b3euKzMvvMfKJyIiouvn0PCTwWBAYWEhUlJSrBeQSpGSkoL9+/d36hrZ2dmYP38+fH197d6v0Wiwc+dOLFu2rN19L774IoKCgjBu3Di88soraGlp6fB59Ho9tFqtza2vYeUTERFR93Gop6a2thZGoxFhYWE2x8PCwnDs2LFrPr6goADFxcXIzs7u8Jy///3v8Pf3x913321z/He/+x3Gjx+PwMBAfPPNN0hPT0dlZSUyMzPtXicjIwPPPPNMJ16Vc9Q1NKP6cmvlUyh7aoiIiK6Xw8NP1yM7OxtxcXFISkrq8JzNmzdj4cKFUCqVNsfT0tIsn48ZMwZyuRy/+c1vkJGRAYVC0e466enpNo/RarWIiorqhlfRPcyL7kWqlfBn5RMREdF1c2j4KTg4GDKZDBqNxua4RqO55lwXnU6HnJwcu8NKZl999RVKS0vx0EMPXbMtycnJaGlpwalTp+zer1AoEBAQYHPrS6yVTxx6IiIi6g4OhRq5XI6EhATk5+dbjplMJuTn52PixIlXfWxubi70ej0WLVrU4TnZ2dlISEhAfHz8NdtSVFQEqVRqt+LKFVjm03DoiYiIqFs4PPyUlpaGJUuWIDExEUlJScjKyoJOp7NUQy1evBgDBgxARkaGzeOys7Mxe/ZsBAUF2b2uVqtFbm4u/vSnP7W7b//+/fj2229x2223wd/fH/v378fq1auxaNEi9O/f39GX0CdY93xiTw0REVF3cDjUzJs3DzU1NdiwYQOqqqowduxY5OXlWSYPV1RUQCq17QAqLS3Fvn37sGvXrg6vm5OTA0EQcN9997W7T6FQICcnB3/4wx+g1+sxaNAgrF692mbOjKvhwntERETdSyIIguDsRvQGrVYLtVqNuro6p8+vudRgwNhndwMAip9JhZ+iV+drExERuQxH3r+595MTmHtpBvTzYaAhIiLqJgw1TmBddI9DT0RERN2FocYJjlebt0fgJGEiIqLuwlDjBCznJiIi6n4MNU7AhfeIiIi6H0NNL7uoM6C2nns+ERERdTeGml5mHnoa0M8Hvqx8IiIi6jYMNb2szDJJmL00RERE3YmhppeVa7g9AhERUU9gqOll5ZwkTERE1CMYanqZdSNLDj8RERF1J4aaXnRBZ0BtvQEAMDiEoYaIiKg7MdT0InPl08D+rHwiIiLqbgw1vYiThImIiHoOQ00vsq4kzKEnIiKi7sZQ04vMw0/DQtlTQ0RE1N0YanpROXfnJiIi6jEMNb3kfL0eF3QGSCTAEO75RERE1O0YanqJeT5NVH8VfOQyJ7eGiIjI/TDU9BLzonvcmZuIiKhnMNT0EvMkYW6PQERE1DMYanqJefiJ2yMQERH1DIaaXiAIAhfeIyIi6mEMNb2gtt6Aiw3NkEi45xMREVFPYajpBeZJwtGBrHwiIiLqKQw1vaDcvD0CVxImIiLqMQw1vcBa+cShJyIiop7CUNMLyln5RERE1OMYanqYIAgosyy8x+EnIiKinsJQ08Nq6vW41NAMKfd8IiIi6lEMNT3MPPQUHaiC0puVT0RERD2lS6Fm48aNiI2NhVKpRHJyMgoKCjo8d8qUKZBIJO1uM2fOtJxj736JRIJXXnnFcs6FCxewcOFCBAQEoF+/fli2bBnq6+u70vxexe0RiIiIeofDoWbbtm1IS0vD008/jUOHDiE+Ph6pqamorq62e/727dtRWVlpuRUXF0Mmk2Hu3LmWc9reX1lZic2bN0MikWDOnDmWcxYuXIgffvgBu3fvxscff4wvv/wSK1as6MJL7l3l1ZwkTERE1BskgiAIjjwgOTkZEyZMwF/+8hcAgMlkQlRUFB555BGsXbv2mo/PysrChg0bUFlZCV9fX7vnzJ49G5cvX0Z+fj4AoKSkBKNGjcLBgweRmJgIAMjLy8OMGTNw5swZREZGXvN5tVot1Go16urqEBAQ0NmXe93mbvoGB09dxJ/nj8WdYwf02vMSERG5A0fevx3qqTEYDCgsLERKSor1AlIpUlJSsH///k5dIzs7G/Pnz+8w0Gg0GuzcuRPLli2zHNu/fz/69etnCTQAkJKSAqlUim+//daRl9CrBEGwbGTJScJEREQ9y8uRk2tra2E0GhEWFmZzPCwsDMeOHbvm4wsKClBcXIzs7OwOz/n73/8Of39/3H333ZZjVVVVCA0NtW24lxcCAwNRVVVl9zp6vR56vd7ytVarvWb7ulvNZT3qGsXKJ+75RERE1LN6tfopOzsbcXFxSEpK6vCczZs3Y+HChVAqldf1XBkZGVCr1ZZbVFTUdV2vK8y9NDFBvqx8IiIi6mEOhZrg4GDIZDJoNBqb4xqNBuHh4Vd9rE6nQ05Ojs2w0pW++uorlJaW4qGHHrI5Hh4e3m4icktLCy5cuNDh86anp6Ours5yO3369FXb1xMslU8ceiIiIupxDoUauVyOhIQEywReQJwonJ+fj4kTJ171sbm5udDr9Vi0aFGH52RnZyMhIQHx8fE2xydOnIhLly6hsLDQcuzzzz+HyWRCcnKy3WspFAoEBATY3HqbeXfuYSznJiIi6nEODz+lpaXhnXfewd///neUlJTgt7/9LXQ6HZYuXQoAWLx4MdLT09s9Ljs7G7Nnz0ZQUJDd62q1WuTm5rbrpQGAkSNHYtq0aVi+fDkKCgrw9ddfY9WqVZg/f36nKp+cxbI7N8u5iYiIepxDE4UBYN68eaipqcGGDRtQVVWFsWPHIi8vzzJ5uKKiAlKpbVYqLS3Fvn37sGvXrg6vm5OTA0EQcN9999m9f8uWLVi1ahWmTp0KqVSKOXPm4PXXX3e0+b1GrHxiTw0REVFvcXidGlfV2+vUaLRNSH4hH1IJUPLcNCi8OFGYiMhdGY1GNDc3O7sZLsnb2xsyWcfvkY68fzvcU0OdY+6liQ3yZaAhInJTgiCgqqoKly5dcnZTXFq/fv0QHh4OiURyXddhqOkhZZxPQ0Tk9syBJjQ0FCqV6rrflD2NIAhoaGiwVDhHRERc1/UYanpIOefTEBG5NaPRaAk0HRXB0LX5+PgAAKqrqxEaGnrVoahr6dXF9zwJd+cmInJv5jk0KpXKyS1xfebv4fXOS2Ko6QGCIFjKubk7NxGRe+OQ0/Xrru8hQ00P0Gj1uKxvgUwqwaBg+xt3EhERUfdiqOkB1sonFSufiIjIrcXGxiIrK8vZzQDAicI9wrrnE+fTEBFR3zNlyhSMHTu2W8LIwYMH4evbN0YlGGp6AOfTEBGRKxMEAUajEV5e144JISEhvdCizuHwUw8oq2blExER9U0PPPAA9u7diz//+c+QSCSQSCT429/+BolEgk8//RQJCQlQKBTYt28fTpw4gTvvvBNhYWHw8/PDhAkT8Nlnn9lc78rhJ4lEgv/7v//DXXfdBZVKhaFDh2LHjh298toYarqZIAg4bumpYaghIvIUgiCgwdDilJsjOx79+c9/xsSJE7F8+XJUVlaisrISUVFRAIC1a9fixRdfRElJCcaMGYP6+nrMmDED+fn5OHz4MKZNm4ZZs2ahoqLiqs/xzDPP4N5778WRI0cwY8YMLFy4EBcuXLiu729ncPipm1XWNeGyvgVerHwiIvIojc1GjNrwX6c894/PpkIl79xbulqthlwuh0qlQnh4OADg2LFjAIBnn30Wv/zlLy3nBgYGIj4+3vL1c889hw8++AA7duzAqlWrOnyOBx54wLJB9QsvvIDXX38dBQUFmDZtmsOvzRHsqelm5dViL01ssC/kXvz2EhGR60hMTLT5ur6+HmvWrMHIkSPRr18/+Pn5oaSk5Jo9NWPGjLF87uvri4CAAMtWCD2JPTXdzLo9AicJExF5Eh9vGX58NtVpz90drqxiWrNmDXbv3o1XX30VQ4YMgY+PD+655x4YDIarXsfb29vma4lEApPJ1C1tvBqGmm7Gcm4iIs8kkUg6PQTkbHK5HEaj8Zrnff3113jggQdw1113ARB7bk6dOtXDres6jo90M+7OTUREfV1sbCy+/fZbnDp1CrW1tR32ogwdOhTbt29HUVERvv/+eyxYsKBXely6iqGmGwmCgOPVrHwiIqK+bc2aNZDJZBg1ahRCQkI6nCOTmZmJ/v37Y9KkSZg1axZSU1Mxfvz4Xm5t50kER+rAXJhWq4VarUZdXR0CAgJ65DnOXmrEzS9+Di+pBD8+O40ThYmI3FhTUxN++uknDBo0CEql0tnNcWlX+1468v7Nd91uZJ5PM4iVT0RERL2O77zdyFr5xKEnIiKi3sZQ043KOUmYiIjIaRhqulEZJwkTERE5DUNNNxH3fOLCe0RERM7CUNNNzl5qhM5ghLdMgpgg7vlERETU2xhquol5Ps2gYF94y/htJSIi6m189+0mlu0ROJ+GiIjIKRhquol5e4Rh3POJiIjIKRhqusnxak4SJiIizxAbG4usrCzL1xKJBP/5z386PP/UqVOQSCQoKirq0Xa5xnaifZzJJKC82rxGDXtqiIjIs1RWVqJ///7ObgZDTXc4e6kRDa2VT7FBKmc3h4iIqFeFh4c7uwkAOPzULcpbh55uCPaDFyufiIioD3v77bcRGRkJk8lkc/zOO+/Egw8+iBMnTuDOO+9EWFgY/Pz8MGHCBHz22WdXveaVw08FBQUYN24clEolEhMTcfjw4Z54Ke3wHbgblHF7BCIiEgTAoHPOTRA63cy5c+fi/Pnz2LNnj+XYhQsXkJeXh4ULF6K+vh4zZsxAfn4+Dh8+jGnTpmHWrFmoqKjo1PXr6+vxq1/9CqNGjUJhYSH+8Ic/YM2aNQ5/O7uiS8NPGzduxCuvvIKqqirEx8fjjTfeQFJSkt1zp0yZgr1797Y7PmPGDOzcudPydUlJCZ544gns3bsXLS0tGDVqFN5//31ER0d3eJ3f/OY32LRpU1deQrcq40aWRETU3AC8EOmc537yHCDv3MKv/fv3x/Tp07F161ZMnToVAPDvf/8bwcHBuO222yCVShEfH285/7nnnsMHH3yAHTt2YNWqVde8/tatW2EymZCdnQ2lUokbb7wRZ86cwW9/+9uuvTYHONxTs23bNqSlpeHpp5/GoUOHEB8fj9TUVFRXV9s9f/v27aisrLTciouLIZPJMHfuXMs5J06cwC233IIRI0bgiy++wJEjR7B+/XoolUqbay1fvtzmWi+//LKjze8R5oX3WPlERESuYOHChXj//feh1+sBAFu2bMH8+fMhlUpRX1+PNWvWYOTIkejXrx/8/PxQUlLS6Z6akpISjBkzxuY9fOLEiT3yOq7kcE9NZmYmli9fjqVLlwIANm3ahJ07d2Lz5s1Yu3Ztu/MDAwNtvs7JyYFKpbIJNU899RRmzJhhE1IGDx7c7loqlarPTEYyM5kEHGflExEReavEHhNnPbcDZs2aBUEQsHPnTkyYMAFfffUVXnvtNQDAmjVrsHv3brz66qsYMmQIfHx8cM8998BgMPREy7uVQz01BoMBhYWFSElJsV5AKkVKSgr279/fqWtkZ2dj/vz58PUVu8lMJhN27tyJYcOGITU1FaGhoUhOTrZb775lyxYEBwdj9OjRSE9PR0NDQ4fPo9frodVqbW494eylRjQ2GyGXSRETyMonIiKPJZGIQ0DOuEkkDjVVqVTi7rvvxpYtW/Dee+9h+PDhGD9+PADg66+/xgMPPIC77roLcXFxCA8Px6lTpzp97ZEjR+LIkSNoamqyHDtw4IBD7esqh0JNbW0tjEYjwsLCbI6HhYWhqqrqmo8vKChAcXExHnroIcux6upq1NfX48UXX8S0adOwa9cu3HXXXbj77rtt5tAsWLAA7777Lvbs2YP09HT885//xKJFizp8royMDKjVasstKirKkZfaaeb5NDeE+LLyiYiIXMbChQstIy0LFy60HB86dCi2b9+OoqIifP/991iwYEG7SqmrWbBgASQSCZYvX44ff/wRn3zyCV599dWeeAnt9Oo6NdnZ2YiLi7OZVGz+Rt15551YvXo1AGDs2LH45ptvsGnTJtx6660AgBUrVlgeExcXh4iICEydOhUnTpywO1SVnp6OtLQ0y9darbZHgk1ssC/SfjkMAUou+UNERK7j9ttvR2BgIEpLS7FgwQLL8czMTDz44IOYNGkSgoOD8cQTTzg02uHn54ePPvoIDz/8MMaNG4dRo0bhpZdewpw5c3riZdhw6J04ODgYMpkMGo3G5rhGo7nmXBedToecnBw8++yz7a7p5eWFUaNG2RwfOXIk9u3b1+H1kpOTAQDHjx+3G2oUCgUUCsVV29QdBof44XdTh/b48xAREXUnqVSKc+fazwGKjY3F559/bnNs5cqVNl9fORwlXFFSftNNN7XbEuHKc3qCQ+MlcrkcCQkJyM/PtxwzmUzIz8+/5szm3Nxc6PX6dkNGcrkcEyZMQGlpqc3xsrIyxMTEdHg98zcrIiLCkZdAREREbsrhMZO0tDQsWbIEiYmJSEpKQlZWFnQ6naUaavHixRgwYAAyMjJsHpednY3Zs2cjKCio3TUff/xxzJs3D5MnT8Ztt92GvLw8fPTRR/jiiy8AiCXfW7duxYwZMxAUFIQjR45g9erVmDx5MsaMGdOFl01ERETuxuFQM2/ePNTU1GDDhg2oqqrC2LFjkZeXZ5k8XFFRAanUtgOotLQU+/btw65du+xe86677sKmTZuQkZGB3/3udxg+fDjef/993HLLLQDE3pzPPvvMEqCioqIwZ84crFu3ztHmExERkZuSCL0xyNUHaLVaqNVq1NXVISAgwNnNISIiF9fU1ISffvoJgwYNardYLDnmat9LR96/WYNMREREboGhhoiI6Do4soYL2ddd30MurkJERNQFcrncUhYdEhICuVwOiYMr+3o6QRBgMBhQU1MDqVQKuVx+XddjqCEiIuoCqVSKQYMGobKy0u56L9R5KpUK0dHR7QqNHMVQQ0RE1EVyuRzR0dFoaWmB0Wh0dnNckkwmg5eXV7f0cjHUEBERXQeJRAJvb294e3s7uykejxOFiYiIyC0w1BAREZFbYKghIiIit+Axc2rMCyc7sn06EREROZf5fbszGyB4TKi5fPkyACAqKsrJLSEiIiJHXb58GWq1+qrneMzeTyaTCefOnYO/vz8XR+qAVqtFVFQUTp8+zf2x+gD+PPoW/jz6Fv48+p6e+pkIgoDLly8jMjLymuvYeExPjVQqxcCBA53dDJcQEBDAXxJ9CH8efQt/Hn0Lfx59T0/8TK7VQ2PGicJERETkFhhqiIiIyC0w1JCFQqHA008/DYVC4eymEPjz6Gv48+hb+PPoe/rCz8RjJgoTERGRe2NPDREREbkFhhoiIiJyCww1RERE5BYYaoiIiMgtMNR4uIyMDEyYMAH+/v4IDQ3F7NmzUVpa6uxmUasXX3wREokEjz32mLOb4tHOnj2LRYsWISgoCD4+PoiLi8N3333n7GZ5JKPRiPXr12PQoEHw8fHB4MGD8dxzz3VqXyC6fl9++SVmzZqFyMhISCQS/Oc//7G5XxAEbNiwAREREfDx8UFKSgrKy8t7rX0MNR5u7969WLlyJQ4cOIDdu3ejubkZd9xxB3Q6nbOb5vEOHjyI//3f/8WYMWOc3RSPdvHiRdx8883w9vbGp59+ih9//BF/+tOf0L9/f2c3zSO99NJLeOutt/CXv/wFJSUleOmll/Dyyy/jjTfecHbTPIJOp0N8fDw2btxo9/6XX34Zr7/+OjZt2oRvv/0Wvr6+SE1NRVNTU6+0jyXdZKOmpgahoaHYu3cvJk+e7OzmeKz6+nqMHz8eb775Jv74xz9i7NixyMrKcnazPNLatWvx9ddf46uvvnJ2UwjAr371K4SFhSE7O9tybM6cOfDx8cG7777rxJZ5HolEgg8++ACzZ88GIPbSREZG4ve//z3WrFkDAKirq0NYWBj+9re/Yf78+T3eJvbUkI26ujoAQGBgoJNb4tlWrlyJmTNnIiUlxdlN8Xg7duxAYmIi5s6di9DQUIwbNw7vvPOOs5vlsSZNmoT8/HyUlZUBAL7//nvs27cP06dPd3LL6KeffkJVVZXN7y21Wo3k5GTs37+/V9rgMRta0rWZTCY89thjuPnmmzF69GhnN8dj5eTk4NChQzh48KCzm0IATp48ibfeegtpaWl48skncfDgQfzud7+DXC7HkiVLnN08j7N27VpotVqMGDECMpkMRqMRzz//PBYuXOjspnm8qqoqAEBYWJjN8bCwMMt9PY2hhixWrlyJ4uJi7Nu3z9lN8VinT5/Go48+it27d0OpVDq7OQQx7CcmJuKFF14AAIwbNw7FxcXYtGkTQ40T/Otf/8KWLVuwdetW3HjjjSgqKsJjjz2GyMhI/jyIw08kWrVqFT7++GPs2bMHAwcOdHZzPFZhYSGqq6sxfvx4eHl5wcvLC3v37sXrr78OLy8vGI1GZzfR40RERGDUqFE2x0aOHImKigontcizPf7441i7di3mz5+PuLg43H///Vi9ejUyMjKc3TSPFx4eDgDQaDQ2xzUajeW+nsZQ4+EEQcCqVavwwQcf4PPPP8egQYOc3SSPNnXqVBw9ehRFRUWWW2JiIhYuXIiioiLIZDJnN9Hj3Hzzze2WOSgrK0NMTIyTWuTZGhoaIJXavnXJZDKYTCYntYjMBg0ahPDwcOTn51uOabVafPvtt5g4cWKvtIHDTx5u5cqV2Lp1Kz788EP4+/tbxj3VajV8fHyc3DrP4+/v324+k6+vL4KCgjjPyUlWr16NSZMm4YUXXsC9996LgoICvP3223j77bed3TSPNGvWLDz//POIjo7GjTfeiMOHDyMzMxMPPvigs5vmEerr63H8+HHL1z/99BOKiooQGBiI6OhoPPbYY/jjH/+IoUOHYtCgQVi/fj0iIyMtFVI9TiCPBsDu7a9//auzm0atbr31VuHRRx91djM82kcffSSMHj1aUCgUwogRI4S3337b2U3yWFqtVnj00UeF6OhoQalUCjfccIPw1FNPCXq93tlN8wh79uyx+56xZMkSQRAEwWQyCevXrxfCwsIEhUIhTJ06VSgtLe219nGdGiIiInILnFNDREREboGhhoiIiNwCQw0RERG5BYYaIiIicgsMNUREROQWGGqIiIjILTDUEBERkVtgqCEiIiK3wFBDREREboGhhoiIiNwCQw0RERG5BYYaIiIicgv/H8O2bq3Vy3LxAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "graficar_accuracy(history4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Aumentar cantidad de celdas LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder_3(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_matrix):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size1 = 128\n",
        "        self.lstm_size2 = 64\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_matrix.shape[1]\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embedding.weight.requires_grad = False  # marcar como layer no entrenable (freeze)\n",
        "        # Primer LSTM\n",
        "        self.lstm1 = nn.LSTM(input_size=self.embedding_dim,\n",
        "                             hidden_size=self.lstm_size1,\n",
        "                             batch_first=True,\n",
        "                             num_layers=self.num_layers)\n",
        "\n",
        "        # Segundo LSTM, recibe como input la salida del primero\n",
        "        self.lstm2 = nn.LSTM(input_size=self.lstm_size1,\n",
        "                             hidden_size=self.lstm_size2,\n",
        "                             batch_first=True,\n",
        "                             num_layers=self.num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        lstm_out1, (h1, c1) = self.lstm1(out)  # [batch_size, seq_len, lstm_size1]\n",
        "        lstm_out2, (h2, c2) = self.lstm2(lstm_out1)  # [batch_size, seq_len, lstm_size2]\n",
        "\n",
        "        # Retornar hidden y cell del último LSTM\n",
        "        return h2, c2\n",
        "\n",
        "class Decoder_3(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim, embedding_matrix=None):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size1 = 128\n",
        "        self.lstm_size2 = 64\n",
        "        self.num_layers = 1 \n",
        "        self.embedding_dim = embedding_matrix.shape[1] if embedding_matrix is not None else 50\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "\n",
        "        # Para utilizar versión con embedding preentrenados\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = False  # \n",
        "\n",
        "        # Primer LSTM\n",
        "        self.lstm1 = nn.LSTM(input_size=self.embedding_dim,\n",
        "                             hidden_size=self.lstm_size1,\n",
        "                             batch_first=True,\n",
        "                             num_layers=self.num_layers)\n",
        "\n",
        "        # Segundo LSTM, recibe como input la salida del primero\n",
        "        self.lstm2 = nn.LSTM(input_size=self.lstm_size1,\n",
        "                             hidden_size=self.lstm_size2,\n",
        "                             batch_first=True,\n",
        "                             num_layers=self.num_layers)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=self.lstm_size2, out_features=self.output_dim) # Fully connected layer\n",
        "\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        out = self.embedding(x)\n",
        "        # Primera LSTM SIN estado inicial (128)\n",
        "        lstm_out1, _ = self.lstm1(out)\n",
        "        # Segunda LSTM CON el estado del encoder (64)\n",
        "        lstm_out2, (ht2, ct2) = self.lstm2(lstm_out1, prev_state)\n",
        "        out = self.fc1(lstm_out2[:,-1,:])\n",
        "        return out, (ht2, ct2)\n",
        "\n",
        "class Seq2Seq_3(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        \n",
        "        assert encoder.lstm_size2 == decoder.lstm_size2, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.num_layers == decoder.num_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, encoder_input, decoder_input):\n",
        "        batch_size = decoder_input.shape[0]\n",
        "        decoder_input_len = decoder_input.shape[1]\n",
        "        vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        # tensor para almacenar la salida\n",
        "        # (batch_size, sentence_len, one_hot_size)\n",
        "        outputs = torch.zeros(batch_size, decoder_input_len, vocab_size)\n",
        "        \n",
        "        # ultimo hidden state del encoder, primer estado oculto del decoder\n",
        "        prev_state = self.encoder(encoder_input)\n",
        "      \n",
        "        # En la primera iteracion se toma el primer token de target (<sos>)\n",
        "        input = decoder_input[:, 0:1]\n",
        "\n",
        "        for t in range(decoder_input_len):\n",
        "            # t --> token index\n",
        "\n",
        "            # utilizamos método \"teacher forcing\", es decir que durante\n",
        "            # el entrenamiento no realimentamos la salida del decoder\n",
        "            # sino el token correcto que sigue en target\n",
        "            input = decoder_input[:, t:t+1]\n",
        "\n",
        "            # ingresar cada token embedding, uno por uno junto al hidden state\n",
        "            # recibir el output del decoder (softmax)\n",
        "            output, prev_state = self.decoder(input, prev_state)\n",
        "            top1 = output.argmax(1).view(-1, 1)\n",
        "\n",
        "            # Sino se usará \"teacher forcing\" habría que descomentar\n",
        "            # esta linea.\n",
        "            # Hay ejemplos dandos vuelta en donde se utilza un random \n",
        "            # para ver en cada vuelta que técnica se aplica\n",
        "            #input = top1            \n",
        "\n",
        "            # guardar cada salida (softmax)\n",
        "            outputs[:, t, :] = output\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint completo encontrado en: Modelos_entrenados/Aumentar_capas_LSTM\n",
            "No se encontró embedding_matrix_decoder.npy — se entrenará embedding en el Decoder.\n",
            "Checkpoint cargado desde: Modelos_entrenados/Aumentar_capas_LSTM\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder_3(vocab_size=nb_words, embedding_matrix=embedding_matrix)\n",
        "if cuda: encoder.cuda()\n",
        "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
        "decoder = Decoder_3(vocab_size=num_words_output, output_dim=num_words_output)\n",
        "if cuda: decoder.cuda()\n",
        "\n",
        "model = Seq2Seq_3(encoder, decoder)\n",
        "if cuda: model.cuda()\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
        "\n",
        "# Verificar que si el modelo ya existe para cargarlo. Sino entrenar\n",
        "carpeta = \"Modelos_entrenados/Aumentar_capas_LSTM\"\n",
        "\n",
        "modelo_entrenado = check_checkpoint_exists(carpeta)\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "if not modelo_entrenado:\n",
        "    history5 = train(model,\n",
        "                    train_loader,\n",
        "                    valid_loader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    epochs=n_epochs\n",
        "                    )\n",
        "    config = {\n",
        "        # Información general\n",
        "        \"max_input_len\": max_input_len,\n",
        "        \"max_out_len\": max_out_len,\n",
        "        \"max_vocab_size\": MAX_VOCAB_SIZE,\n",
        "        \"cuda\": cuda,\n",
        "\n",
        "        # Hiperparámetros de embedding y red\n",
        "        \"embedding_dim\": embedding_matrix.shape[1],\n",
        "        \"hidden_size\": 128,        \n",
        "        \"hidden_size_lstm2\": 64,\n",
        "        \"num_layers\": 1,          \n",
        "        \"lr\": 0.1,\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": n_epochs,\n",
        "\n",
        "        # Vocabularios (usar tamaños reales)\n",
        "        \"num_words_input\": int(embedding_matrix.shape[0]),\n",
        "        \"num_words_output\": int(num_words_output),\n",
        "\n",
        "        # Checkpoint info (opcional)\n",
        "        \"embedding_source\": getattr(model_embeddings, \"name\", \"custom\"),\n",
        "    }\n",
        "    save_checkpoint(carpeta, model, optimizer, history5, config,\n",
        "                    input_tokenizer, output_tokenizer,\n",
        "                    word2idx_inputs, word2idx_outputs, embedding_matrix)\n",
        "else:\n",
        "    data = load_checkpoint(carpeta, Encoder_3, Decoder_3, Seq2Seq_3, device=\"cuda\" if cuda else \"cpu\")\n",
        "    model = data[\"model\"]\n",
        "    optimizer = data[\"optimizer\"]\n",
        "    history5 = data[\"history\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "graficar_accuracy(history5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. LSTM bidireccional Encoder\n",
        "Ahora se modifica la LSTM por una bidireccional. Esto se hace solamente en el Encoder, ya que el Decoder no puede utilizar información futura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder_bidireccional(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_matrix, dropout_rate=0.2):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 128\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_matrix.shape[1]\n",
        "        self.dropout_rate = dropout_rate\n",
        "        \n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embedding.weight.requires_grad = False  # marcar como layer no entrenable (freeze)\n",
        "        \n",
        "        # Dropout después del embedding\n",
        "        self.dropout_embedding = nn.Dropout(self.dropout_rate)\n",
        "        \n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers,\n",
        "            bidirectional=True,\n",
        "            dropout=self.dropout_rate \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.dropout_embedding(out)  # Dropout después del embedding\n",
        "        lstm_output, (ht, ct) = self.lstm(out)\n",
        "        \n",
        "        # CAMBIO CLAVE: Usar solo el estado forward para evitar problemas de dimensiones\n",
        "        # Esto mantiene la ventaja bidireccional del encoder pero evita incompatibilidades\n",
        "        ht_forward = ht[0].unsqueeze(0)  # Solo forward, shape (1, batch, 128)\n",
        "        ct_forward = ct[0].unsqueeze(0)  # Solo forward, shape (1, batch, 128)\n",
        "        \n",
        "        return (ht_forward, ct_forward)\n",
        "\n",
        "class Decoder_bidreccional(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim, embedding_matrix=None, dropout_rate=0.2):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 128  # Mismo tamaño que el encoder (no bidireccional)\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_matrix.shape[1] if embedding_matrix is not None else 50\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "\n",
        "        # Para utilizar versión con embedding preentrenados\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = False  # \n",
        "\n",
        "        # Dropout después del embedding\n",
        "        self.dropout_embedding = nn.Dropout(self.dropout_rate)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,  # 128 - compatible con encoder\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=self.dropout_rate \n",
        "        )\n",
        "        \n",
        "        # Dropout antes de la capa final\n",
        "        self.dropout_output = nn.Dropout(self.dropout_rate)\n",
        "        self.fc1 = nn.Linear(self.lstm_size, self.output_dim)\n",
        "        # SIN SOFTMAX - usar solo logits para evitar problemas de gradientes\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        out = self.embedding(x)\n",
        "        out = self.dropout_embedding(out)  # Dropout después del embedding\n",
        "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
        "        out = self.dropout_output(lstm_output[:,-1,:])  # Dropout antes de la capa final\n",
        "        out = self.fc1(out)  # Solo logits, sin softmax\n",
        "        return out, (ht, ct)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Modelo bidireccional creado con dropout_rate = 0.2\n",
            "✓ Learning rate = 0.01\n",
            "✓ Dispositivo: CUDA\n",
            "Checkpoint completo encontrado en: Modelos_entrenados/LSTM_bidireccional\n",
            "\n",
            "Cargando modelo existente desde Modelos_entrenados/LSTM_bidireccional\n",
            "No se encontró embedding_matrix_decoder.npy — se entrenará embedding en el Decoder.\n",
            "Checkpoint cargado desde: Modelos_entrenados/LSTM_bidireccional\n",
            "Modelo cargado exitosamente\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/agustin/Desktop/CEIA UBA/Procesamiento Lenguaje Natural I/CEIA-ProcesamientoLenguajeNaturalI/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Crear el modelo bidireccional con dropout\n",
        "dropout_rate = 0.2  # 20% de dropout por defecto\n",
        "\n",
        "encoder_bidireccional = Encoder_bidireccional(vocab_size=nb_words, \n",
        "                                            embedding_matrix=embedding_matrix, \n",
        "                                            dropout_rate=dropout_rate)\n",
        "if cuda: encoder_bidireccional.to(device)\n",
        "\n",
        "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
        "decoder_bidreccional = Decoder_bidreccional(vocab_size=num_words_output, \n",
        "                                          output_dim=num_words_output,\n",
        "                                          dropout_rate=dropout_rate)\n",
        "if cuda: decoder_bidreccional.to(device)\n",
        "\n",
        "model = Seq2Seq(encoder_bidireccional, decoder_bidreccional)\n",
        "if cuda: model.to(device)\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Learning rate más conservador\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
        "\n",
        "print(f\"✓ Modelo bidireccional creado con dropout_rate = {dropout_rate}\")\n",
        "print(f\"✓ Learning rate = 0.01\")\n",
        "print(f\"✓ Dispositivo: {'CUDA' if cuda else 'CPU'}\")\n",
        "\n",
        "# Verificar que si el modelo ya existe para cargarlo. Sino entrenar\n",
        "carpeta = \"Modelos_entrenados/LSTM_bidireccional\"\n",
        "\n",
        "modelo_entrenado = check_checkpoint_exists(carpeta)\n",
        "\n",
        "n_epochs = 20\n",
        "\n",
        "if not modelo_entrenado:\n",
        "    print(f\"\\nIniciando entrenamiento por {n_epochs} épocas...\")\n",
        "    history6 = train(model,\n",
        "                    train_loader,\n",
        "                    valid_loader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    epochs=n_epochs\n",
        "                    )\n",
        "    config = {\n",
        "        # Información general\n",
        "        \"max_input_len\": max_input_len,\n",
        "        \"max_out_len\": max_out_len,\n",
        "        \"max_vocab_size\": MAX_VOCAB_SIZE,\n",
        "        \"cuda\": cuda,\n",
        "\n",
        "        # Hiperparámetros de embedding y red\n",
        "        \"embedding_dim\": embedding_matrix.shape[1],\n",
        "        \"hidden_size\": 128,      \n",
        "        \"num_layers\": 1,           \n",
        "        \"lr\": 0.01,  # Learning rate más conservador\n",
        "        \"dropout_rate\": dropout_rate,  # Nuevo parámetro\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": n_epochs,\n",
        "\n",
        "        # Vocabularios (usar tamaños reales)\n",
        "        \"num_words_input\": int(embedding_matrix.shape[0]),\n",
        "        \"num_words_output\": int(num_words_output),\n",
        "\n",
        "        # Checkpoint info (opcional)\n",
        "        \"embedding_source\": getattr(model_embeddings, \"name\", \"custom\"),\n",
        "    }\n",
        "    save_checkpoint(carpeta, model, optimizer, history6, config,\n",
        "                    input_tokenizer, output_tokenizer,\n",
        "                    word2idx_inputs, word2idx_outputs, embedding_matrix)\n",
        "    print(\"Modelo entrenado y guardado exitosamente\")\n",
        "else:\n",
        "    print(f\"\\nCargando modelo existente desde {carpeta}\")\n",
        "    data = load_checkpoint(carpeta, Encoder_bidireccional, Decoder_bidreccional, Seq2Seq, device=\"cuda\" if cuda else \"cpu\")\n",
        "    model = data[\"model\"]\n",
        "    optimizer = data[\"optimizer\"]\n",
        "    history6 = data[\"history\"]\n",
        "    print(\"Modelo cargado exitosamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "graficar_accuracy(history6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Embedding de encoder entrenable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder_bidireccional_2(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_matrix, dropout_rate=0.2):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 128\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_matrix.shape[1]\n",
        "        self.dropout_rate = dropout_rate\n",
        "        \n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        \n",
        "        # Dropout después del embedding\n",
        "        self.dropout_embedding = nn.Dropout(self.dropout_rate)\n",
        "        \n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers,\n",
        "            bidirectional=True,\n",
        "            dropout=self.dropout_rate \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.dropout_embedding(out)  # Dropout después del embedding\n",
        "        lstm_output, (ht, ct) = self.lstm(out)\n",
        "        \n",
        "        # CAMBIO CLAVE: Usar solo el estado forward para evitar problemas de dimensiones\n",
        "        # Esto mantiene la ventaja bidireccional del encoder pero evita incompatibilidades\n",
        "        ht_forward = ht[0].unsqueeze(0)  # Solo forward, shape (1, batch, 128)\n",
        "        ct_forward = ct[0].unsqueeze(0)  # Solo forward, shape (1, batch, 128)\n",
        "        \n",
        "        return (ht_forward, ct_forward)\n",
        "\n",
        "class Decoder_bidreccional_2(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim, embedding_matrix=None, dropout_rate=0.2):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 128  # Mismo tamaño que el encoder (no bidireccional)\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_matrix.shape[1] if embedding_matrix is not None else 50\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "\n",
        "        # Para utilizar versión con embedding preentrenados\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = False  # \n",
        "\n",
        "        # Dropout después del embedding\n",
        "        self.dropout_embedding = nn.Dropout(self.dropout_rate)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,  # 128 - compatible con encoder\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=self.dropout_rate \n",
        "        )\n",
        "        \n",
        "        # Dropout antes de la capa final\n",
        "        self.dropout_output = nn.Dropout(self.dropout_rate)\n",
        "        self.fc1 = nn.Linear(self.lstm_size, self.output_dim)\n",
        "        # SIN SOFTMAX - usar solo logits para evitar problemas de gradientes\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        out = self.embedding(x)\n",
        "        out = self.dropout_embedding(out)  # Dropout después del embedding\n",
        "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
        "        out = self.dropout_output(lstm_output[:,-1,:])  # Dropout antes de la capa final\n",
        "        out = self.fc1(out)  # Solo logits, sin softmax\n",
        "        return out, (ht, ct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/agustin/Desktop/CEIA UBA/Procesamiento Lenguaje Natural I/CEIA-ProcesamientoLenguajeNaturalI/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Modelo bidireccional creado con dropout_rate = 0.2\n",
            "✓ Learning rate = 0.01\n",
            "✓ Dispositivo: CUDA\n",
            "Checkpoint completo encontrado en: Modelos_entrenados/Embedding_encoder_entrenable\n",
            "\n",
            "Cargando modelo existente desde Modelos_entrenados/Embedding_encoder_entrenable\n",
            "No se encontró embedding_matrix_decoder.npy — se entrenará embedding en el Decoder.\n",
            "Checkpoint cargado desde: Modelos_entrenados/Embedding_encoder_entrenable\n",
            "Modelo cargado exitosamente\n"
          ]
        }
      ],
      "source": [
        "# Crear el modelo bidireccional con dropout\n",
        "dropout_rate = 0.2  # 20% de dropout por defecto\n",
        "\n",
        "encoder_bidireccional = Encoder_bidireccional_2(vocab_size=nb_words, \n",
        "                                            embedding_matrix=embedding_matrix, \n",
        "                                            dropout_rate=dropout_rate)\n",
        "if cuda: encoder_bidireccional.to(device)\n",
        "\n",
        "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
        "decoder_bidreccional = Decoder_bidreccional_2(vocab_size=num_words_output, \n",
        "                                          output_dim=num_words_output,\n",
        "                                          dropout_rate=dropout_rate)\n",
        "if cuda: decoder_bidreccional.to(device)\n",
        "\n",
        "model = Seq2Seq(encoder_bidireccional, decoder_bidreccional)\n",
        "if cuda: model.to(device)\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Learning rate más conservador\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
        "\n",
        "print(f\"✓ Modelo bidireccional creado con dropout_rate = {dropout_rate}\")\n",
        "print(f\"✓ Learning rate = 0.01\")\n",
        "print(f\"✓ Dispositivo: {'CUDA' if cuda else 'CPU'}\")\n",
        "\n",
        "# Verificar que si el modelo ya existe para cargarlo. Sino entrenar\n",
        "carpeta = \"Modelos_entrenados/Embedding_encoder_entrenable\"\n",
        "\n",
        "modelo_entrenado = check_checkpoint_exists(carpeta)\n",
        "\n",
        "n_epochs = 20\n",
        "\n",
        "if not modelo_entrenado:\n",
        "    print(f\"\\nIniciando entrenamiento por {n_epochs} épocas...\")\n",
        "    history7 = train(model,\n",
        "                    train_loader,\n",
        "                    valid_loader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    epochs=n_epochs\n",
        "                    )\n",
        "    config = {\n",
        "        # Información general\n",
        "        \"max_input_len\": max_input_len,\n",
        "        \"max_out_len\": max_out_len,\n",
        "        \"max_vocab_size\": MAX_VOCAB_SIZE,\n",
        "        \"cuda\": cuda,\n",
        "\n",
        "        # Hiperparámetros de embedding y red\n",
        "        \"embedding_dim\": embedding_matrix.shape[1],\n",
        "        \"hidden_size\": 128,      \n",
        "        \"num_layers\": 1,           \n",
        "        \"lr\": 0.01,  # Learning rate más conservador\n",
        "        \"dropout_rate\": dropout_rate,  # Nuevo parámetro\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": n_epochs,\n",
        "\n",
        "        # Vocabularios (usar tamaños reales)\n",
        "        \"num_words_input\": int(embedding_matrix.shape[0]),\n",
        "        \"num_words_output\": int(num_words_output),\n",
        "\n",
        "        # Checkpoint info (opcional)\n",
        "        \"embedding_source\": getattr(model_embeddings, \"name\", \"custom\"),\n",
        "    }\n",
        "    save_checkpoint(carpeta, model, optimizer, history7, config,\n",
        "                    input_tokenizer, output_tokenizer,\n",
        "                    word2idx_inputs, word2idx_outputs, embedding_matrix)\n",
        "    print(\"Modelo entrenado y guardado exitosamente\")\n",
        "else:\n",
        "    print(f\"\\nCargando modelo existente desde {carpeta}\")\n",
        "    data = load_checkpoint(carpeta, Encoder_bidireccional, Decoder_bidreccional, Seq2Seq, device=\"cuda\" if cuda else \"cpu\")\n",
        "    model = data[\"model\"]\n",
        "    optimizer = data[\"optimizer\"]\n",
        "    history7 = data[\"history\"]\n",
        "    print(\"Modelo cargado exitosamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================\n",
        "# Encoder BiLSTM con ATTENTION\n",
        "# ============================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder_bidireccional_attn(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_matrix, hidden_size=128, num_layers=1, dropout_rate=0.2):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.emb_dim = embedding_matrix.shape[1]\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        # si querés congelar el embedding del encoder:\n",
        "        # self.embedding.weight.requires_grad = False\n",
        "\n",
        "        self.dropout_emb = nn.Dropout(dropout_rate)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.emb_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout_rate if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [B, L_src]\n",
        "        return:\n",
        "          enc_out: [B, L_src, 2H]\n",
        "          init_state: (h0, c0) con sólo la dir. forward para casar H\n",
        "        \"\"\"\n",
        "        e = self.dropout_emb(self.embedding(x))\n",
        "        enc_out, (ht, ct) = self.lstm(e)          # enc_out: [B,L,2H]\n",
        "        # usar sólo forward (índice 0) para H=hidden_size\n",
        "        h0 = ht[0].unsqueeze(0)                   # [1,B,H]\n",
        "        c0 = ct[0].unsqueeze(0)                   # [1,B,H]\n",
        "        return enc_out, (h0, c0)\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# Decoder con ATTENTION (Luong \"dot\")\n",
        "# - Proyecta enc_out (2H) -> H\n",
        "# - scores_{t,i} = dec_t · (W_enc * enc_out_i)\n",
        "# - Mask de padding en fuente\n",
        "# ====================================\n",
        "class Decoder_bidreccional_attn(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim, embedding_matrix=None,\n",
        "                 hidden_size=128, num_layers=1, dropout_rate=0.2, enc_out_dim=256):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.emb_dim = embedding_matrix.shape[1] if embedding_matrix is not None else 50\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            # si querés congelar el embedding del decoder:\n",
        "            # self.embedding.weight.requires_grad = False\n",
        "\n",
        "        self.dropout_emb = nn.Dropout(dropout_rate)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.emb_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout_rate if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        # Proyección de estados del encoder (2H -> H) para \"dot\"\n",
        "        self.enc_proj = nn.Linear(enc_out_dim, hidden_size, bias=False)\n",
        "        self.dropout_out = nn.Dropout(dropout_rate)\n",
        "        # Combinar [dec_t, context_t] -> vocab\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, output_dim)\n",
        "\n",
        "    def forward(self, x, prev_state, enc_out, src_pad_mask=None):\n",
        "        \"\"\"\n",
        "        x: [B, T_dec]\n",
        "        prev_state: (h0,c0) [1,B,H]\n",
        "        enc_out: [B, L_src, 2H]\n",
        "        src_pad_mask: [B, L_src], True en PAD\n",
        "        \"\"\"\n",
        "        B, L_src, _ = enc_out.size()\n",
        "\n",
        "        # 1) Decoder \"puro\"\n",
        "        emb = self.dropout_emb(self.embedding(x))               # [B,T,E]\n",
        "        dec_seq, (ht, ct) = self.lstm(emb, prev_state)          # [B,T,H]\n",
        "\n",
        "        # 2) Proyección encoder para dot\n",
        "        enc_proj = self.enc_proj(enc_out)                       # [B,L_src,H]\n",
        "\n",
        "        # 3) Scores y máscara de padding fuente\n",
        "        # scores_{t,i} = dec_t · enc_proj_i\n",
        "        scores = torch.bmm(dec_seq, enc_proj.transpose(1, 2))   # [B,T,L_src]\n",
        "        if src_pad_mask is not None:\n",
        "            # src_pad_mask True en PAD -> -inf para que no atienda ahí\n",
        "            scores = scores.masked_fill(src_pad_mask.unsqueeze(1), float('-inf'))\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)                    # [B,T,L_src]\n",
        "\n",
        "        # 4) Contexto\n",
        "        context = torch.bmm(attn, enc_proj)                     # [B,T,H]\n",
        "\n",
        "        # 5) Fusionar y proyectar a vocab\n",
        "        fused = torch.cat([dec_seq, context], dim=-1)           # [B,T,2H]\n",
        "        logits = self.fc1(self.dropout_out(fused))              # [B,T,V]\n",
        "        return logits, (ht, ct), attn\n",
        "\n",
        "\n",
        "# ======================\n",
        "# Wrapper Seq2Seq + Attn\n",
        "# ======================\n",
        "class Seq2SeqAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder_attn, pad_idx=0):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder_attn\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def forward(self, enc_in, dec_in):\n",
        "        \"\"\"\n",
        "        enc_in: [B,L_src] (con PAD=0)\n",
        "        dec_in: [B,T_dec] (teacher forcing)\n",
        "        \"\"\"\n",
        "        # 1) Encode\n",
        "        enc_out, init_state = self.encoder(enc_in)              # enc_out: [B,L,2H]\n",
        "\n",
        "        # 2) Máscara de PAD en fuente\n",
        "        src_pad_mask = (enc_in == self.pad_idx)                 # [B,L]\n",
        "\n",
        "        # 3) Decode con atención (logits en TODOS los pasos)\n",
        "        logits, _, _ = self.decoder(dec_in, init_state, enc_out, src_pad_mask)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Faltan archivos en el checkpoint: ['seq2seq_model.pth', 'optimizer_state.pth', 'config.pth', 'embedding_matrix.npy', 'input_tokenizer.pkl', 'output_tokenizer.pkl', 'word2idx_inputs.pkl', 'word2idx_outputs.pkl', 'history.json']\n",
            "\n",
            "Iniciando entrenamiento por 200 épocas...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/200 | Train loss: 6.273 | Train acc: 0.038 | Val loss: 5.785 | Val acc: 0.043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 02/200 | Train loss: 5.547 | Train acc: 0.045 | Val loss: 5.612 | Val acc: 0.049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 03/200 | Train loss: 5.174 | Train acc: 0.051 | Val loss: 5.363 | Val acc: 0.054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 04/200 | Train loss: 4.819 | Train acc: 0.055 | Val loss: 5.223 | Val acc: 0.057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 05/200 | Train loss: 4.485 | Train acc: 0.059 | Val loss: 5.114 | Val acc: 0.061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 06/200 | Train loss: 4.180 | Train acc: 0.063 | Val loss: 5.029 | Val acc: 0.065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 07/200 | Train loss: 3.883 | Train acc: 0.069 | Val loss: 5.015 | Val acc: 0.068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 08/200 | Train loss: 3.622 | Train acc: 0.073 | Val loss: 4.983 | Val acc: 0.071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 09/200 | Train loss: 3.360 | Train acc: 0.078 | Val loss: 5.008 | Val acc: 0.071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/200 | Train loss: 3.116 | Train acc: 0.085 | Val loss: 5.016 | Val acc: 0.074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/200 | Train loss: 2.902 | Train acc: 0.093 | Val loss: 5.050 | Val acc: 0.075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/200 | Train loss: 2.709 | Train acc: 0.100 | Val loss: 5.079 | Val acc: 0.076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/200 | Train loss: 2.522 | Train acc: 0.108 | Val loss: 5.083 | Val acc: 0.078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/200 | Train loss: 2.372 | Train acc: 0.113 | Val loss: 5.147 | Val acc: 0.078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/200 | Train loss: 2.235 | Train acc: 0.119 | Val loss: 5.125 | Val acc: 0.081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/200 | Train loss: 2.116 | Train acc: 0.124 | Val loss: 5.143 | Val acc: 0.081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/200 | Train loss: 2.007 | Train acc: 0.129 | Val loss: 5.157 | Val acc: 0.082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/200 | Train loss: 1.905 | Train acc: 0.133 | Val loss: 5.211 | Val acc: 0.082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/200 | Train loss: 1.821 | Train acc: 0.136 | Val loss: 5.214 | Val acc: 0.085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/200 | Train loss: 1.732 | Train acc: 0.140 | Val loss: 5.223 | Val acc: 0.085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/200 | Train loss: 1.663 | Train acc: 0.144 | Val loss: 5.240 | Val acc: 0.085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/200 | Train loss: 1.587 | Train acc: 0.147 | Val loss: 5.233 | Val acc: 0.085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/200 | Train loss: 1.529 | Train acc: 0.150 | Val loss: 5.306 | Val acc: 0.087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/200 | Train loss: 1.480 | Train acc: 0.152 | Val loss: 5.288 | Val acc: 0.086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/200 | Train loss: 1.409 | Train acc: 0.155 | Val loss: 5.328 | Val acc: 0.088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/200 | Train loss: 1.358 | Train acc: 0.158 | Val loss: 5.310 | Val acc: 0.088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/200 | Train loss: 1.296 | Train acc: 0.161 | Val loss: 5.313 | Val acc: 0.089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/200 | Train loss: 1.261 | Train acc: 0.163 | Val loss: 5.359 | Val acc: 0.089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/200 | Train loss: 1.212 | Train acc: 0.165 | Val loss: 5.340 | Val acc: 0.089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/200 | Train loss: 1.177 | Train acc: 0.167 | Val loss: 5.355 | Val acc: 0.089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/200 | Train loss: 1.141 | Train acc: 0.168 | Val loss: 5.396 | Val acc: 0.090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32/200 | Train loss: 1.104 | Train acc: 0.170 | Val loss: 5.396 | Val acc: 0.090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33/200 | Train loss: 1.060 | Train acc: 0.173 | Val loss: 5.418 | Val acc: 0.090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34/200 | Train loss: 1.026 | Train acc: 0.174 | Val loss: 5.437 | Val acc: 0.090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/200 | Train loss: 1.004 | Train acc: 0.176 | Val loss: 5.478 | Val acc: 0.091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/200 | Train loss: 0.984 | Train acc: 0.177 | Val loss: 5.439 | Val acc: 0.090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37/200 | Train loss: 0.951 | Train acc: 0.179 | Val loss: 5.484 | Val acc: 0.092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/200 | Train loss: 0.919 | Train acc: 0.180 | Val loss: 5.502 | Val acc: 0.092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39/200 | Train loss: 0.889 | Train acc: 0.182 | Val loss: 5.479 | Val acc: 0.092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40/200 | Train loss: 0.874 | Train acc: 0.182 | Val loss: 5.517 | Val acc: 0.092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41/200 | Train loss: 0.842 | Train acc: 0.185 | Val loss: 5.559 | Val acc: 0.093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42/200 | Train loss: 0.824 | Train acc: 0.186 | Val loss: 5.581 | Val acc: 0.093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43/200 | Train loss: 0.792 | Train acc: 0.188 | Val loss: 5.613 | Val acc: 0.092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44/200 | Train loss: 0.771 | Train acc: 0.189 | Val loss: 5.656 | Val acc: 0.092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45/200 | Train loss: 0.769 | Train acc: 0.188 | Val loss: 5.597 | Val acc: 0.093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46/200 | Train loss: 0.741 | Train acc: 0.191 | Val loss: 5.601 | Val acc: 0.093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47/200 | Train loss: 0.728 | Train acc: 0.190 | Val loss: 5.617 | Val acc: 0.093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48/200 | Train loss: 0.707 | Train acc: 0.192 | Val loss: 5.605 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49/200 | Train loss: 0.683 | Train acc: 0.194 | Val loss: 5.719 | Val acc: 0.093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50/200 | Train loss: 0.665 | Train acc: 0.194 | Val loss: 5.665 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51/200 | Train loss: 0.650 | Train acc: 0.196 | Val loss: 5.695 | Val acc: 0.093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52/200 | Train loss: 0.633 | Train acc: 0.197 | Val loss: 5.768 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53/200 | Train loss: 0.611 | Train acc: 0.198 | Val loss: 5.737 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54/200 | Train loss: 0.599 | Train acc: 0.198 | Val loss: 5.795 | Val acc: 0.095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55/200 | Train loss: 0.587 | Train acc: 0.199 | Val loss: 5.820 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56/200 | Train loss: 0.573 | Train acc: 0.200 | Val loss: 5.733 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57/200 | Train loss: 0.561 | Train acc: 0.201 | Val loss: 5.797 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58/200 | Train loss: 0.562 | Train acc: 0.200 | Val loss: 5.819 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59/200 | Train loss: 0.542 | Train acc: 0.202 | Val loss: 5.855 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60/200 | Train loss: 0.529 | Train acc: 0.203 | Val loss: 5.850 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61/200 | Train loss: 0.523 | Train acc: 0.203 | Val loss: 5.894 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62/200 | Train loss: 0.509 | Train acc: 0.204 | Val loss: 5.863 | Val acc: 0.094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63/200 | Train loss: 0.490 | Train acc: 0.205 | Val loss: 5.922 | Val acc: 0.095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64/200 | Train loss: 0.487 | Train acc: 0.205 | Val loss: 5.925 | Val acc: 0.095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65/200 | Train loss: 0.471 | Train acc: 0.207 | Val loss: 5.951 | Val acc: 0.095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66/200 | Train loss: 0.473 | Train acc: 0.206 | Val loss: 5.913 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67/200 | Train loss: 0.453 | Train acc: 0.207 | Val loss: 5.928 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68/200 | Train loss: 0.457 | Train acc: 0.207 | Val loss: 5.916 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69/200 | Train loss: 0.441 | Train acc: 0.209 | Val loss: 5.951 | Val acc: 0.095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70/200 | Train loss: 0.431 | Train acc: 0.209 | Val loss: 5.953 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 71/200 | Train loss: 0.428 | Train acc: 0.209 | Val loss: 5.972 | Val acc: 0.095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 72/200 | Train loss: 0.415 | Train acc: 0.210 | Val loss: 5.967 | Val acc: 0.095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 73/200 | Train loss: 0.419 | Train acc: 0.209 | Val loss: 6.059 | Val acc: 0.095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 74/200 | Train loss: 0.398 | Train acc: 0.211 | Val loss: 6.043 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 75/200 | Train loss: 0.394 | Train acc: 0.211 | Val loss: 6.049 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 76/200 | Train loss: 0.386 | Train acc: 0.212 | Val loss: 6.051 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 77/200 | Train loss: 0.380 | Train acc: 0.212 | Val loss: 6.048 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 78/200 | Train loss: 0.369 | Train acc: 0.213 | Val loss: 6.053 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 79/200 | Train loss: 0.369 | Train acc: 0.213 | Val loss: 6.100 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 80/200 | Train loss: 0.358 | Train acc: 0.213 | Val loss: 6.134 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 81/200 | Train loss: 0.354 | Train acc: 0.214 | Val loss: 6.104 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 82/200 | Train loss: 0.344 | Train acc: 0.214 | Val loss: 6.190 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 83/200 | Train loss: 0.335 | Train acc: 0.215 | Val loss: 6.129 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 84/200 | Train loss: 0.327 | Train acc: 0.215 | Val loss: 6.188 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 85/200 | Train loss: 0.327 | Train acc: 0.215 | Val loss: 6.205 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 86/200 | Train loss: 0.324 | Train acc: 0.215 | Val loss: 6.217 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 87/200 | Train loss: 0.328 | Train acc: 0.216 | Val loss: 6.172 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 88/200 | Train loss: 0.317 | Train acc: 0.217 | Val loss: 6.192 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 89/200 | Train loss: 0.307 | Train acc: 0.217 | Val loss: 6.290 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 90/200 | Train loss: 0.307 | Train acc: 0.217 | Val loss: 6.278 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 91/200 | Train loss: 0.302 | Train acc: 0.217 | Val loss: 6.218 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 92/200 | Train loss: 0.288 | Train acc: 0.219 | Val loss: 6.320 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 93/200 | Train loss: 0.292 | Train acc: 0.218 | Val loss: 6.336 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 94/200 | Train loss: 0.291 | Train acc: 0.218 | Val loss: 6.304 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 95/200 | Train loss: 0.289 | Train acc: 0.218 | Val loss: 6.322 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 96/200 | Train loss: 0.286 | Train acc: 0.218 | Val loss: 6.351 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 97/200 | Train loss: 0.281 | Train acc: 0.218 | Val loss: 6.356 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 98/200 | Train loss: 0.279 | Train acc: 0.219 | Val loss: 6.362 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99/200 | Train loss: 0.268 | Train acc: 0.219 | Val loss: 6.330 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100/200 | Train loss: 0.266 | Train acc: 0.220 | Val loss: 6.352 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 101/200 | Train loss: 0.258 | Train acc: 0.220 | Val loss: 6.434 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 102/200 | Train loss: 0.256 | Train acc: 0.220 | Val loss: 6.399 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 103/200 | Train loss: 0.247 | Train acc: 0.221 | Val loss: 6.443 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 104/200 | Train loss: 0.246 | Train acc: 0.221 | Val loss: 6.444 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 105/200 | Train loss: 0.242 | Train acc: 0.221 | Val loss: 6.519 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 106/200 | Train loss: 0.237 | Train acc: 0.222 | Val loss: 6.522 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 107/200 | Train loss: 0.245 | Train acc: 0.221 | Val loss: 6.476 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 108/200 | Train loss: 0.246 | Train acc: 0.221 | Val loss: 6.464 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 109/200 | Train loss: 0.242 | Train acc: 0.221 | Val loss: 6.475 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 110/200 | Train loss: 0.236 | Train acc: 0.221 | Val loss: 6.470 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 111/200 | Train loss: 0.233 | Train acc: 0.222 | Val loss: 6.482 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 112/200 | Train loss: 0.229 | Train acc: 0.223 | Val loss: 6.510 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 113/200 | Train loss: 0.222 | Train acc: 0.223 | Val loss: 6.530 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 114/200 | Train loss: 0.236 | Train acc: 0.222 | Val loss: 6.479 | Val acc: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 115/200 | Train loss: 0.228 | Train acc: 0.222 | Val loss: 6.538 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 116/200 | Train loss: 0.217 | Train acc: 0.223 | Val loss: 6.518 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 117/200 | Train loss: 0.224 | Train acc: 0.223 | Val loss: 6.595 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 118/200 | Train loss: 0.212 | Train acc: 0.223 | Val loss: 6.526 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 119/200 | Train loss: 0.213 | Train acc: 0.223 | Val loss: 6.568 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 120/200 | Train loss: 0.205 | Train acc: 0.224 | Val loss: 6.557 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 121/200 | Train loss: 0.204 | Train acc: 0.223 | Val loss: 6.560 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 122/200 | Train loss: 0.209 | Train acc: 0.224 | Val loss: 6.501 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 123/200 | Train loss: 0.206 | Train acc: 0.224 | Val loss: 6.571 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 124/200 | Train loss: 0.206 | Train acc: 0.224 | Val loss: 6.619 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 125/200 | Train loss: 0.199 | Train acc: 0.224 | Val loss: 6.601 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 126/200 | Train loss: 0.193 | Train acc: 0.225 | Val loss: 6.581 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 127/200 | Train loss: 0.203 | Train acc: 0.224 | Val loss: 6.586 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 128/200 | Train loss: 0.195 | Train acc: 0.224 | Val loss: 6.635 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 129/200 | Train loss: 0.193 | Train acc: 0.225 | Val loss: 6.623 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 130/200 | Train loss: 0.195 | Train acc: 0.224 | Val loss: 6.650 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 131/200 | Train loss: 0.191 | Train acc: 0.225 | Val loss: 6.652 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 132/200 | Train loss: 0.185 | Train acc: 0.225 | Val loss: 6.699 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 133/200 | Train loss: 0.190 | Train acc: 0.225 | Val loss: 6.665 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 134/200 | Train loss: 0.189 | Train acc: 0.225 | Val loss: 6.694 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 135/200 | Train loss: 0.184 | Train acc: 0.225 | Val loss: 6.685 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 136/200 | Train loss: 0.196 | Train acc: 0.224 | Val loss: 6.657 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 137/200 | Train loss: 0.186 | Train acc: 0.225 | Val loss: 6.705 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 138/200 | Train loss: 0.177 | Train acc: 0.226 | Val loss: 6.694 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 139/200 | Train loss: 0.178 | Train acc: 0.226 | Val loss: 6.732 | Val acc: 0.097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 140/200 | Train loss: 0.173 | Train acc: 0.226 | Val loss: 6.763 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 141/200 | Train loss: 0.176 | Train acc: 0.226 | Val loss: 6.825 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 142/200 | Train loss: 0.179 | Train acc: 0.226 | Val loss: 6.709 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 143/200 | Train loss: 0.179 | Train acc: 0.226 | Val loss: 6.754 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 144/200 | Train loss: 0.170 | Train acc: 0.226 | Val loss: 6.773 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 145/200 | Train loss: 0.172 | Train acc: 0.226 | Val loss: 6.747 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 146/200 | Train loss: 0.167 | Train acc: 0.226 | Val loss: 6.767 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 147/200 | Train loss: 0.162 | Train acc: 0.227 | Val loss: 6.767 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 148/200 | Train loss: 0.153 | Train acc: 0.227 | Val loss: 6.828 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 149/200 | Train loss: 0.158 | Train acc: 0.227 | Val loss: 6.750 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 150/200 | Train loss: 0.161 | Train acc: 0.227 | Val loss: 6.875 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 151/200 | Train loss: 0.159 | Train acc: 0.227 | Val loss: 6.818 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 152/200 | Train loss: 0.161 | Train acc: 0.227 | Val loss: 6.823 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 153/200 | Train loss: 0.160 | Train acc: 0.227 | Val loss: 6.835 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 154/200 | Train loss: 0.158 | Train acc: 0.227 | Val loss: 6.843 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 155/200 | Train loss: 0.148 | Train acc: 0.227 | Val loss: 6.867 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 156/200 | Train loss: 0.152 | Train acc: 0.227 | Val loss: 6.808 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 157/200 | Train loss: 0.150 | Train acc: 0.227 | Val loss: 6.865 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 158/200 | Train loss: 0.150 | Train acc: 0.227 | Val loss: 6.821 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 159/200 | Train loss: 0.160 | Train acc: 0.227 | Val loss: 6.887 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 160/200 | Train loss: 0.153 | Train acc: 0.227 | Val loss: 6.841 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 161/200 | Train loss: 0.154 | Train acc: 0.227 | Val loss: 6.872 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 162/200 | Train loss: 0.148 | Train acc: 0.228 | Val loss: 6.909 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 163/200 | Train loss: 0.149 | Train acc: 0.228 | Val loss: 6.904 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 164/200 | Train loss: 0.147 | Train acc: 0.228 | Val loss: 6.975 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 165/200 | Train loss: 0.142 | Train acc: 0.228 | Val loss: 6.978 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 166/200 | Train loss: 0.141 | Train acc: 0.228 | Val loss: 6.987 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 167/200 | Train loss: 0.151 | Train acc: 0.227 | Val loss: 6.934 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 168/200 | Train loss: 0.150 | Train acc: 0.227 | Val loss: 6.914 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 169/200 | Train loss: 0.145 | Train acc: 0.228 | Val loss: 6.976 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 170/200 | Train loss: 0.142 | Train acc: 0.228 | Val loss: 6.921 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 171/200 | Train loss: 0.139 | Train acc: 0.228 | Val loss: 6.958 | Val acc: 0.100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 172/200 | Train loss: 0.141 | Train acc: 0.228 | Val loss: 6.966 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 173/200 | Train loss: 0.132 | Train acc: 0.229 | Val loss: 6.982 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 174/200 | Train loss: 0.140 | Train acc: 0.228 | Val loss: 6.977 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 175/200 | Train loss: 0.144 | Train acc: 0.228 | Val loss: 6.917 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 176/200 | Train loss: 0.138 | Train acc: 0.228 | Val loss: 6.930 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 177/200 | Train loss: 0.135 | Train acc: 0.229 | Val loss: 6.954 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 178/200 | Train loss: 0.134 | Train acc: 0.229 | Val loss: 6.990 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 179/200 | Train loss: 0.134 | Train acc: 0.229 | Val loss: 7.027 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 180/200 | Train loss: 0.137 | Train acc: 0.229 | Val loss: 7.037 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 181/200 | Train loss: 0.131 | Train acc: 0.229 | Val loss: 7.010 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 182/200 | Train loss: 0.130 | Train acc: 0.229 | Val loss: 6.987 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 183/200 | Train loss: 0.137 | Train acc: 0.228 | Val loss: 6.962 | Val acc: 0.100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 184/200 | Train loss: 0.133 | Train acc: 0.229 | Val loss: 7.007 | Val acc: 0.100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 185/200 | Train loss: 0.137 | Train acc: 0.228 | Val loss: 6.966 | Val acc: 0.100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 186/200 | Train loss: 0.135 | Train acc: 0.229 | Val loss: 7.068 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 187/200 | Train loss: 0.135 | Train acc: 0.229 | Val loss: 7.063 | Val acc: 0.101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 188/200 | Train loss: 0.129 | Train acc: 0.229 | Val loss: 7.062 | Val acc: 0.100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 189/200 | Train loss: 0.127 | Train acc: 0.229 | Val loss: 7.049 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 190/200 | Train loss: 0.136 | Train acc: 0.229 | Val loss: 7.044 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 191/200 | Train loss: 0.130 | Train acc: 0.229 | Val loss: 7.076 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 192/200 | Train loss: 0.126 | Train acc: 0.229 | Val loss: 7.051 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 193/200 | Train loss: 0.135 | Train acc: 0.229 | Val loss: 7.072 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 194/200 | Train loss: 0.124 | Train acc: 0.229 | Val loss: 7.071 | Val acc: 0.100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 195/200 | Train loss: 0.131 | Train acc: 0.229 | Val loss: 7.052 | Val acc: 0.098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 196/200 | Train loss: 0.126 | Train acc: 0.229 | Val loss: 7.100 | Val acc: 0.100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 197/200 | Train loss: 0.123 | Train acc: 0.230 | Val loss: 7.104 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 198/200 | Train loss: 0.124 | Train acc: 0.229 | Val loss: 7.057 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 199/200 | Train loss: 0.126 | Train acc: 0.229 | Val loss: 7.068 | Val acc: 0.099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 200/200 | Train loss: 0.118 | Train acc: 0.230 | Val loss: 7.150 | Val acc: 0.099\n",
            "Checkpoint guardado en: Modelos_entrenados/Embedding_encoder_con_attention\n",
            "Modelo entrenado y guardado exitosamente\n"
          ]
        }
      ],
      "source": [
        "# =============== Crear modelo con ATTENTION (drop-in) ===============\n",
        "dropout_rate = 0.2\n",
        "hidden_size = 128\n",
        "num_layers = 1\n",
        "pad_idx = 0\n",
        "\n",
        "encoder_attn = Encoder_bidireccional_attn(\n",
        "    vocab_size=nb_words,\n",
        "    embedding_matrix=embedding_matrix,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    dropout_rate=dropout_rate\n",
        ")\n",
        "decoder_attn =  Decoder_bidreccional_attn(\n",
        "    vocab_size=num_words_output,\n",
        "    output_dim=num_words_output,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    dropout_rate=dropout_rate,\n",
        "    enc_out_dim=hidden_size*2   # 2H (BiLSTM)\n",
        "    # si tenés embedding del decoder en español:\n",
        "    # , embedding_matrix=embedding_matrix_decoder\n",
        ")\n",
        "\n",
        "model = Seq2SeqAttention(encoder_attn, decoder_attn, pad_idx=pad_idx)\n",
        "model = model.to(device)\n",
        "\n",
        "# Optimizador y loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 1e-3 suele ir mejor que 1e-2\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "#  =============== Train o Load (mismo estilo) ===============\n",
        "carpeta = \"Modelos_entrenados/Embedding_encoder_con_attention\"\n",
        "\n",
        "modelo_entrenado = check_checkpoint_exists(carpeta)\n",
        "n_epochs = 200\n",
        "\n",
        "if not modelo_entrenado:\n",
        "    print(f\"\\nIniciando entrenamiento por {n_epochs} épocas...\")\n",
        "    history_attn = train(\n",
        "        model,\n",
        "        train_loader,\n",
        "        valid_loader,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        epochs=n_epochs\n",
        "    )\n",
        "\n",
        "    config = {\n",
        "        \"max_input_len\": max_input_len,\n",
        "        \"max_out_len\": max_out_len,\n",
        "        \"max_vocab_size\": MAX_VOCAB_SIZE,\n",
        "        \"cuda\": cuda,\n",
        "\n",
        "        \"embedding_dim_enc\": int(embedding_matrix.shape[1]),\n",
        "        \"embedding_dim_dec\": int(embedding_matrix.shape[1]),  # cambia si usás embedding_matrix_decoder\n",
        "        \"hidden_size\": hidden_size,\n",
        "        \"num_layers\": num_layers,\n",
        "        \"lr\": 0.001,\n",
        "        \"dropout_rate\": dropout_rate,\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": n_epochs,\n",
        "\n",
        "        \"num_words_input\": int(embedding_matrix.shape[0]),\n",
        "        \"num_words_output\": int(num_words_output),\n",
        "\n",
        "        \"embedding_source_enc\": getattr(model_embeddings, \"name\", \"custom\"),\n",
        "        \"embedding_source_dec\": \"same_as_enc\",  # o \"spanish_pretrained\" si usaste embedding_matrix_decoder\n",
        "        \"variant\": \"seq2seq_attention_luong_dot\"\n",
        "    }\n",
        "\n",
        "    # Si usaste embedding_matrix_decoder, pásalo como param opcional\n",
        "    save_checkpoint(\n",
        "        carpeta, model, optimizer, history_attn, config,\n",
        "        input_tokenizer, output_tokenizer,\n",
        "        word2idx_inputs, word2idx_outputs, embedding_matrix\n",
        "        # , embedding_matrix_decoder=embedding_matrix_decoder\n",
        "    )\n",
        "    print(\"Modelo entrenado y guardado exitosamente\")\n",
        "else:\n",
        "    print(f\"\\nCargando modelo existente desde {carpeta}\")\n",
        "    data = load_checkpoint(\n",
        "        carpeta,\n",
        "        Encoder_bidireccional_attn, Decoder_bidreccional_attn, Seq2SeqAttention,\n",
        "        device=\"cuda\" if cuda else \"cpu\"\n",
        "    )\n",
        "    model = data[\"model\"]\n",
        "    optimizer = data[\"optimizer\"]\n",
        "    history_attn = data[\"history\"]\n",
        "    print(\"Modelo cargado exitosamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generar inferencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# Reconstruir idx2word_outputs si no existe\n",
        "# ===============================================================\n",
        "if 'idx2word_outputs' not in globals():\n",
        "    if 'output_tokenizer' in globals() and hasattr(output_tokenizer, 'index_word'):\n",
        "        idx2word_outputs = output_tokenizer.index_word\n",
        "    elif 'word2idx_outputs' in globals():\n",
        "        idx2word_outputs = {v: k for k, v in word2idx_outputs.items()}\n",
        "    else:\n",
        "        raise ValueError(\"No se encontró ni 'output_tokenizer' ni 'word2idx_outputs'.\")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def greedy_decode(model, encoder_input, sos_idx, eos_idx, max_len, device, pad_idx=0):\n",
        "    \"\"\"\n",
        "    Decodificación Greedy para un modelo Seq2Seq:\n",
        "    - model(encoder_input, decoder_input) -> logits [B, T, V]\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    if encoder_input.dim() == 1:\n",
        "        encoder_input = encoder_input.unsqueeze(0)\n",
        "    encoder_input = encoder_input.to(device)\n",
        "\n",
        "    dec = torch.full((1, 1), sos_idx, dtype=torch.long, device=device)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        logits = model(encoder_input, dec)\n",
        "        next_token = logits[:, -1, :].argmax(dim=-1)\n",
        "        #  Forzamos el token al mismo device que dec\n",
        "        next_token = next_token.to(device)\n",
        "        dec = torch.cat([dec, next_token.unsqueeze(1)], dim=1)\n",
        "        if next_token.item() == eos_idx:\n",
        "            break\n",
        "\n",
        "    return dec.squeeze(0).tolist()[1:]  # sin <sos>\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def beam_search_decode(model, encoder_input, sos_idx, eos_idx, max_len, device,\n",
        "                       beam_size=5, length_penalty=1.0, pad_idx=0,\n",
        "                       temperature=1.0, top_k=None):\n",
        "    \"\"\"\n",
        "    Beam Search estándar para Seq2Seq.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    if encoder_input.dim() == 1:\n",
        "        encoder_input = encoder_input.unsqueeze(0)\n",
        "    encoder_input = encoder_input.to(device)\n",
        "\n",
        "    beams = [(0.0, torch.full((1, 1), sos_idx, dtype=torch.long, device=device))]\n",
        "    finished = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        new_beams = []\n",
        "        for logp, seq in beams:\n",
        "            if seq[0, -1].item() == eos_idx:\n",
        "                finished.append((logp, seq.clone()))\n",
        "                continue\n",
        "\n",
        "            logits = model(encoder_input, seq)[:, -1, :]\n",
        "            if temperature != 1.0:\n",
        "                logits /= temperature\n",
        "\n",
        "            if top_k is not None and 0 < top_k < logits.size(-1):\n",
        "                topk_vals, topk_idx = torch.topk(logits, k=top_k, dim=-1)\n",
        "                log_probs = F.log_softmax(topk_vals, dim=-1)\n",
        "                cand_ids = topk_idx.squeeze(0)\n",
        "            else:\n",
        "                log_probs = F.log_softmax(logits, dim=-1)\n",
        "                cand_ids = torch.arange(log_probs.size(-1), device=device)\n",
        "\n",
        "            log_probs = log_probs.squeeze(0)\n",
        "            topk_logp, topk_id = torch.topk(log_probs, k=min(beam_size, log_probs.numel()))\n",
        "            for add_logp, token_rank in zip(topk_logp.tolist(), topk_id.tolist()):\n",
        "                token_id = cand_ids[token_rank].item()\n",
        "                new_seq = torch.cat([seq, torch.tensor([[token_id]], device=device)], dim=1)\n",
        "                new_beams.append((logp + add_logp, new_seq))\n",
        "\n",
        "        if not new_beams and not finished:\n",
        "            break\n",
        "\n",
        "        def norm_score(tup):\n",
        "            lp, s = tup\n",
        "            # s: [1, t_con_sos]\n",
        "            seq_len_wo_sos = max(1, s.size(1) - 1)\n",
        "            denom = (seq_len_wo_sos ** length_penalty) if length_penalty != 1.0 else seq_len_wo_sos\n",
        "            return lp / denom\n",
        "\n",
        "\n",
        "        new_beams.sort(key=norm_score, reverse=True)\n",
        "        beams = new_beams[:beam_size]\n",
        "\n",
        "        if all(seq[0, -1].item() == eos_idx for _, seq in beams):\n",
        "            finished.extend(beams)\n",
        "            break\n",
        "\n",
        "    pool = finished if finished else beams\n",
        "    pool.sort(key=lambda x: x[0] / (max(1, x[1].size(1) - 1) ** length_penalty), reverse=True)\n",
        "    best = pool[0][1].squeeze(0).tolist()\n",
        "    return best[1:]  # sin <sos>\n",
        "\n",
        "def ids_to_sentence(ids, idx2word, eos_idx, skip_special=True):\n",
        "    out = []\n",
        "    for i in ids:\n",
        "        if i == eos_idx:\n",
        "            break\n",
        "        tok = idx2word.get(i, f\"<unk:{i}>\")\n",
        "        if skip_special and tok in (\"<sos>\", \"<eos>\", \"<pad>\"):\n",
        "            continue\n",
        "        out.append(tok)\n",
        "    return \" \".join(out).strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "[5238] Original inglés         : good always wins over evil\n",
            "[5238] Traducción de referencia: el bien gana siempre al mal\n",
            "[5238] GREEDY                  : bueno no lo puede ser diferente\n",
            "[5238] BEAM                    : bueno no lo puede ser diferente\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "[912] Original inglés         : you'll miss the train\n",
            "[912] Traducción de referencia: perderás el tren\n",
            "[912] GREEDY                  : perderás el tren\n",
            "[912] BEAM                    : perderás el tren\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "[204] Original inglés         : christmas is december 25th\n",
            "[204] Traducción de referencia: la navidad es el 25 de diciembre\n",
            "[204] GREEDY                  : la navidad es el 25 de diciembre\n",
            "[204] BEAM                    : la navidad es el 25 de diciembre\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "[2253] Original inglés         : do you know me\n",
            "[2253] Traducción de referencia: me conoce usted\n",
            "[2253] GREEDY                  : me conoce usted\n",
            "[2253] BEAM                    : me conoce usted\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "[2006] Original inglés         : tom has a 13 year old daughter\n",
            "[2006] Traducción de referencia: tom tiene una hija de 13 años\n",
            "[2006] GREEDY                  : tom tiene una hija de 13 años\n",
            "[2006] BEAM                    : tom tiene una hija de 13 años\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# Ejemplo de inferencia Greedy y Beam Search en 5 muestras\n",
        "# ===============================================================\n",
        "import random\n",
        "\n",
        "SEED = 42  # <- cambiálo si querés otra corrida reproducible\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Para que cuDNN no meta heurísticas no determinísticas\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# --- Parámetros necesarios ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval().to(device)\n",
        "\n",
        "# Vocab inverso de entrada\n",
        "if 'idx2word_inputs' not in globals():\n",
        "    if 'input_tokenizer' in globals() and hasattr(input_tokenizer, 'index_word'):\n",
        "        idx2word_inputs = input_tokenizer.index_word\n",
        "    elif 'word2idx_inputs' in globals():\n",
        "        idx2word_inputs = {v: k for k, v in word2idx_inputs.items()}\n",
        "    else:\n",
        "        raise ValueError(\"No se encontró idx2word_inputs (ni input_tokenizer ni word2idx_inputs).\")\n",
        "\n",
        "sos_idx = word2idx_outputs[\"<sos>\"]\n",
        "eos_idx = word2idx_outputs[\"<eos>\"]\n",
        "pad_idx = 0\n",
        "\n",
        "def get_item(i):\n",
        "    if 'data_set' in globals() and data_set is not None:\n",
        "        enc, _, dec_out = data_set[i]\n",
        "        if dec_out.dim() == 3:\n",
        "            dec_out = dec_out.argmax(dim=-1)\n",
        "        return enc.long(), dec_out.long()\n",
        "    else:\n",
        "        enc = torch.from_numpy(encoder_input_sequences[i]).long()\n",
        "        tgt = torch.from_numpy(decoder_output_sequences[i]).long()\n",
        "        return enc, tgt\n",
        "\n",
        "def ids_to_sentence_input(ids, idx2word, skip_special=True):\n",
        "    out = []\n",
        "    for i in ids:\n",
        "        tok = idx2word.get(int(i), f\"<unk:{i}>\")\n",
        "        if skip_special and tok in (\"<sos>\", \"<eos>\", \"<pad>\"):\n",
        "            continue\n",
        "        out.append(tok)\n",
        "    return \" \".join(out).strip()\n",
        "\n",
        "# --- Selecciono 5 ejemplos aleatorios ---\n",
        "N = 5\n",
        "pool_size = len(data_set) if 'data_set' in globals() and data_set is not None else len(encoder_input_sequences)\n",
        "indices = random.sample(range(pool_size), k=min(N, pool_size))\n",
        "\n",
        "for idx in indices:\n",
        "    enc, tgt = get_item(idx)\n",
        "    enc = enc.unsqueeze(0) if enc.dim() == 1 else enc\n",
        "\n",
        "    greedy_ids = greedy_decode(model, enc, sos_idx, eos_idx, max_out_len, device, pad_idx)\n",
        "    beam_ids   = beam_search_decode(model, enc, sos_idx, eos_idx, max_out_len, device,\n",
        "                                    beam_size=10, length_penalty=0.1, pad_idx=pad_idx)\n",
        "\n",
        "    ref_text    = ids_to_sentence(tgt.tolist(), idx2word_outputs, eos_idx)\n",
        "    greedy_text = ids_to_sentence(greedy_ids, idx2word_outputs, eos_idx)\n",
        "    beam_text   = ids_to_sentence(beam_ids, idx2word_outputs, eos_idx)\n",
        "    # ids para imprimir (sin padding=0)\n",
        "    src_ids_for_print = [int(t) for t in enc.squeeze(0).tolist() if t != 0]\n",
        "    src_text = ids_to_sentence_input(src_ids_for_print, idx2word_inputs)\n",
        "\n",
        "    print(\"=\"*100)\n",
        "    print(f\"[{idx}] Original inglés         : {src_text}\")\n",
        "    print(f\"[{idx}] Traducción de referencia: {ref_text}\")\n",
        "    print(f\"[{idx}] GREEDY                  : {greedy_text}\")\n",
        "    print(f\"[{idx}] BEAM                    : {beam_text}\")\n",
        "    print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Traducciones (GREEDY y BEAM) =====\n",
            "\n",
            "EN: I will miss you\n",
            "GREEDY: te echaré de menos\n",
            "BEAM  : te echaré de menos\n",
            "--------------------------------------------------------------------------------\n",
            "EN: happy birthday\n",
            "GREEDY: felices de su cumpleaños\n",
            "BEAM  : felices de su cumpleaños\n",
            "--------------------------------------------------------------------------------\n",
            "EN: my friend Paul lives in this city\n",
            "GREEDY: mi amigo se llama en esta ciudad\n",
            "BEAM  : mi amigo es esta ciudad\n",
            "--------------------------------------------------------------------------------\n",
            "EN: how long have you been living here\n",
            "GREEDY: cuánto tiempo has estado nadando\n",
            "BEAM  : cuánto tiempo has estado nadando\n",
            "--------------------------------------------------------------------------------\n",
            "EN: welcome to my home\n",
            "GREEDY: dónde está mi casa\n",
            "BEAM  : dónde está mi casa\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Asegurar mapeo idx->palabra de salida\n",
        "if 'idx2word_outputs' not in globals():\n",
        "    if 'output_tokenizer' in globals() and hasattr(output_tokenizer, 'index_word'):\n",
        "        idx2word_outputs = output_tokenizer.index_word\n",
        "    elif 'word2idx_outputs' in globals():\n",
        "        idx2word_outputs = {v: k for k, v in word2idx_outputs.items()}\n",
        "    else:\n",
        "        raise ValueError(\"No se encontró ni 'output_tokenizer' ni 'word2idx_outputs'.\")\n",
        "\n",
        "phrases = [\n",
        "    \"I will miss you\",\n",
        "    \"happy birthday\",\n",
        "    \"my friend Paul lives in this city\",\n",
        "    \"how long have you been living here\",\n",
        "    \"welcome to my home\",\n",
        "]\n",
        "\n",
        "# Tokenizar y padear entradas\n",
        "int_seqs = input_tokenizer.texts_to_sequences(phrases)\n",
        "enc_batch = pad_sequences(int_seqs, maxlen=max_input_len)\n",
        "enc_batch_t = torch.from_numpy(enc_batch).long()\n",
        "\n",
        "sos_idx = word2idx_outputs[\"<sos>\"]\n",
        "eos_idx = word2idx_outputs[\"<eos>\"]\n",
        "pad_idx = 0\n",
        "\n",
        "model.eval().to(device)\n",
        "\n",
        "print(\"\\n===== Traducciones (GREEDY y BEAM) =====\\n\")\n",
        "for i, sent in enumerate(phrases):\n",
        "    enc = enc_batch_t[i:i+1].to(device)\n",
        "\n",
        "    greedy_ids = greedy_decode(model, enc, sos_idx, eos_idx, max_out_len, device, pad_idx)\n",
        "    beam_ids   = beam_search_decode(model, enc, sos_idx, eos_idx, max_out_len, device,\n",
        "                                    beam_size=10, length_penalty=0.1, pad_idx=pad_idx)\n",
        "\n",
        "    greedy_text = ids_to_sentence(greedy_ids, idx2word_outputs, eos_idx)\n",
        "    beam_text   = ids_to_sentence(beam_ids, idx2word_outputs, eos_idx)\n",
        "\n",
        "    print(f\"EN: {sent}\")\n",
        "    print(f\"GREEDY: {greedy_text}\")\n",
        "    print(f\"BEAM  : {beam_text}\")\n",
        "    print(\"-\"*80)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CEIA-ProcLenNaturalI",
      "language": "python",
      "name": "proc-len-naturali"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
